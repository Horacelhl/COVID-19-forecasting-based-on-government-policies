{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOWCATL algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "store_data = pd.read_csv(r\"C:\\Users\\MORPH\\DataSciCov\\store_data2.csv\")  #Importing Dataset from system\n",
    "\n",
    "store_data.head()   # to check the header\n",
    "\n",
    "store_data = pd.read_csv(r\"C:\\Users\\MORPH\\DataSciCov\\store_data2.csv\", header=None)  #keeping header as None\n",
    "\n",
    "num_records = len(store_data)\n",
    "print(num_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Bagel</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2\n",
       "0     Bread    Wine    Eggs\n",
       "1     Bread  Cheese    Meat\n",
       "2    Cheese    Meat    Eggs\n",
       "3    Cheese    Meat    Eggs\n",
       "4      Eggs   Bread    Wine\n",
       "..      ...     ...     ...\n",
       "139   Bagel   Bread  Diaper\n",
       "140  Cheese    Meat    Eggs\n",
       "141  Cheese    Meat    Eggs\n",
       "142   Bread    Wine    Eggs\n",
       "143  Cheese    Meat    Eggs\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = store_data[[0,1,2]]\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pencil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0      Meat\n",
       "1    Diaper\n",
       "2      Milk\n",
       "3      Milk\n",
       "4    Pencil\n",
       "..      ...\n",
       "139  Cheese\n",
       "140    Milk\n",
       "141    Milk\n",
       "142   Bagel\n",
       "143    Milk\n",
       "\n",
       "[144 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = store_data[[3]]\n",
    "target_data.columns = [0]\n",
    "target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. generate all initial episodes in k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def init_all_epsiode(data, min_supp):\n",
    "    \n",
    "    all_antecedent_list = {}\n",
    "    for i in range(len(data.columns)):\n",
    "        print(\"this is \", i, \"col\")\n",
    "        antecedent_list = init_epsiode(data[[i]], min_supp)\n",
    "        temp = [antecedent_list]\n",
    "        all_antecedent_list.update({i : temp})\n",
    "    \n",
    "    return all_antecedent_list\n",
    "\n",
    "\n",
    "def init_epsiode(data, min_supp):\n",
    "    \n",
    "    antecedent_list = []\n",
    "    \n",
    "    GC_list = data.values\n",
    "    GC_list = list(itertools.chain.from_iterable(GC_list))\n",
    "\n",
    "    _t = list(np.unique(GC_list))   \n",
    "    \n",
    "    for item in _t:\n",
    "        #print(item)\n",
    "        item = [item]\n",
    "        count = init_count(item, GC_list)\n",
    "        if count > min_supp:\n",
    "            antecedent_list.append(item)\n",
    "            print(item,count, \"is support\" )\n",
    "       \n",
    "    return antecedent_list\n",
    "\n",
    "\n",
    "def init_count(item_set, data):\n",
    "    # we need to go over the all data, find how many times the item set is appear.\n",
    "    #print(data)\n",
    "    count = 0\n",
    "    for i in range(len(item_set)):\n",
    "        for j in range(len(data)):\n",
    "\n",
    "            #print(set(item_set), set([data[j]]))\n",
    "            #print(set(item_set).issubset(set(data[j])))\n",
    "\n",
    "            if set(item_set).issubset(set([data[j]])):\n",
    "                count += 1\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. build all combination for single space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "\n",
    "def powerset(s):\n",
    "    return list(chain.from_iterable(combinations(s,r) for r in range(1,len(s)+1)))\n",
    "\n",
    "def get_all_epsiodes(data, L1_item_sets, min_supp, window):\n",
    "    \n",
    "    item_sets = {}\n",
    "    item_sets_occurences = {}\n",
    "    item_sets_count = {}\n",
    "    \n",
    "    # get data\n",
    "    # know how many space\n",
    "    # do one space each time, along with its item_set\n",
    "    length = len(data.columns)\n",
    "    for i in range(length):\n",
    "        print(\"begin data space:\", i)\n",
    "        #print(data[[i]])\n",
    "        #print(L1_item_sets[i])\n",
    "        item_set, item_occurence, item_count = check_epsiode(data[[i]], L1_item_sets[i], min_supp, window)\n",
    "        # update dict\n",
    "        item_sets.update({i: item_set})\n",
    "        item_sets_occurences.update({i : item_occurence})\n",
    "        item_sets_count.update({i : item_count})\n",
    "    \n",
    "    return item_sets, item_sets_occurences, item_sets_count\n",
    "\n",
    "\n",
    "def check_epsiode(data, L1_item_set, min_supp, window):\n",
    "    \n",
    "    item_set = []\n",
    "    item_occurence = []\n",
    "    item_count = []\n",
    "    # first generate all combination\n",
    "    # pop the combination one by one\n",
    "    # count if it meet the min_supp\n",
    "    s = powerset(L1_item_set[0])\n",
    "    s.pop()\n",
    "    \n",
    "    for z in s:\n",
    "        #print(z)\n",
    "        count, min_occurences = count_epsiode(data, z, window)\n",
    "        if count > min_supp:\n",
    "            print(\"item set candidate:\", z)\n",
    "            print(\"occur in :\", min_occurences)\n",
    "            print(\"count :\", count)\n",
    "            # add this item to list\n",
    "            # add its occurences to list\n",
    "            # add its count to list\n",
    "            item_set.append(z)\n",
    "            item_occurence.append(min_occurences)\n",
    "            item_count.append(count)\n",
    "   \n",
    "    return item_set, item_occurence, item_count\n",
    "\n",
    "def count_epsiode(data, item, window):\n",
    "    \n",
    "    count = 0\n",
    "    minimal_occurences = []\n",
    "    \n",
    "    if len(item) <= window :     \n",
    "    \n",
    "        # count epsiode\n",
    "        # also record its minimal occurences\n",
    "        # when the item not larger than window, process it\n",
    "        for i in range(len(data)- window):\n",
    "            find, begin, end = sequence_check(data, i, item, window)\n",
    "            if find:\n",
    "                occur = \"{}-{}\".format(begin, end)\n",
    "                if minimal_occurences.count(occur) == 0 :\n",
    "                    # new position found for this epsiode\n",
    "                    minimal_occurences.append(occur)\n",
    "                    count += 1\n",
    "                \n",
    "    return count, minimal_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_check(data, start_index, item, window):\n",
    "    # we will try to find every item in epsiode inside the search window\n",
    "    item_mark = len(item)\n",
    "    item_flag = 0\n",
    "    begin_position = 0\n",
    "    end_position = 0\n",
    "    \n",
    "    #print(\"item to check \", item, item_mark)\n",
    "    locol_data = data.copy()\n",
    "    locol_data.columns = [0]\n",
    "    \n",
    "    for i in range(start_index, start_index + window):\n",
    "        #print(i)\n",
    "        #print(locol_data.iloc[i][0], item[item_flag][0])\n",
    "        if locol_data.iloc[i][0] == item[item_flag][0]:\n",
    "            if begin_position == 0:\n",
    "                begin_position = i\n",
    "                end_position = i\n",
    "            else:\n",
    "                end_position = i\n",
    "            item_flag += 1\n",
    "            \n",
    "            if item_flag == item_mark:\n",
    "                # this means we find all item in epsiode\n",
    "                return True,begin_position, end_position\n",
    "    \n",
    "    return False, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create initial dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_init_dataframe(antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count,\n",
    "                         consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count):\n",
    "    \n",
    "    df1 = create_init_ante_dataframe(antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count)\n",
    "    df2 = create_init_conse_dataframe(consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count)\n",
    "    df_final = pd.concat([df1, df2])\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "def create_init_ante_dataframe(antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count):\n",
    "    \n",
    "    first_col = \"episode/rule\"\n",
    "    second_col = \"consequent\"\n",
    "    third_col = \"Minimal occurrences\"\n",
    "    forth_col = \"Support\"\n",
    "    fifth_col = \"confidence\"\n",
    "    \n",
    "    first_list = []\n",
    "    second_list = []\n",
    "    third_list = []\n",
    "    forth_list = []\n",
    "    fifth_list = []\n",
    "    \n",
    "    df = pd.DataFrame(columns = [first_col,second_col,third_col,forth_col, fifth_col])\n",
    "    \n",
    "    if len(antecedent_item_sets) > 0:\n",
    "\n",
    "        for k,v in  antecedent_item_sets.items():\n",
    "            \n",
    "            #print(k, v)\n",
    "            #print(len(v))\n",
    "            \n",
    "            for i in range(len(v)):\n",
    "                first_list.append(v[i])\n",
    "                second_list.append(\"#\")\n",
    "                third_list.append(antecedent_item_sets_occurences[k][i])\n",
    "                forth_list.append(antecedent_item_sets_count[k][i])\n",
    "                fifth_list.append(\"#\")\n",
    "    \n",
    "        data = {first_col:  first_list,\n",
    "                second_col: second_list,\n",
    "                third_col: third_list,\n",
    "                forth_col: forth_list,\n",
    "                fifth_col: fifth_list\n",
    "                }\n",
    "\n",
    "        df = pd.DataFrame (data, columns = [first_col,second_col,third_col,forth_col,fifth_col])\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_init_conse_dataframe(consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count):\n",
    "    first_col = \"episode/rule\"\n",
    "    second_col = \"consequent\"\n",
    "    third_col = \"Minimal occurrences\"\n",
    "    forth_col = \"Support\"\n",
    "    fifth_col = \"confidence\"\n",
    "    \n",
    "    first_list = []\n",
    "    second_list = []\n",
    "    third_list = []\n",
    "    forth_list = []\n",
    "    fifth_list = []\n",
    "    \n",
    "    df = pd.DataFrame(columns = [first_col,second_col,third_col,forth_col,fifth_col])\n",
    "    \n",
    "    if len(consequent_item_sets) > 0:\n",
    "\n",
    "        for k,v in  consequent_item_sets.items():\n",
    "            \n",
    "            #print(k, v)\n",
    "            #print(len(v))\n",
    "            \n",
    "            for i in range(len(v)):\n",
    "                first_list.append(\"#\")\n",
    "                second_list.append(v[i])\n",
    "                third_list.append(consequent_item_sets_occurences[k][i])\n",
    "                forth_list.append(consequent_item_sets_count[k][i])\n",
    "                fifth_list.append(\"#\")\n",
    "    \n",
    "        data = {first_col:  first_list,\n",
    "                second_col: second_list,\n",
    "                third_col: third_list,\n",
    "                forth_col: forth_list,\n",
    "                fifth_col: fifth_list\n",
    "                }\n",
    "\n",
    "        df = pd.DataFrame (data, columns = [first_col,second_col,third_col,forth_col,fifth_col])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. get epsiode combination in all space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_space_epsiode_combination(item_sets, space_order):\n",
    "    \n",
    "    all_space_epsiode_list = []\n",
    "    \n",
    "    # first we need to add all signle epsiode into storage\n",
    "    # k = 1\n",
    "    for k,v in item_sets.items():\n",
    "        for i in range(len(v)):\n",
    "            temp = {k : v[i]}\n",
    "            all_space_epsiode_list.append(temp)\n",
    "    \n",
    "    # second we need to deal with k = 2 combination\n",
    "    \n",
    "    new_candidate = []\n",
    "    the_initial_space = list(item_sets)\n",
    "    for i in range(len(space_order) -1):\n",
    "        #print(the_initial_space[i])\n",
    "        for j in range(i+1, len(space_order)):\n",
    "        \n",
    "            print(i,j)\n",
    "            \n",
    "            first_group_candidate = list(item_sets[the_initial_space[i]])\n",
    "            print(first_group_candidate)\n",
    "            second_group_candidate = list(item_sets[the_initial_space[j]])\n",
    "            print(second_group_candidate)\n",
    "            for x in range(len(first_group_candidate)):\n",
    "                for y in range(len(second_group_candidate)):\n",
    "                    temp = merge_candidate(the_initial_space[i],first_group_candidate[x], \n",
    "                                                        the_initial_space[j], second_group_candidate[y], space_order)\n",
    "                    all_space_epsiode_list.append(temp)\n",
    "                    new_candidate.append(temp)\n",
    "                    \n",
    "    \n",
    "    # last we want to deal with k > 2 combination\n",
    "\n",
    "\n",
    "    while len(new_candidate) > 2:\n",
    "        print(\"=============\")\n",
    "        print(\"this round has candidate:\", len(new_candidate))\n",
    "        print(\"=============\")\n",
    "        Ln = []\n",
    "        # we start doing combination\n",
    "        # always resign the new_candidate\n",
    "        for i in range(0,len(new_candidate)-1):\n",
    "            for j in range(i+1,len(new_candidate)):\n",
    "                #print(list(L2_item_set[i]), list(L2_item_set[j]))\n",
    "                #print(L2_item_set[i], L2_item_set[j])\n",
    "\n",
    "                item_set = merge_candidate(list(new_candidate[i]),new_candidate[i], list(new_candidate[j]), new_candidate[j],space_order)\n",
    "\n",
    "                if len(item_set) > 0:\n",
    "                    print(item_set)\n",
    "                    # we need to check if duplicate\n",
    "                    if check_duplicate(Ln,item_set):\n",
    "                        print(\"duplicate\")\n",
    "                    else:\n",
    "                        Ln.append(item_set)\n",
    "                        all_space_epsiode_list.append(item_set)\n",
    "        new_candidate = Ln\n",
    "        \n",
    "        \n",
    "    return all_space_epsiode_list\n",
    "\n",
    "def merge_item_list(item1, item2, order):\n",
    "    length = len(item1)\n",
    "    count = 0\n",
    "    same_space = []\n",
    "    temp = item1.copy()\n",
    "    temp2 = item2.copy()\n",
    "\n",
    "    for i in order:\n",
    "        if (i in item1) & (i in item2):\n",
    "            if item1[i] == item2[i]:\n",
    "                count += 1\n",
    "                #print(i, \"is the same space\")\n",
    "                same_space.append(i)\n",
    "    \n",
    "    if (length - count) == 1:\n",
    "        # we will merge item here with the support of order\n",
    "        print(item1)\n",
    "        print(item2)\n",
    "        print(\"item allow to merge\")\n",
    "        for j in range(len(same_space)):\n",
    "            del temp2[same_space[j]]\n",
    "        \n",
    "        temp.update(temp2.items())\n",
    "        return temp\n",
    "        \n",
    "    return {}\n",
    "\n",
    "def merge_candidate(space1, item1, space2, item2, order):\n",
    "    \n",
    "    temp_dict = {}\n",
    "    \n",
    "    if isinstance(space1, list): \n",
    "        #print(\"your object is a list, proceeding for L > 2 \") \n",
    "        # this means the item we received will be multiple, we will have to\n",
    "        # apply special check for them\n",
    "        \n",
    "        #print(space1)\n",
    "        #print(len(space1))\n",
    "        #print(space2)\n",
    "        #print(len(space2))\n",
    "        \n",
    "        if len(space1) == len(space2):\n",
    "            mark = len(space1)\n",
    "            space_same_count = 0  \n",
    "            #print(\"same length\")\n",
    "        \n",
    "            # test if the two space are only different in 1 space\n",
    "            for i in range(len(space1)):\n",
    "                for j in range(len(space1)):\n",
    "                    if space1[i] == space2[j]:\n",
    "                        space_same_count += 1\n",
    "                    \n",
    "            # if the difference in space is 1, we are going to check if the same space has same item\n",
    "            # we need to trace the order of space\n",
    "            \n",
    "            if (mark-space_same_count) == 1:\n",
    "                #print(\"space allow to merge\")\n",
    "                temp_dict = merge_item_list(item1, item2, order)\n",
    "                return temp_dict\n",
    "            #else:\n",
    "                #print(\"not allow to merge\")\n",
    "        #print(\"====end====\")\n",
    "        \n",
    "    else: \n",
    "        #print(\"your object is not a list, this is the initial L2\") \n",
    "    \n",
    "        if space1 != space2:\n",
    "            temp_dict.update({space1 : item1})\n",
    "            temp_dict.update({space2 : item2})\n",
    "\n",
    "        print(\"direct merge:\", temp_dict)\n",
    "    return temp_dict \n",
    "\n",
    "\n",
    "def check_duplicate(all_rule_set, item_set):\n",
    "    result = False\n",
    "    temp = {}\n",
    "    \n",
    "    for i in range(len(all_rule_set)):\n",
    "        count = 0\n",
    "        temp = all_rule_set[i]\n",
    "        mark = len(list(temp))\n",
    "        \n",
    "        # if there is a rule exist, has the same with item_set, we consider this is dupulicate\n",
    "        \n",
    "        for k,v in temp.items():\n",
    "            if k in item_set :\n",
    "                if v == item_set[k]:\n",
    "                    count += 1\n",
    "                    if count == mark:\n",
    "                        result = True\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. get final count and confidence measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence(antecedent_episode_list, antecedent_window, antecedent_data, \n",
    "                   consequent_episode_list, consequent_window, consequent_data, \n",
    "                   min_supp = 5, lag = 1, min_conf = 0.1):\n",
    "    \n",
    "    first_col = \"episode/rule\"\n",
    "    second_col = \"consequent\"\n",
    "    third_col = \"Minimal occurrences\"\n",
    "    forth_col = \"Support\"\n",
    "    fifth_col = \"confidence\"\n",
    "    \n",
    "    result_df = pd.DataFrame(columns = [first_col,second_col,third_col,forth_col, fifth_col])\n",
    "    for i in range(len(consequent_episode_list)):\n",
    "        for j in range(len(antecedent_episode_list)):\n",
    "            result = count_association(antecedent_episode_list[j], antecedent_window, antecedent_data, \n",
    "                                      consequent_episode_list[i], consequent_window, consequent_data, \n",
    "                                      min_supp, lag, min_conf)\n",
    "            if len(result) > 0:\n",
    "                df2 = create_final_dataframe(result)\n",
    "                \n",
    "                result_df = pd.concat([result_df, df2])\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def count_association(item1, win1, data1, item2, win2, data2, min_supp, lag, min_conf):\n",
    "    \n",
    "    ante_count = 0\n",
    "    conse_count = 0\n",
    "    \n",
    "    \n",
    "    ante_begin = 0\n",
    "    ante_end = 0\n",
    "    conse_begin = 0\n",
    "    conse_end = 0\n",
    "    \n",
    "    rule = \"\"\n",
    "    conse = \"\"\n",
    "    ante_occur = \"\"\n",
    "    conse_occur = \"\"\n",
    "    occur_list = []\n",
    "    conf = 0\n",
    "    # we want to loop based on data row index\n",
    "    for i in range(len(data1)):\n",
    "                \n",
    "        # we need to concern about the whole length may out of index, thus we need to check if index in dataframe range \n",
    "        # when processing it\n",
    "                \n",
    "        # first we need to check if all the epsiode in antecedent is exist\n",
    "        # we will collect the count of exist, see if the number match with the number of elements\n",
    "        # we will also collect the begin and end of each \n",
    "        # the begin and end of whole epsiode is the min-begin and max-end\n",
    "        # in the search of consequent, we begin with the max-end of antecedent\n",
    "        antecedent_count = 0\n",
    "        \n",
    "        ante_end_list = []    \n",
    "        for k,v in item1.items():\n",
    "            result, end_pos = check_episode_exist(k ,v, data1, i, win1)\n",
    "            if result:\n",
    "                antecedent_count += 1\n",
    "                ante_end_list.append(end_pos)\n",
    "            \n",
    "        if antecedent_count == len(item1):\n",
    "            if len(item1) == 1:\n",
    "                ante_begin = max(ante_end_list)\n",
    "            else:\n",
    "                ante_begin = i\n",
    "            ante_end = max(ante_end_list)\n",
    "            #print(\"pass\")\n",
    "            ante_count += 1\n",
    "            ante_occur = \"{}-{}\".format(ante_begin, ante_end)\n",
    "  \n",
    "            \n",
    "            # second we need to check when this item is exist, does consequent also exist\n",
    "            # we need search from the position of antecedent max-end, with a distance of lag\n",
    "            # if we deal with single dimension\n",
    "                # if we deal with single item, then we find it - done\n",
    "                # if we deal with mulitple item, we find the begining item inside distance of lag, and then find\n",
    "                # right sequence inside window - done\n",
    "            # if we deal with multiple dimension\n",
    "                # we need to do every instance like above, and check the count\n",
    "                # when the exist count is match the number of its dimension - done\n",
    "                    \n",
    "            # whatever happened here will not influence the count of antecedent, it always add 1\n",
    "\n",
    "            for j in range(ante_end, ante_end + lag + 1):\n",
    "                \n",
    "                consequent_count = 0\n",
    "                consequent_end_list = []\n",
    "                for a,b in item2.items():\n",
    "                    result, end_pos = check_episode_exist(a,b, data2, i, win2)\n",
    "                    if result:\n",
    "                        consequent_count += 1\n",
    "                        consequent_end_list.append(end_pos)\n",
    "                \n",
    "                # to avoid repeat count, we only going to find once\n",
    "                if consequent_count == len(item2):\n",
    "                    conse_count += 1\n",
    "                    conse_begin = j\n",
    "                    conse_end = max(ante_end_list)\n",
    "                    conse_occur = \"{}-{}\".format(conse_begin, conse_end)\n",
    "                    occur_list.append([ante_occur, conse_occur])\n",
    "                    break;\n",
    "        \n",
    "        \n",
    "    if (ante_count > min_supp) & (conse_count > min_supp):\n",
    "        if conse_count / ante_count > min_conf:\n",
    "            \n",
    "            for k,v in item1.items():\n",
    "                rule += \" {}\".format(v)\n",
    "                \n",
    "            for k,v in item2.items():\n",
    "                conse += \" {}\".format(v)\n",
    "            \n",
    "            rule += \"lag{}\".format(lag)\n",
    "            conf = conse_count / ante_count     \n",
    "            \n",
    "            return [rule, conse, occur_list, conse_count, conf]\n",
    "    \n",
    "    \n",
    "    return []\n",
    "\n",
    "def check_episode_exist(space, episode, data, begin_index, window):\n",
    "    \n",
    "    local_data = data[space].copy()\n",
    "    local_mark = len(episode)\n",
    "    local_count = 0\n",
    "    end_position = 0\n",
    "    result = False\n",
    "    for i in range(begin_index, begin_index + 1 + window):\n",
    "        if i in local_data.index:\n",
    "            #print(i, local_data.iloc[i] , local_mark, episode)\n",
    "            if local_data.iloc[i] == episode[local_count][0]:\n",
    "                local_count += 1\n",
    "            if local_count == local_mark:\n",
    "                end_position = i\n",
    "                result = True\n",
    "                break;\n",
    "    \n",
    "    return result, end_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. create final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_dataframe(result):\n",
    "    \n",
    "    first_col = \"episode/rule\"\n",
    "    second_col = \"consequent\"\n",
    "    third_col = \"Minimal occurrences\"\n",
    "    forth_col = \"Support\"\n",
    "    fifth_col = \"confidence\"\n",
    "    \n",
    "    first_list = []\n",
    "    second_list = []\n",
    "    third_list = []\n",
    "    forth_list = []\n",
    "    fifth_list = []\n",
    "    \n",
    "    df = pd.DataFrame(columns = [first_col,second_col,third_col,forth_col, fifth_col])\n",
    "    \n",
    "    if len(result) > 0:     \n",
    "        result0 = result[0].replace(\"(\", \"\")\n",
    "        result0 = result0.replace(\")\", \"\")\n",
    "        first_list.append(result0)\n",
    "        result1 = result[1].replace(\"(\", \"\")\n",
    "        result1 = result1.replace(\")\", \"\")\n",
    "        second_list.append(result1)\n",
    "        third_list.append(result[2])\n",
    "        forth_list.append(result[3])\n",
    "        fifth_list.append(result[4])\n",
    "    \n",
    "        data = {first_col:  first_list,\n",
    "                second_col: second_list,\n",
    "                third_col: third_list,\n",
    "                forth_col: forth_list,\n",
    "                fifth_col: fifth_list\n",
    "                }\n",
    "\n",
    "        df = pd.DataFrame (data, columns = [first_col,second_col,third_col,forth_col,fifth_col])\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete packge of MOWCATL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MOWCATL_algorithm(cleaned_data, target_data, min_supp = 15, window_antecedent = 3, window_consequent = 3, lag = 1, conf = 0.1):\n",
    "    \n",
    "    # init all k=1 epsiode\n",
    "    antecedent_L1 = init_all_epsiode(cleaned_data, min_supp)\n",
    "    consequent_L1 = init_all_epsiode(target_data, min_supp)\n",
    "    \n",
    "    # generate all epsiode space\n",
    "    antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count = get_all_epsiodes(cleaned_data, antecedent_L1, min_supp, window_antecedent)\n",
    "    consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count = get_all_epsiodes(target_data, consequent_L1, min_supp, window_consequent)\n",
    "    \n",
    "    # visual initial epsiode space\n",
    "    init_df = create_init_dataframe(antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count,\n",
    "                         consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count)\n",
    "    \n",
    "    # create the combination of epsiode space\n",
    "    antecedent_space_name_order = cleaned_data.columns.values\n",
    "    consequent_space_name_order = target_data.columns.values\n",
    "\n",
    "    ante_Ln = get_space_epsiode_combination(antecedent_item_sets,antecedent_space_name_order)\n",
    "    conse_Ln = get_space_epsiode_combination(consequent_item_sets,consequent_space_name_order)\n",
    "    \n",
    "    # final association rules\n",
    "    result_df = get_confidence(ante_Ln, window_antecedent, cleaned_data, conse_Ln, window_consequent, target_data, min_supp, lag, conf)\n",
    "    \n",
    "    return init_df, result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is  0 col\n",
      "['Bagel'] 19 is support\n",
      "['Bread'] 27 is support\n",
      "['Cheese'] 40 is support\n",
      "this is  1 col\n",
      "['Cheese'] 22 is support\n",
      "['Meat'] 36 is support\n",
      "this is  2 col\n",
      "['Diaper'] 18 is support\n",
      "['Eggs'] 40 is support\n",
      "['Meat'] 19 is support\n",
      "this is  0 col\n",
      "['Cheese'] 18 is support\n",
      "['Milk'] 37 is support\n",
      "['Pencil'] 16 is support\n",
      "begin data space: 0\n",
      "item set candidate: (['Bagel'],)\n",
      "occur in : ['6-6', '8-8', '10-10', '12-12', '13-13', '40-40', '56-56', '58-58', '59-59', '60-60', '84-84', '90-90', '91-91', '102-102', '104-104', '106-106', '108-108', '109-109', '139-139']\n",
      "count : 19\n",
      "item set candidate: (['Bread'],)\n",
      "occur in : ['0-0', '1-1', '7-7', '11-11', '35-35', '37-37', '44-44', '51-51', '62-62', '65-65', '67-67', '74-74', '82-82', '86-86', '87-87', '93-93', '96-96', '97-97', '98-98', '99-99', '100-100', '103-103', '107-107', '132-132', '134-134', '136-136', '142-142']\n",
      "count : 27\n",
      "item set candidate: (['Cheese'],)\n",
      "occur in : ['2-2', '3-3', '9-9', '15-15', '19-19', '22-22', '24-24', '26-26', '27-27', '28-28', '30-30', '31-31', '41-41', '42-42', '48-48', '49-49', '52-52', '53-53', '73-73', '75-75', '77-77', '78-78', '79-79', '85-85', '88-88', '92-92', '105-105', '111-111', '115-115', '117-117', '120-120', '121-121', '123-123', '124-124', '125-125', '127-127', '128-128', '140-140']\n",
      "count : 38\n",
      "begin data space: 1\n",
      "item set candidate: (['Cheese'],)\n",
      "occur in : ['1-1', '12-12', '13-13', '32-32', '34-34', '36-36', '44-44', '45-45', '46-46', '47-47', '57-57', '71-71', '72-72', '80-80', '83-83', '90-90', '93-93', '108-108', '109-109', '129-129', '131-131', '133-133']\n",
      "count : 22\n",
      "item set candidate: (['Meat'],)\n",
      "occur in : ['2-2', '3-3', '9-9', '18-18', '19-19', '20-20', '24-24', '26-26', '27-27', '31-31', '35-35', '41-41', '42-42', '48-48', '50-50', '53-53', '62-62', '69-69', '77-77', '85-85', '88-88', '92-92', '96-96', '105-105', '114-114', '115-115', '116-116', '120-120', '121-121', '123-123', '124-124', '128-128', '132-132', '140-140']\n",
      "count : 34\n",
      "begin data space: 2\n",
      "item set candidate: (['Diaper'],)\n",
      "occur in : ['8-8', '29-29', '34-34', '36-36', '38-38', '40-40', '60-60', '87-87', '97-97', '98-98', '99-99', '100-100', '104-104', '126-126', '131-131', '133-133', '137-137', '139-139']\n",
      "count : 18\n",
      "item set candidate: (['Eggs'],)\n",
      "occur in : ['0-0', '2-2', '3-3', '5-5', '9-9', '17-17', '19-19', '21-21', '24-24', '26-26', '27-27', '31-31', '41-41', '42-42', '48-48', '51-51', '53-53', '56-56', '64-64', '71-71', '77-77', '79-79', '85-85', '88-88', '90-90', '92-92', '95-95', '101-101', '105-105', '113-113', '115-115', '120-120', '121-121', '123-123', '124-124', '128-128', '140-140']\n",
      "count : 37\n",
      "item set candidate: (['Meat'],)\n",
      "occur in : ['1-1', '10-10', '13-13', '28-28', '30-30', '39-39', '52-52', '54-54', '66-66', '67-67', '75-75', '78-78', '80-80', '89-89', '106-106', '109-109', '125-125', '127-127', '138-138']\n",
      "count : 19\n",
      "begin data space: 0\n",
      "item set candidate: (['Cheese'],)\n",
      "occur in : ['5-5', '21-21', '39-39', '40-40', '43-43', '51-51', '58-58', '59-59', '62-62', '64-64', '66-66', '67-67', '68-68', '87-87', '101-101', '118-118', '138-138', '139-139']\n",
      "count : 18\n",
      "item set candidate: (['Milk'],)\n",
      "occur in : ['2-2', '3-3', '7-7', '9-9', '19-19', '24-24', '26-26', '27-27', '31-31', '35-35', '41-41', '42-42', '47-47', '48-48', '53-53', '55-55', '56-56', '72-72', '77-77', '79-79', '85-85', '88-88', '90-90', '91-91', '92-92', '103-103', '105-105', '115-115', '120-120', '121-121', '123-123', '124-124', '128-128', '132-132', '140-140']\n",
      "count : 35\n",
      "item set candidate: (['Pencil'],)\n",
      "occur in : ['4-4', '6-6', '17-17', '20-20', '29-29', '32-32', '37-37', '76-76', '80-80', '84-84', '102-102', '113-113', '116-116', '126-126', '129-129', '134-134']\n",
      "count : 16\n",
      "0 1\n",
      "[(['Bagel'],), (['Bread'],), (['Cheese'],)]\n",
      "[(['Cheese'],), (['Meat'],)]\n",
      "direct merge: {0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Bagel'],), 1: (['Meat'],)}\n",
      "direct merge: {0: (['Bread'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Bread'],), 1: (['Meat'],)}\n",
      "direct merge: {0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Cheese'],), 1: (['Meat'],)}\n",
      "0 2\n",
      "[(['Bagel'],), (['Bread'],), (['Cheese'],)]\n",
      "[(['Diaper'],), (['Eggs'],), (['Meat'],)]\n",
      "direct merge: {0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "direct merge: {0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "direct merge: {0: (['Bagel'],), 2: (['Meat'],)}\n",
      "direct merge: {0: (['Bread'],), 2: (['Diaper'],)}\n",
      "direct merge: {0: (['Bread'],), 2: (['Eggs'],)}\n",
      "direct merge: {0: (['Bread'],), 2: (['Meat'],)}\n",
      "direct merge: {0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "direct merge: {0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "direct merge: {0: (['Cheese'],), 2: (['Meat'],)}\n",
      "1 2\n",
      "[(['Cheese'],), (['Meat'],)]\n",
      "[(['Diaper'],), (['Eggs'],), (['Meat'],)]\n",
      "direct merge: {1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "direct merge: {1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "direct merge: {1: (['Cheese'],), 2: (['Meat'],)}\n",
      "direct merge: {1: (['Meat'],), 2: (['Diaper'],)}\n",
      "direct merge: {1: (['Meat'],), 2: (['Eggs'],)}\n",
      "direct merge: {1: (['Meat'],), 2: (['Meat'],)}\n",
      "=============\n",
      "this round has candidate: 21\n",
      "=============\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Diaper'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Diaper'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Eggs'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Eggs'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Meat'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Meat'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Diaper'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Diaper'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Eggs'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Eggs'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Meat'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Meat'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Diaper'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Diaper'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Eggs'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Eggs'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Meat'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Meat'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "=============\n",
      "this round has candidate: 18\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "df1, df2 = MOWCATL_algorithm(cleaned_data, target_data, min_supp = 15, \n",
    "                             window_antecedent = 3, window_consequent = 3, lag = 1, conf = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode/rule</th>\n",
       "      <th>consequent</th>\n",
       "      <th>Minimal occurrences</th>\n",
       "      <th>Support</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([Bagel],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[6-6, 8-8, 10-10, 12-12, 13-13, 40-40, 56-56, ...</td>\n",
       "      <td>19</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([Bread],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[0-0, 1-1, 7-7, 11-11, 35-35, 37-37, 44-44, 51...</td>\n",
       "      <td>27</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([Cheese],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[2-2, 3-3, 9-9, 15-15, 19-19, 22-22, 24-24, 26...</td>\n",
       "      <td>38</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([Cheese],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[1-1, 12-12, 13-13, 32-32, 34-34, 36-36, 44-44...</td>\n",
       "      <td>22</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([Meat],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[2-2, 3-3, 9-9, 18-18, 19-19, 20-20, 24-24, 26...</td>\n",
       "      <td>34</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([Diaper],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[8-8, 29-29, 34-34, 36-36, 38-38, 40-40, 60-60...</td>\n",
       "      <td>18</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([Eggs],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[0-0, 2-2, 3-3, 5-5, 9-9, 17-17, 19-19, 21-21,...</td>\n",
       "      <td>37</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([Meat],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[1-1, 10-10, 13-13, 28-28, 30-30, 39-39, 52-52...</td>\n",
       "      <td>19</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#</td>\n",
       "      <td>([Cheese],)</td>\n",
       "      <td>[5-5, 21-21, 39-39, 40-40, 43-43, 51-51, 58-58...</td>\n",
       "      <td>18</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#</td>\n",
       "      <td>([Milk],)</td>\n",
       "      <td>[2-2, 3-3, 7-7, 9-9, 19-19, 24-24, 26-26, 27-2...</td>\n",
       "      <td>35</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#</td>\n",
       "      <td>([Pencil],)</td>\n",
       "      <td>[4-4, 6-6, 17-17, 20-20, 29-29, 32-32, 37-37, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  episode/rule   consequent  \\\n",
       "0   ([Bagel],)            #   \n",
       "1   ([Bread],)            #   \n",
       "2  ([Cheese],)            #   \n",
       "3  ([Cheese],)            #   \n",
       "4    ([Meat],)            #   \n",
       "5  ([Diaper],)            #   \n",
       "6    ([Eggs],)            #   \n",
       "7    ([Meat],)            #   \n",
       "0            #  ([Cheese],)   \n",
       "1            #    ([Milk],)   \n",
       "2            #  ([Pencil],)   \n",
       "\n",
       "                                 Minimal occurrences  Support confidence  \n",
       "0  [6-6, 8-8, 10-10, 12-12, 13-13, 40-40, 56-56, ...       19          #  \n",
       "1  [0-0, 1-1, 7-7, 11-11, 35-35, 37-37, 44-44, 51...       27          #  \n",
       "2  [2-2, 3-3, 9-9, 15-15, 19-19, 22-22, 24-24, 26...       38          #  \n",
       "3  [1-1, 12-12, 13-13, 32-32, 34-34, 36-36, 44-44...       22          #  \n",
       "4  [2-2, 3-3, 9-9, 18-18, 19-19, 20-20, 24-24, 26...       34          #  \n",
       "5  [8-8, 29-29, 34-34, 36-36, 38-38, 40-40, 60-60...       18          #  \n",
       "6  [0-0, 2-2, 3-3, 5-5, 9-9, 17-17, 19-19, 21-21,...       37          #  \n",
       "7  [1-1, 10-10, 13-13, 28-28, 30-30, 39-39, 52-52...       19          #  \n",
       "0  [5-5, 21-21, 39-39, 40-40, 43-43, 51-51, 58-58...       18          #  \n",
       "1  [2-2, 3-3, 7-7, 9-9, 19-19, 24-24, 26-26, 27-2...       35          #  \n",
       "2  [4-4, 6-6, 17-17, 20-20, 29-29, 32-32, 37-37, ...       16          #  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode/rule</th>\n",
       "      <th>consequent</th>\n",
       "      <th>Minimal occurrences</th>\n",
       "      <th>Support</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Bagel'],lag1</td>\n",
       "      <td>['Cheese'],</td>\n",
       "      <td>[[6-6, 6-6], [6-6, 6-6], [6-6, 6-6], [40-40, 4...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.468085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Bread'],lag1</td>\n",
       "      <td>['Cheese'],</td>\n",
       "      <td>[[7-7, 7-7], [7-7, 7-7], [37-37, 37-37], [37-3...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.407895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Cheese'],lag1</td>\n",
       "      <td>['Cheese'],</td>\n",
       "      <td>[[2-2, 2-2], [3-3, 3-3], [19-19, 19-19], [19-1...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.273684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Meat'],lag1</td>\n",
       "      <td>['Cheese'],</td>\n",
       "      <td>[[2-2, 2-2], [3-3, 3-3], [18-18, 18-18], [19-1...</td>\n",
       "      <td>33</td>\n",
       "      <td>0.320388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Diaper'],lag1</td>\n",
       "      <td>['Cheese'],</td>\n",
       "      <td>[[8-8, 8-8], [36-36, 36-36], [38-38, 38-38], [...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Cheese'], ['Eggs'],lag1</td>\n",
       "      <td>['Pencil'],</td>\n",
       "      <td>[[1-2, 2-2], [2-2, 2-2], [3-3, 3-3], [6-9, 9-9...</td>\n",
       "      <td>39</td>\n",
       "      <td>0.443182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Cheese'], ['Meat'],lag1</td>\n",
       "      <td>['Pencil'],</td>\n",
       "      <td>[[1-2, 2-2], [26-28, 28-28], [27-28, 28-28], [...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Meat'], ['Diaper'],lag1</td>\n",
       "      <td>['Pencil'],</td>\n",
       "      <td>[[6-9, 9-9], [26-29, 29-29], [27-29, 29-29], [...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Meat'], ['Eggs'],lag1</td>\n",
       "      <td>['Pencil'],</td>\n",
       "      <td>[[1-2, 2-2], [2-2, 2-2], [3-3, 3-3], [6-9, 9-9...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.393258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Cheese'], ['Meat'], ['Eggs'],lag1</td>\n",
       "      <td>['Pencil'],</td>\n",
       "      <td>[[1-2, 2-2], [2-2, 2-2], [3-3, 3-3], [6-9, 9-9...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.426829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            episode/rule    consequent  \\\n",
       "0                         ['Bagel'],lag1   ['Cheese'],   \n",
       "0                         ['Bread'],lag1   ['Cheese'],   \n",
       "0                        ['Cheese'],lag1   ['Cheese'],   \n",
       "0                          ['Meat'],lag1   ['Cheese'],   \n",
       "0                        ['Diaper'],lag1   ['Cheese'],   \n",
       "..                                   ...           ...   \n",
       "0              ['Cheese'], ['Eggs'],lag1   ['Pencil'],   \n",
       "0              ['Cheese'], ['Meat'],lag1   ['Pencil'],   \n",
       "0              ['Meat'], ['Diaper'],lag1   ['Pencil'],   \n",
       "0                ['Meat'], ['Eggs'],lag1   ['Pencil'],   \n",
       "0    ['Cheese'], ['Meat'], ['Eggs'],lag1   ['Pencil'],   \n",
       "\n",
       "                                  Minimal occurrences Support  confidence  \n",
       "0   [[6-6, 6-6], [6-6, 6-6], [6-6, 6-6], [40-40, 4...      22    0.468085  \n",
       "0   [[7-7, 7-7], [7-7, 7-7], [37-37, 37-37], [37-3...      31    0.407895  \n",
       "0   [[2-2, 2-2], [3-3, 3-3], [19-19, 19-19], [19-1...      26    0.273684  \n",
       "0   [[2-2, 2-2], [3-3, 3-3], [18-18, 18-18], [19-1...      33    0.320388  \n",
       "0   [[8-8, 8-8], [36-36, 36-36], [38-38, 38-38], [...      23    0.433962  \n",
       "..                                                ...     ...         ...  \n",
       "0   [[1-2, 2-2], [2-2, 2-2], [3-3, 3-3], [6-9, 9-9...      39    0.443182  \n",
       "0   [[1-2, 2-2], [26-28, 28-28], [27-28, 28-28], [...      18    0.400000  \n",
       "0   [[6-9, 9-9], [26-29, 29-29], [27-29, 29-29], [...      19    0.487179  \n",
       "0   [[1-2, 2-2], [2-2, 2-2], [3-3, 3-3], [6-9, 9-9...      35    0.393258  \n",
       "0   [[1-2, 2-2], [2-2, 2-2], [3-3, 3-3], [6-9, 9-9...      35    0.426829  \n",
       "\n",
       "[62 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
