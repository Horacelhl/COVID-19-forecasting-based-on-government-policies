{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n"
     ]
    }
   ],
   "source": [
    "store_data = pd.read_csv(r\"C:\\Users\\MORPH\\DataSciCov\\store_data.csv\")  #Importing Dataset from system\n",
    "\n",
    "store_data.head()   # to check the header\n",
    "\n",
    "store_data = pd.read_csv(r\"C:\\Users\\MORPH\\DataSciCov\\store_data.csv\", header=None)  #keeping header as None\n",
    "\n",
    "num_records = len(store_data)\n",
    "print(num_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Pencil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meat</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Meat</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>Wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Meat</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Bagel</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Meat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2       3       4       5       6\n",
       "0     Bread    Wine    Eggs    Meat  Cheese  Pencil  Diaper\n",
       "1     Bread  Cheese    Meat  Diaper    Wine    Milk  Pencil\n",
       "2    Cheese    Meat    Eggs    Milk    Wine     NaN     NaN\n",
       "3    Cheese    Meat    Eggs    Milk    Wine     NaN     NaN\n",
       "4      Meat  Pencil    Wine     NaN     NaN     NaN     NaN\n",
       "..      ...     ...     ...     ...     ...     ...     ...\n",
       "310   Bread    Eggs  Cheese     NaN     NaN     NaN     NaN\n",
       "311    Meat    Milk  Pencil     NaN     NaN     NaN     NaN\n",
       "312   Bread  Cheese    Eggs    Meat  Pencil  Diaper    Wine\n",
       "313    Meat  Cheese     NaN     NaN     NaN     NaN     NaN\n",
       "314    Eggs    Wine   Bagel   Bread    Meat     NaN     NaN\n",
       "\n",
       "[315 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i in range(0,num_records):\n",
    "    records.append([str(store_data.values[i,j]) for j in range(0,7)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Bread', 'Wine', 'Eggs', 'Meat', 'Cheese', 'Pencil', 'Diaper'],\n",
       " ['Bread', 'Cheese', 'Meat', 'Diaper', 'Wine', 'Milk', 'Pencil'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Meat', 'Pencil', 'Wine', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Bread', 'Wine', 'Pencil', 'Milk', 'Diaper', 'Bagel'],\n",
       " ['Wine', 'Pencil', 'Eggs', 'Cheese', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Bread', 'Milk', 'Pencil', 'Diaper', 'nan', 'nan'],\n",
       " ['Bread', 'Diaper', 'Cheese', 'Milk', 'Wine', 'Eggs', 'nan'],\n",
       " ['Bagel', 'Wine', 'Diaper', 'Meat', 'Pencil', 'Eggs', 'Cheese'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Bagel', 'Eggs', 'Meat', 'Bread', 'Diaper', 'Wine', 'Milk'],\n",
       " ['Bread', 'Diaper', 'Pencil', 'Bagel', 'Meat', 'nan', 'nan'],\n",
       " ['Bagel', 'Cheese', 'Milk', 'Meat', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Diaper', 'Bagel', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Bagel', 'Bread', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Cheese', 'Meat', 'Bread', 'Diaper', 'Eggs', 'nan'],\n",
       " ['Meat', 'Pencil', 'Cheese', 'Bread', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Eggs', 'Wine', 'Bread', 'Milk', 'Pencil', 'Meat'],\n",
       " ['Eggs', 'Bagel', 'Cheese', 'Meat', 'Diaper', 'nan', 'nan'],\n",
       " ['Diaper', 'Wine', 'Eggs', 'Pencil', 'Meat', 'nan', 'nan'],\n",
       " ['Diaper', 'Meat', 'Milk', 'Bread', 'Bagel', 'Cheese', 'nan'],\n",
       " ['Pencil', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Diaper', 'Meat', 'Bread', 'Pencil', 'Wine', 'Cheese', 'Milk'],\n",
       " ['Bread', 'Bagel', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Bread', 'Eggs', 'Cheese', 'Milk', 'Diaper', 'nan'],\n",
       " ['Diaper', 'Meat', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Bagel', 'Bread', 'Diaper', 'Wine', 'nan', 'nan'],\n",
       " ['Cheese', 'Milk', 'Bread', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Bread', 'Wine', 'Meat', 'Bagel', 'nan', 'nan'],\n",
       " ['Bread', 'Cheese', 'Milk', 'Wine', 'Diaper', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Wine', 'Milk', 'Cheese', 'Pencil', 'Bagel', 'Bread'],\n",
       " ['Bagel', 'Eggs', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Wine', 'Meat', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Bread', 'Bagel', 'Eggs', 'Wine', 'Milk', 'Cheese'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Wine', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Wine', 'Milk', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Bread', 'Bagel', 'Diaper', 'Milk', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Diaper', 'Meat', 'Wine', 'Bread', 'nan', 'nan'],\n",
       " ['Wine', 'Milk', 'Diaper', 'Pencil', 'Cheese', 'Eggs', 'nan'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Diaper', 'Wine', 'Milk', 'Bread'],\n",
       " ['Diaper', 'Eggs', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Wine', 'Cheese', 'Bagel', 'Pencil', 'Bread', 'Meat', 'Diaper'],\n",
       " ['Milk', 'Pencil', 'Cheese', 'Bagel', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Cheese', 'Diaper', 'Wine', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Meat', 'Pencil', 'Milk', 'Wine', 'Diaper', 'nan'],\n",
       " ['Pencil', 'Cheese', 'Diaper', 'Wine', 'Eggs', 'nan', 'nan'],\n",
       " ['Bread', 'Diaper', 'Milk', 'Pencil', 'Cheese', 'Eggs', 'nan'],\n",
       " ['Pencil', 'Milk', 'Cheese', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Bagel', 'Bread', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Bread', 'Cheese', 'Bagel', 'Meat', 'Pencil', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'Diaper', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Bread', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Milk', 'Diaper', 'Eggs', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Milk', 'Meat', 'Cheese', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Cheese', 'Meat', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Wine', 'Eggs', 'Bagel', 'Cheese', 'Pencil', 'Diaper'],\n",
       " ['Diaper', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Milk', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Pencil', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Milk', 'Cheese', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Bagel', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Diaper', 'Wine', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Meat', 'Cheese', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Bagel', 'Pencil', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Eggs', 'Bagel', 'Cheese', 'Wine', 'nan', 'nan'],\n",
       " ['Bread', 'Cheese', 'Wine', 'Bagel', 'Milk', 'Meat', 'nan'],\n",
       " ['Meat', 'Cheese', 'Pencil', 'Wine', 'Bread', 'nan', 'nan'],\n",
       " ['Milk', 'Cheese', 'Wine', 'Bagel', 'Meat', 'Pencil', 'Bread'],\n",
       " ['Pencil', 'Cheese', 'Wine', 'Milk', 'Diaper', 'Bagel', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Diaper', 'Pencil', 'Bagel', 'Wine', 'Meat', 'Eggs'],\n",
       " ['Eggs', 'Meat', 'Wine', 'Bagel', 'Milk', 'Cheese', 'Diaper'],\n",
       " ['Meat', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Diaper', 'Bread', 'Cheese', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Pencil', 'Wine', 'Meat', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Bread', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Milk', 'Eggs', 'Cheese', 'Wine', 'Pencil', 'nan'],\n",
       " ['Cheese', 'Milk', 'Meat', 'Eggs', 'Bagel', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Wine', 'Meat', 'Eggs', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Diaper', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Wine', 'Bread', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Bread', 'Eggs', 'Milk', 'Pencil', 'Meat', 'Wine'],\n",
       " ['Milk', 'Cheese', 'Wine', 'Meat', 'Bagel', 'Diaper', 'Bread'],\n",
       " ['Bagel', 'Diaper', 'Milk', 'Cheese', 'Wine', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Pencil', 'Bread', 'Cheese', 'Eggs', 'nan', 'nan'],\n",
       " ['Bread', 'Eggs', 'Cheese', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Milk', 'Pencil', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Diaper', 'Wine'],\n",
       " ['Meat', 'Cheese', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Wine', 'Bagel', 'Bread', 'Meat', 'nan', 'nan'],\n",
       " ['Bagel', 'Cheese', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Pencil', 'Diaper', 'Wine', 'Meat', 'nan', 'nan'],\n",
       " ['Milk', 'Pencil', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Wine', 'Bagel', 'Eggs', 'Diaper', 'nan', 'nan'],\n",
       " ['Bread', 'Meat', 'Milk', 'Cheese', 'Wine', 'Eggs', 'Pencil'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Bread', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Milk', 'Bagel', 'Wine', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Pencil', 'Meat', 'Eggs', 'Milk', 'Bagel', 'Wine'],\n",
       " ['Cheese', 'Milk', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Pencil', 'Milk', 'Bread', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Bread', 'Wine', 'Diaper', 'Bagel', 'nan', 'nan'],\n",
       " ['Bagel', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Diaper', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Diaper', 'Eggs', 'Cheese', 'Bagel', 'nan', 'nan'],\n",
       " ['Bread', 'Pencil', 'Bagel', 'Eggs', 'nan', 'nan', 'nan'],\n",
       " ['Milk', 'Eggs', 'Meat', 'Cheese', 'Bread', 'Wine', 'Pencil'],\n",
       " ['Pencil', 'Eggs', 'Meat', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Bagel', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Meat', 'Cheese', 'Eggs', 'Pencil', 'nan'],\n",
       " ['Milk', 'Eggs', 'Bread', 'Cheese', 'nan', 'nan', 'nan'],\n",
       " ['Milk', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Meat', 'Bread', 'Bagel', 'Cheese', 'nan', 'nan'],\n",
       " ['Wine', 'Eggs', 'Bread', 'Diaper', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Cheese', 'Eggs', 'Bagel', 'Wine', 'Bread', 'nan'],\n",
       " ['Meat', 'Cheese', 'Bread', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Milk', 'Pencil', 'Eggs', 'Bread', 'Meat', 'nan'],\n",
       " ['Bread', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Eggs', 'Bagel', 'Diaper', 'Milk', 'Meat', 'Pencil'],\n",
       " ['Milk', 'Diaper', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Wine', 'Bagel', 'Diaper', 'Bread'],\n",
       " ['Diaper', 'Bagel', 'Bread', 'Pencil', 'Cheese', 'Milk', 'nan'],\n",
       " ['Diaper', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Wine', 'Meat', 'Bagel', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Diaper', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Cheese', 'Meat', 'Pencil', 'Eggs', 'nan', 'nan'],\n",
       " ['Eggs', 'Bagel', 'Pencil', 'Wine', 'Cheese', 'nan', 'nan'],\n",
       " ['Bagel', 'Diaper', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Eggs', 'Wine', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Milk', 'Pencil', 'Wine', 'Eggs', 'Bagel', 'nan'],\n",
       " ['Milk', 'Bread', 'Bagel', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Eggs', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Cheese', 'Milk', 'Meat', 'Bread', 'Eggs', 'nan'],\n",
       " ['Meat', 'Wine', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Bread', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Eggs', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Milk', 'Wine', 'Pencil', 'Cheese', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Diaper', 'Pencil', 'Bagel', 'Cheese', 'nan', 'nan'],\n",
       " ['Bread', 'Pencil', 'Diaper', 'Cheese', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Bagel', 'Meat', 'Diaper', 'Pencil', 'Milk', 'Bread'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Meat', 'Wine', 'Pencil', 'Bread', 'nan', 'nan'],\n",
       " ['Eggs', 'Cheese', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Pencil', 'Wine', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Milk', 'Eggs', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Cheese', 'Eggs', 'Milk', 'Meat', 'Pencil', 'Bread'],\n",
       " ['Bagel', 'Diaper', 'Pencil', 'Milk', 'Meat', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Bread', 'Wine', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Cheese', 'Milk', 'Diaper', 'Pencil', 'nan', 'nan'],\n",
       " ['Milk', 'Pencil', 'Bagel', 'Wine', 'Eggs', 'Meat', 'nan'],\n",
       " ['Wine', 'Milk', 'Eggs', 'Bread', 'Meat', 'nan', 'nan'],\n",
       " ['Bread', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Diaper', 'Pencil', 'Meat', 'Wine', 'nan', 'nan'],\n",
       " ['Cheese', 'Pencil', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Diaper', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Diaper', 'Wine', 'Bread', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Bread', 'Diaper', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Bagel', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Meat', 'Pencil', 'Eggs', 'Cheese', 'Milk', 'Wine'],\n",
       " ['Bread', 'Wine', 'Diaper', 'Eggs', 'Pencil', 'nan', 'nan'],\n",
       " ['Bread', 'Wine', 'Diaper', 'Eggs', 'Pencil', 'nan', 'nan'],\n",
       " ['Bread', 'Wine', 'Diaper', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Wine', 'Diaper', 'Eggs', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Wine', 'Diaper', 'Eggs', 'Pencil', 'Milk', 'nan'],\n",
       " ['Wine', 'Pencil', 'Eggs', 'Cheese', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Bread', 'Milk', 'Pencil', 'Diaper', 'nan', 'nan'],\n",
       " ['Bread', 'Diaper', 'Cheese', 'Milk', 'Wine', 'Eggs', 'nan'],\n",
       " ['Bagel', 'Wine', 'Diaper', 'Meat', 'Pencil', 'Eggs', 'Cheese'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Bagel', 'Eggs', 'Meat', 'Bread', 'Diaper', 'Wine', 'Milk'],\n",
       " ['Bread', 'Diaper', 'Pencil', 'Bagel', 'Meat', 'nan', 'nan'],\n",
       " ['Bagel', 'Cheese', 'Milk', 'Meat', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Diaper', 'Bagel', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Bagel', 'Bread', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Cheese', 'Meat', 'Bread', 'Diaper', 'Eggs', 'nan'],\n",
       " ['Meat', 'Pencil', 'Cheese', 'Bread', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Eggs', 'Wine', 'Bread', 'Milk', 'Pencil', 'Meat'],\n",
       " ['Eggs', 'Bagel', 'Cheese', 'Meat', 'Diaper', 'nan', 'nan'],\n",
       " ['Diaper', 'Wine', 'Eggs', 'Pencil', 'Meat', 'nan', 'nan'],\n",
       " ['Diaper', 'Meat', 'Milk', 'Bread', 'Bagel', 'Cheese', 'nan'],\n",
       " ['Pencil', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Diaper', 'Meat', 'Bread', 'Pencil', 'Wine', 'Cheese', 'Milk'],\n",
       " ['Bread', 'Bagel', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Bread', 'Eggs', 'Cheese', 'Milk', 'Diaper', 'nan'],\n",
       " ['Diaper', 'Meat', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Bagel', 'Bread', 'Diaper', 'Wine', 'nan', 'nan'],\n",
       " ['Cheese', 'Milk', 'Bread', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Bread', 'Wine', 'Meat', 'Bagel', 'nan', 'nan'],\n",
       " ['Bread', 'Cheese', 'Milk', 'Wine', 'Diaper', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Wine', 'Milk', 'Cheese', 'Pencil', 'Bagel', 'Bread'],\n",
       " ['Bagel', 'Eggs', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Wine', 'Meat', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Bread', 'Bagel', 'Eggs', 'Wine', 'Milk', 'Cheese'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Wine', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Wine', 'Milk', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Bread', 'Bagel', 'Diaper', 'Milk', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Diaper', 'Meat', 'Wine', 'Bread', 'nan', 'nan'],\n",
       " ['Wine', 'Milk', 'Diaper', 'Pencil', 'Cheese', 'Eggs', 'nan'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Diaper', 'Wine', 'Milk', 'Bread'],\n",
       " ['Diaper', 'Eggs', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'Wine', 'nan', 'nan'],\n",
       " ['Wine', 'Cheese', 'Bagel', 'Pencil', 'Bread', 'Meat', 'Diaper'],\n",
       " ['Milk', 'Pencil', 'Cheese', 'Bagel', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Cheese', 'Diaper', 'Wine', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Meat', 'Pencil', 'Milk', 'Wine', 'Diaper', 'nan'],\n",
       " ['Pencil', 'Cheese', 'Diaper', 'Wine', 'Eggs', 'nan', 'nan'],\n",
       " ['Bread', 'Diaper', 'Milk', 'Pencil', 'Cheese', 'Eggs', 'nan'],\n",
       " ['Pencil', 'Milk', 'Cheese', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Bagel', 'Bread', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Bread', 'Cheese', 'Bagel', 'Meat', 'Pencil', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'Diaper', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Bread', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Milk', 'Diaper', 'Eggs', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Milk', 'Meat', 'Cheese', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Cheese', 'Meat', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Wine', 'Eggs', 'Bagel', 'Cheese', 'Pencil', 'Diaper'],\n",
       " ['Diaper', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Milk', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Pencil', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Milk', 'Cheese', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Bagel', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Diaper', 'Wine', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Meat', 'Cheese', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Bagel', 'Pencil', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Eggs', 'Bagel', 'Cheese', 'Wine', 'nan', 'nan'],\n",
       " ['Bread', 'Cheese', 'Wine', 'Bagel', 'Milk', 'Meat', 'nan'],\n",
       " ['Meat', 'Cheese', 'Pencil', 'Wine', 'Bread', 'nan', 'nan'],\n",
       " ['Milk', 'Cheese', 'Wine', 'Bagel', 'Meat', 'Pencil', 'Bread'],\n",
       " ['Pencil', 'Cheese', 'Wine', 'Milk', 'Diaper', 'Bagel', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Cheese', 'Diaper', 'Pencil', 'Bagel', 'Wine', 'Meat', 'Eggs'],\n",
       " ['Eggs', 'Meat', 'Wine', 'Bagel', 'Milk', 'Cheese', 'Diaper'],\n",
       " ['Meat', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Diaper', 'Bread', 'Cheese', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Pencil', 'Wine', 'Meat', 'nan', 'nan', 'nan'],\n",
       " ['Wine', 'Bread', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Milk', 'Eggs', 'Cheese', 'Wine', 'Pencil', 'nan'],\n",
       " ['Cheese', 'Milk', 'Meat', 'Eggs', 'Bagel', 'nan', 'nan'],\n",
       " ['Cheese', 'Meat', 'Eggs', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'Wine', 'Meat', 'Eggs', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Diaper', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Pencil', 'Wine', 'Bread', 'Milk', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Bread', 'Eggs', 'Milk', 'Pencil', 'Meat', 'Wine'],\n",
       " ['Milk', 'Cheese', 'Wine', 'Meat', 'Bagel', 'Diaper', 'Bread'],\n",
       " ['Bagel', 'Diaper', 'Milk', 'Cheese', 'Wine', 'nan', 'nan'],\n",
       " ['Bread', 'Bagel', 'Milk', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Diaper', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bagel', 'Pencil', 'Bread', 'Cheese', 'Eggs', 'nan', 'nan'],\n",
       " ['Bread', 'Eggs', 'Cheese', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Meat', 'Milk', 'Pencil', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Diaper', 'Wine'],\n",
       " ['Meat', 'Cheese', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       " ['Eggs', 'Wine', 'Bagel', 'Bread', 'Meat', 'nan', 'nan']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "RelationRecord(items=frozenset({'Diaper', 'Meat', 'Eggs', 'Cheese', 'Bagel', 'nan', 'Bread'}), support=0.006349206349206349, ordered_statistics=[OrderedStatistic(items_base=frozenset({'Diaper', 'Eggs', 'Bagel', 'nan', 'Bread'}), items_add=frozenset({'Cheese', 'Meat'}), confidence=1.0, lift=3.0882352941176467)])\n"
     ]
    }
   ],
   "source": [
    "association_rules = apriori(records, min_support=0.0045, min_confidence=0.2, min_lift=3, min_length=2)\n",
    "association_results = list(association_rules)\n",
    "\n",
    "print(len(association_results))  #to check the Total Number of Rules mined\n",
    "print(association_results[0])  # to print the first item the association_rules list to see the first rule\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule: Diaper -> Meat\n",
      "Support: 0.006349206349206349\n",
      "Confidence: 1.0\n",
      "Lift: 3.0882352941176467\n",
      "=====================================\n",
      "Rule: Pencil -> Diaper\n",
      "Support: 0.006349206349206349\n",
      "Confidence: 1.0\n",
      "Lift: 3.5795454545454546\n",
      "=====================================\n",
      "Rule: Pencil -> Diaper\n",
      "Support: 0.006349206349206349\n",
      "Confidence: 0.6666666666666666\n",
      "Lift: 3.230769230769231\n",
      "=====================================\n",
      "Rule: Pencil -> Diaper\n",
      "Support: 0.012698412698412698\n",
      "Confidence: 0.2857142857142857\n",
      "Lift: 3.1034482758620685\n",
      "=====================================\n",
      "Rule: Pencil -> Diaper\n",
      "Support: 0.006349206349206349\n",
      "Confidence: 0.5\n",
      "Lift: 3.2142857142857144\n",
      "=====================================\n",
      "Rule: Diaper -> Meat\n",
      "Support: 0.006349206349206349\n",
      "Confidence: 1.0\n",
      "Lift: 4.2\n",
      "=====================================\n",
      "Rule: Pencil -> Diaper\n",
      "Support: 0.009523809523809525\n",
      "Confidence: 1.0\n",
      "Lift: 4.090909090909091\n",
      "=====================================\n",
      "Rule: Pencil -> Diaper\n",
      "Support: 0.006349206349206349\n",
      "Confidence: 1.0\n",
      "Lift: 5.0\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for item in association_results:                                          # to display the rule, the support, the confidence, and lift for each rule in a more clear way:\n",
    "\n",
    "    # first index of the inner list\n",
    "    # Contains base item and add item\n",
    "    pair = item[0] \n",
    "    items = [x for x in pair]\n",
    "    print(\"Rule: \" + items[0] + \" -> \" + items[1])\n",
    "\n",
    "    #second index of the inner list\n",
    "    print(\"Support: \" + str(item[1]))\n",
    "\n",
    "    #third index of the list located at 0th\n",
    "    #of the third index of the inner list\n",
    "\n",
    "    print(\"Confidence: \" + str(item[2][0][2]))\n",
    "    print(\"Lift: \" + str(item[2][0][3]))\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This just using the function provided, next we have to write our own algorithm of apriori, so we can make updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New read function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_data, order = 'null'):\n",
    "    data = []\n",
    "    with open(path_to_data, 'r') as fid:\n",
    "        for lines in fid:\n",
    "            str_line = list(lines.strip().split(','))\n",
    "            _t = list(np.unique(str_line))\n",
    "            _t = list(filter(None, _t))\n",
    "            if order != 'null':\n",
    "                print('test')\n",
    "                _t.sort(key=lambda x:order.index(x)) # make the output follow the order based on its importance\n",
    "            data.append(_t)\n",
    "    return data\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = r\"C:\\Users\\MORPH\\DataSciCov\\store_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = load_data(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Meat', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Eggs', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Milk', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Eggs', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Meat', 'Pencil'],\n",
       " ['Bagel', 'Cheese', 'Meat', 'Milk'],\n",
       " ['Bread'],\n",
       " ['Bagel', 'Diaper', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Meat'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Diaper'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat'],\n",
       " ['Bread', 'Cheese', 'Meat', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Eggs', 'Meat'],\n",
       " ['Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Meat', 'Milk'],\n",
       " ['Pencil'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Diaper', 'Meat'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Meat', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Eggs'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Meat'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Eggs', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Eggs'],\n",
       " ['Diaper', 'Meat', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Milk', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Eggs', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Milk', 'Wine'],\n",
       " ['Diaper'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Milk', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Meat', 'Wine'],\n",
       " ['Cheese', 'Diaper', 'Eggs', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Diaper', 'Eggs'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Milk', 'Pencil'],\n",
       " ['Cheese', 'Diaper', 'Meat', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bread', 'Diaper', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Eggs', 'Milk', 'Pencil'],\n",
       " ['Cheese', 'Milk', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Eggs'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Milk'],\n",
       " ['Bread', 'Eggs'],\n",
       " ['Diaper', 'Eggs', 'Milk', 'Pencil'],\n",
       " ['Cheese', 'Meat', 'Milk', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Meat'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine'],\n",
       " ['Diaper'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Milk'],\n",
       " ['Bread', 'Pencil'],\n",
       " ['Cheese', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Cheese'],\n",
       " ['Diaper', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat'],\n",
       " ['Bagel', 'Meat', 'Pencil'],\n",
       " ['Bagel', 'Cheese', 'Eggs', 'Meat', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Meat'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Pencil'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Wine'],\n",
       " ['Bagel', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Diaper', 'Eggs', 'Meat', 'Wine'],\n",
       " ['Diaper', 'Meat'],\n",
       " ['Bread', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Diaper'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Eggs', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Eggs'],\n",
       " ['Meat', 'Milk', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Meat'],\n",
       " ['Bagel', 'Bread', 'Eggs', 'Meat', 'Wine'],\n",
       " ['Bagel', 'Cheese'],\n",
       " ['Bagel', 'Diaper', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Milk', 'Pencil'],\n",
       " ['Bagel', 'Diaper', 'Eggs', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bread', 'Pencil'],\n",
       " ['Bagel', 'Eggs', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Milk'],\n",
       " ['Bread', 'Diaper', 'Milk', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Diaper'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Meat', 'Wine'],\n",
       " ['Bagel'],\n",
       " ['Diaper', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Eggs', 'Meat'],\n",
       " ['Bagel', 'Bread', 'Eggs', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Eggs', 'Meat', 'Pencil'],\n",
       " ['Bagel', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Milk'],\n",
       " ['Milk'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Meat', 'Pencil'],\n",
       " ['Bread', 'Diaper', 'Eggs', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Eggs', 'Meat', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Meat', 'Milk'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Meat', 'Milk', 'Pencil'],\n",
       " ['Bread'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil'],\n",
       " ['Diaper', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Milk', 'Pencil'],\n",
       " ['Diaper'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bagel', 'Cheese', 'Meat', 'Wine'],\n",
       " ['Cheese', 'Diaper', 'Eggs', 'Milk'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Eggs', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Diaper'],\n",
       " ['Meat'],\n",
       " ['Bread', 'Eggs', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Eggs', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bagel', 'Eggs'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Meat', 'Wine'],\n",
       " ['Bread', 'Wine'],\n",
       " ['Eggs', 'Meat'],\n",
       " ['Bagel', 'Cheese', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Pencil'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bread', 'Diaper', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Eggs'],\n",
       " ['Cheese', 'Pencil', 'Wine'],\n",
       " ['Eggs'],\n",
       " ['Eggs', 'Milk', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Eggs', 'Meat', 'Milk', 'Pencil'],\n",
       " ['Bagel', 'Diaper', 'Meat', 'Milk', 'Pencil'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bread', 'Cheese', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Milk', 'Pencil'],\n",
       " ['Bagel', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bread'],\n",
       " ['Bread', 'Diaper', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Pencil'],\n",
       " ['Bread', 'Diaper'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Wine'],\n",
       " ['Bread', 'Diaper', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bagel', 'Diaper'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Diaper', 'Eggs', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Diaper', 'Eggs', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Diaper', 'Wine'],\n",
       " ['Bread', 'Diaper', 'Eggs', 'Wine'],\n",
       " ['Bread', 'Diaper', 'Eggs', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Milk', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Eggs', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Meat', 'Pencil'],\n",
       " ['Bagel', 'Cheese', 'Meat', 'Milk'],\n",
       " ['Bread'],\n",
       " ['Bagel', 'Diaper', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Meat'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Diaper'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat'],\n",
       " ['Bread', 'Cheese', 'Meat', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Eggs', 'Meat'],\n",
       " ['Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Meat', 'Milk'],\n",
       " ['Pencil'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Diaper', 'Meat'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Meat', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Eggs'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Meat'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Eggs', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Eggs'],\n",
       " ['Diaper', 'Meat', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Milk', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Eggs', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Milk', 'Wine'],\n",
       " ['Diaper'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Milk', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Meat', 'Wine'],\n",
       " ['Cheese', 'Diaper', 'Eggs', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Diaper', 'Eggs'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Milk', 'Pencil'],\n",
       " ['Cheese', 'Diaper', 'Meat', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Bread', 'Diaper', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Eggs', 'Milk', 'Pencil'],\n",
       " ['Cheese', 'Milk', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Eggs'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Diaper', 'Milk'],\n",
       " ['Bread', 'Eggs'],\n",
       " ['Diaper', 'Eggs', 'Milk', 'Pencil'],\n",
       " ['Cheese', 'Meat', 'Milk', 'Pencil'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Meat'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine'],\n",
       " ['Diaper'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Milk'],\n",
       " ['Bread', 'Pencil'],\n",
       " ['Cheese', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Cheese'],\n",
       " ['Diaper', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Eggs', 'Meat'],\n",
       " ['Bagel', 'Meat', 'Pencil'],\n",
       " ['Bagel', 'Cheese', 'Eggs', 'Meat', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Wine'],\n",
       " ['Meat'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Pencil'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Wine'],\n",
       " ['Bagel', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Bread', 'Wine'],\n",
       " ['Bread', 'Cheese', 'Eggs', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Cheese', 'Eggs', 'Meat', 'Milk'],\n",
       " ['Diaper', 'Eggs', 'Meat', 'Wine'],\n",
       " ['Diaper', 'Meat'],\n",
       " ['Bread', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Diaper', 'Meat', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Cheese', 'Diaper', 'Milk', 'Wine'],\n",
       " ['Bagel', 'Bread', 'Milk'],\n",
       " ['Diaper'],\n",
       " ['Bagel', 'Bread', 'Cheese', 'Eggs', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Eggs'],\n",
       " ['Meat', 'Milk', 'Pencil'],\n",
       " ['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine'],\n",
       " ['Cheese', 'Meat'],\n",
       " ['Bagel', 'Bread', 'Eggs', 'Meat', 'Wine']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "RelationRecord(items=frozenset({'Pencil', 'Diaper', 'Meat', 'Eggs', 'Bagel', 'Milk', 'Bread'}), support=0.006349206349206349, ordered_statistics=[OrderedStatistic(items_base=frozenset({'Pencil', 'Diaper', 'Eggs', 'Bagel', 'Milk'}), items_add=frozenset({'Meat', 'Bread'}), confidence=0.6666666666666666, lift=3.230769230769231), OrderedStatistic(items_base=frozenset({'Pencil', 'Diaper', 'Meat', 'Bagel', 'Milk'}), items_add=frozenset({'Eggs', 'Bread'}), confidence=0.6666666666666666, lift=3.559322033898305), OrderedStatistic(items_base=frozenset({'Pencil', 'Diaper', 'Meat', 'Eggs', 'Milk'}), items_add=frozenset({'Bagel', 'Bread'}), confidence=1.0, lift=3.5795454545454546)])\n",
      "=========\n",
      "RelationRecord(items=frozenset({'Pencil', 'Diaper', 'Meat', 'Eggs', 'Cheese', 'Bagel', 'Wine'}), support=0.012698412698412698, ordered_statistics=[OrderedStatistic(items_base=frozenset({'Diaper', 'Pencil', 'Cheese', 'Meat'}), items_add=frozenset({'Eggs', 'Bagel', 'Wine'}), confidence=0.2857142857142857, lift=3.1034482758620685), OrderedStatistic(items_base=frozenset({'Eggs', 'Diaper', 'Pencil', 'Meat'}), items_add=frozenset({'Cheese', 'Bagel', 'Wine'}), confidence=0.36363636363636365, lift=3.3689839572192515), OrderedStatistic(items_base=frozenset({'Pencil', 'Diaper', 'Meat', 'Eggs', 'Cheese'}), items_add=frozenset({'Bagel', 'Wine'}), confidence=0.5714285714285714, lift=3.333333333333333)])\n",
      "=========\n",
      "RelationRecord(items=frozenset({'Pencil', 'Diaper', 'Meat', 'Cheese', 'Milk', 'Bread', 'Wine'}), support=0.009523809523809525, ordered_statistics=[OrderedStatistic(items_base=frozenset({'Pencil', 'Diaper', 'Meat', 'Cheese', 'Milk'}), items_add=frozenset({'Bread', 'Wine'}), confidence=1.0, lift=4.090909090909091)])\n"
     ]
    }
   ],
   "source": [
    "association_rules = apriori(transactions, min_support=0.0045, min_confidence=0.2, min_lift=3, min_length=2)\n",
    "association_results = list(association_rules)\n",
    "\n",
    "print(len(association_results))  #to check the Total Number of Rules mined\n",
    "print(association_results[0])  # to print the first item the association_rules list to see the first rule\n",
    "print(\"=========\")\n",
    "print(association_results[1]) \n",
    "print(\"=========\")\n",
    "print(association_results[2]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the apriori algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_data, order = 'null'):\n",
    "    data = []\n",
    "    with open(path_to_data, 'r') as fid:\n",
    "        for lines in fid:\n",
    "            str_line = list(lines.strip().split(','))\n",
    "            _t = list(np.unique(str_line))           # get all string\n",
    "            _t = list(filter(None, _t))              # just keep not null value\n",
    "            if order != 'null':\n",
    "                print('test')\n",
    "                _t.sort(key=lambda x:order.index(x)) # make the output follow the order based on its importance\n",
    "            data.append(_t)\n",
    "    return data\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurence(item_set, data):\n",
    "    # we need to go over the all data, find how many times the item set is appear.\n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        if set(item_set).issubset(set(data[i])):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent(item_sets, data, min_support, prev_discarded):\n",
    "    L = [] # item sets that are frequent enough\n",
    "    supp_count = [] # count of item sets which are frequent enough\n",
    "    new_discarded = []\n",
    "    num_data = len(data)\n",
    "    k = len(prev_discarded.keys()) \n",
    "    \n",
    "    for s in range(len(item_sets)):\n",
    "        # we need to do two things\n",
    "        # 1. Does item set has any item is already discarded\n",
    "        # 2. calculate the frequence of every item set to see if they are frequent\n",
    "        discarded_before = False # A flag to control logic\n",
    "        if k > 0:\n",
    "            for it in prev_discarded[k]:\n",
    "                if set(it).issubset(set(item_sets[s])):\n",
    "                    discarded_before = True\n",
    "                    break\n",
    "        # by this we confirm only the set has all its element is frequent from previous can proceed to next level.\n",
    "        \n",
    "        if not discarded_before:\n",
    "            count = count_occurence(item_sets[s], data) # for each item set, we want to know how many times it appear\n",
    "            if count/num_data >= min_support:           # then we like to see if this item set is frequent enough\n",
    "                L.append(item_sets[s])                  # if yes, we add to the frequent list, otherwise in discard.\n",
    "                supp_count.append(count)\n",
    "            else:\n",
    "                new_discarded.append(item_sets[s])\n",
    "    \n",
    "    return L, supp_count, new_discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_candidates(data):\n",
    "    my_whole_set = []\n",
    "    for element in data:\n",
    "        for i in range(len(element)):\n",
    "            if element[i] not in my_whole_set:\n",
    "                print(element[i])\n",
    "                my_whole_set.append(element[i])\n",
    "    return  my_whole_set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### key function to get merged item set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_two_item_sets(item1, item2, whole_set):\n",
    "    \n",
    "    # this function is very important \n",
    "    # consider 1,2,3,4,5,6\n",
    "    # when k = 1, it is themself\n",
    "    # when k = 2, it become 12,13,14,15,16,23,24 .........45,46,56.\n",
    "    # when k = 3, it become 12+13 = 123, 12+14 = 124 ..... 13+14 = 134, 13+15 = 135 ....   23+24 = 234 .....\n",
    "    # this is the logic we need to apply here, to make sure the item set are unique\n",
    "    # 1. we need to make sure they are all in order\n",
    "    # 2. we need to compare them, only when they are different in last item, and the item has higher order, we merge them together\n",
    "    # thus 23 + 24 = 234 is legal \n",
    "    # and 13 + 24 = 1234 is not legal here, it suppose to show in k = 4, correctly merge by 123 + 124.\n",
    "    \n",
    "    item1.sort(key = lambda x: whole_set.index(x))\n",
    "    item2.sort(key = lambda x: whole_set.index(x))\n",
    "    \n",
    "    for i in range(len(item1)-1): # check before the last item, if any different, quit.\n",
    "        if item1[i] != item2[i]:\n",
    "            return []\n",
    "    \n",
    "    if whole_set.index(item1[-1]) < whole_set.index(item2[-1]):  # if all item are same before the last item, and the last item in 2 is higher order than 1, we are good to merge\n",
    "        return item1 + [item2[-1]]\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_itemsets(set_of_items, whole_set):\n",
    "    C = []   # return a list of candidates\n",
    "    for i in range(len(set_of_items)):\n",
    "        for j in range(i+1, len(set_of_items)):\n",
    "            it_out = join_two_item_sets(set_of_items[i],set_of_items[j], whole_set) # if these two item are able to join, we will have s joined new item\n",
    "                                                                                    # However it get a chance that we may not be able to join them\n",
    "                                                                                    # then it will return a empty list\n",
    "            if len(it_out) > 0:\n",
    "                C.append(it_out)\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(T, supp_count):\n",
    "    print(\"Item | Frequency count\")\n",
    "    for k in range(len(T)):\n",
    "        print(\"{}:{}\".format(T[k],supp_count[k]))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_candidates(data, min_supp = 0.2):\n",
    "    \n",
    "    C = {}  # the set of all candidates dictionary, based on item set size.\n",
    "            # 1 means the item set only contain 1 item, like \"cheese\"\n",
    "            # 2 means the item set contain 2 item, like \"cheese, beef\"\n",
    "            # etc..\n",
    "            \n",
    "    L = {}  # the actual success candidates dictionary, based on item set size\n",
    "    supp_count_L = {}  # the count for L\n",
    "    \n",
    "    Discard = {1:[]}   # no discard item set at very beginning.\n",
    "    k = 1   # the initial loop, also the single item set.\n",
    "    \n",
    "    # initization all the item and prepare the item set with only 1 item in the set.\n",
    "    my_whole_set = init_candidates(data)\n",
    "    C.update({1 : [[f] for f in my_whole_set]})\n",
    "    \n",
    "    f, sup , new_discard  = get_frequent(C[k], data, min_supp, Discard)\n",
    "    L.update({k: f})\n",
    "    supp_count_L.update({k: sup})\n",
    "    Discard.update({k: new_discard})\n",
    "    \n",
    "    # prepare the item set with more than 1 item in the set, depends on the number of unique elements.\n",
    "    k += 1\n",
    "    convergence = False\n",
    "    while not convergence:\n",
    "        C.update({k: join_itemsets(L[k-1], my_whole_set)})    # why use L[k-1] is really important to understand.\n",
    "                                                              # because join_itemsets work as merging the old L into a new L\n",
    "                                                              # the new L will be smaller in number, but larger in single item set\n",
    "                                                              # eventually, L[k] will become empty.\n",
    "        f, sup , new_discard  = get_frequent(C[k], data, min_supp, Discard)\n",
    "        L.update({k: f})\n",
    "        supp_count_L.update({k: sup})\n",
    "        Discard.update({k: new_discard})\n",
    "        \n",
    "        # checking for C, L\n",
    "        print(\"TABLE C{}:\\n\".format(k))\n",
    "        print_table(C[k], [count_occurence(item,data) for item in C[k]])\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(L[k]) == 0:\n",
    "            convergence = True\n",
    "        else:\n",
    "            print(\"TABLE L{}: \\n\".format(k))\n",
    "            print_table(L[k], supp_count_L[k])\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    return C, L, supp_count_L, Discard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bread\n",
      "Cheese\n",
      "Diaper\n",
      "Eggs\n",
      "Meat\n",
      "Pencil\n",
      "Wine\n",
      "Milk\n",
      "Bagel\n",
      "TABLE C2:\n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese']:75\n",
      "['Bread', 'Diaper']:73\n",
      "['Bread', 'Eggs']:59\n",
      "['Bread', 'Meat']:65\n",
      "['Bread', 'Pencil']:63\n",
      "['Bread', 'Wine']:77\n",
      "['Bread', 'Milk']:88\n",
      "['Bread', 'Bagel']:88\n",
      "['Cheese', 'Diaper']:63\n",
      "['Cheese', 'Eggs']:94\n",
      "['Cheese', 'Meat']:102\n",
      "['Cheese', 'Pencil']:63\n",
      "['Cheese', 'Wine']:85\n",
      "['Cheese', 'Milk']:96\n",
      "['Cheese', 'Bagel']:61\n",
      "['Diaper', 'Eggs']:51\n",
      "['Diaper', 'Meat']:61\n",
      "['Diaper', 'Pencil']:54\n",
      "['Diaper', 'Wine']:74\n",
      "['Diaper', 'Milk']:49\n",
      "['Diaper', 'Bagel']:58\n",
      "['Eggs', 'Meat']:84\n",
      "['Eggs', 'Pencil']:52\n",
      "['Eggs', 'Wine']:76\n",
      "['Eggs', 'Milk']:77\n",
      "['Eggs', 'Bagel']:48\n",
      "['Meat', 'Pencil']:56\n",
      "['Meat', 'Wine']:79\n",
      "['Meat', 'Milk']:77\n",
      "['Meat', 'Bagel']:60\n",
      "['Pencil', 'Wine']:63\n",
      "['Pencil', 'Milk']:54\n",
      "['Pencil', 'Bagel']:50\n",
      "['Wine', 'Milk']:69\n",
      "['Wine', 'Bagel']:54\n",
      "['Milk', 'Bagel']:71\n",
      "\n",
      "\n",
      "\n",
      "TABLE L2: \n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese']:75\n",
      "['Bread', 'Diaper']:73\n",
      "['Bread', 'Eggs']:59\n",
      "['Bread', 'Meat']:65\n",
      "['Bread', 'Pencil']:63\n",
      "['Bread', 'Wine']:77\n",
      "['Bread', 'Milk']:88\n",
      "['Bread', 'Bagel']:88\n",
      "['Cheese', 'Diaper']:63\n",
      "['Cheese', 'Eggs']:94\n",
      "['Cheese', 'Meat']:102\n",
      "['Cheese', 'Pencil']:63\n",
      "['Cheese', 'Wine']:85\n",
      "['Cheese', 'Milk']:96\n",
      "['Cheese', 'Bagel']:61\n",
      "['Diaper', 'Eggs']:51\n",
      "['Diaper', 'Meat']:61\n",
      "['Diaper', 'Pencil']:54\n",
      "['Diaper', 'Wine']:74\n",
      "['Diaper', 'Milk']:49\n",
      "['Diaper', 'Bagel']:58\n",
      "['Eggs', 'Meat']:84\n",
      "['Eggs', 'Pencil']:52\n",
      "['Eggs', 'Wine']:76\n",
      "['Eggs', 'Milk']:77\n",
      "['Eggs', 'Bagel']:48\n",
      "['Meat', 'Pencil']:56\n",
      "['Meat', 'Wine']:79\n",
      "['Meat', 'Milk']:77\n",
      "['Meat', 'Bagel']:60\n",
      "['Pencil', 'Wine']:63\n",
      "['Pencil', 'Milk']:54\n",
      "['Pencil', 'Bagel']:50\n",
      "['Wine', 'Milk']:69\n",
      "['Wine', 'Bagel']:54\n",
      "['Milk', 'Bagel']:71\n",
      "\n",
      "\n",
      "\n",
      "TABLE C3:\n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper']:43\n",
      "['Bread', 'Cheese', 'Eggs']:37\n",
      "['Bread', 'Cheese', 'Meat']:45\n",
      "['Bread', 'Cheese', 'Pencil']:39\n",
      "['Bread', 'Cheese', 'Wine']:45\n",
      "['Bread', 'Cheese', 'Milk']:41\n",
      "['Bread', 'Cheese', 'Bagel']:33\n",
      "['Bread', 'Diaper', 'Eggs']:28\n",
      "['Bread', 'Diaper', 'Meat']:38\n",
      "['Bread', 'Diaper', 'Pencil']:33\n",
      "['Bread', 'Diaper', 'Wine']:47\n",
      "['Bread', 'Diaper', 'Milk']:36\n",
      "['Bread', 'Diaper', 'Bagel']:38\n",
      "['Bread', 'Eggs', 'Meat']:29\n",
      "['Bread', 'Eggs', 'Pencil']:31\n",
      "['Bread', 'Eggs', 'Wine']:38\n",
      "['Bread', 'Eggs', 'Milk']:33\n",
      "['Bread', 'Eggs', 'Bagel']:27\n",
      "['Bread', 'Meat', 'Pencil']:35\n",
      "['Bread', 'Meat', 'Wine']:42\n",
      "['Bread', 'Meat', 'Milk']:33\n",
      "['Bread', 'Meat', 'Bagel']:36\n",
      "['Bread', 'Pencil', 'Wine']:36\n",
      "['Bread', 'Pencil', 'Milk']:34\n",
      "['Bread', 'Pencil', 'Bagel']:28\n",
      "['Bread', 'Wine', 'Milk']:41\n",
      "['Bread', 'Wine', 'Bagel']:32\n",
      "['Bread', 'Milk', 'Bagel']:54\n",
      "['Cheese', 'Diaper', 'Eggs']:32\n",
      "['Cheese', 'Diaper', 'Meat']:36\n",
      "['Cheese', 'Diaper', 'Pencil']:28\n",
      "['Cheese', 'Diaper', 'Wine']:43\n",
      "['Cheese', 'Diaper', 'Milk']:30\n",
      "['Cheese', 'Diaper', 'Bagel']:34\n",
      "['Cheese', 'Eggs', 'Meat']:68\n",
      "['Cheese', 'Eggs', 'Pencil']:34\n",
      "['Cheese', 'Eggs', 'Wine']:52\n",
      "['Cheese', 'Eggs', 'Milk']:62\n",
      "['Cheese', 'Eggs', 'Bagel']:29\n",
      "['Cheese', 'Meat', 'Pencil']:33\n",
      "['Cheese', 'Meat', 'Wine']:53\n",
      "['Cheese', 'Meat', 'Milk']:64\n",
      "['Cheese', 'Meat', 'Bagel']:38\n",
      "['Cheese', 'Pencil', 'Wine']:40\n",
      "['Cheese', 'Pencil', 'Milk']:32\n",
      "['Cheese', 'Pencil', 'Bagel']:28\n",
      "['Cheese', 'Wine', 'Milk']:51\n",
      "['Cheese', 'Wine', 'Bagel']:34\n",
      "['Cheese', 'Milk', 'Bagel']:28\n",
      "['Diaper', 'Eggs', 'Meat']:27\n",
      "['Diaper', 'Eggs', 'Pencil']:26\n",
      "['Diaper', 'Eggs', 'Wine']:35\n",
      "['Diaper', 'Eggs', 'Milk']:23\n",
      "['Diaper', 'Eggs', 'Bagel']:22\n",
      "['Diaper', 'Meat', 'Pencil']:26\n",
      "['Diaper', 'Meat', 'Wine']:39\n",
      "['Diaper', 'Meat', 'Milk']:20\n",
      "['Diaper', 'Meat', 'Bagel']:33\n",
      "['Diaper', 'Pencil', 'Wine']:34\n",
      "['Diaper', 'Pencil', 'Milk']:23\n",
      "['Diaper', 'Pencil', 'Bagel']:26\n",
      "['Diaper', 'Wine', 'Milk']:29\n",
      "['Diaper', 'Wine', 'Bagel']:32\n",
      "['Diaper', 'Milk', 'Bagel']:25\n",
      "['Eggs', 'Meat', 'Pencil']:25\n",
      "['Eggs', 'Meat', 'Wine']:47\n",
      "['Eggs', 'Meat', 'Milk']:56\n",
      "['Eggs', 'Meat', 'Bagel']:29\n",
      "['Eggs', 'Pencil', 'Wine']:38\n",
      "['Eggs', 'Pencil', 'Milk']:27\n",
      "['Eggs', 'Pencil', 'Bagel']:23\n",
      "['Eggs', 'Wine', 'Milk']:43\n",
      "['Eggs', 'Wine', 'Bagel']:29\n",
      "['Eggs', 'Milk', 'Bagel']:20\n",
      "['Meat', 'Pencil', 'Wine']:36\n",
      "['Meat', 'Pencil', 'Milk']:25\n",
      "['Meat', 'Pencil', 'Bagel']:27\n",
      "['Meat', 'Wine', 'Milk']:40\n",
      "['Meat', 'Wine', 'Bagel']:33\n",
      "['Meat', 'Milk', 'Bagel']:24\n",
      "['Pencil', 'Wine', 'Milk']:30\n",
      "['Pencil', 'Wine', 'Bagel']:26\n",
      "['Pencil', 'Milk', 'Bagel']:22\n",
      "['Wine', 'Milk', 'Bagel']:28\n",
      "\n",
      "\n",
      "\n",
      "TABLE L3: \n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper']:43\n",
      "['Bread', 'Cheese', 'Eggs']:37\n",
      "['Bread', 'Cheese', 'Meat']:45\n",
      "['Bread', 'Cheese', 'Pencil']:39\n",
      "['Bread', 'Cheese', 'Wine']:45\n",
      "['Bread', 'Cheese', 'Milk']:41\n",
      "['Bread', 'Cheese', 'Bagel']:33\n",
      "['Bread', 'Diaper', 'Eggs']:28\n",
      "['Bread', 'Diaper', 'Meat']:38\n",
      "['Bread', 'Diaper', 'Pencil']:33\n",
      "['Bread', 'Diaper', 'Wine']:47\n",
      "['Bread', 'Diaper', 'Milk']:36\n",
      "['Bread', 'Diaper', 'Bagel']:38\n",
      "['Bread', 'Eggs', 'Meat']:29\n",
      "['Bread', 'Eggs', 'Pencil']:31\n",
      "['Bread', 'Eggs', 'Wine']:38\n",
      "['Bread', 'Eggs', 'Milk']:33\n",
      "['Bread', 'Eggs', 'Bagel']:27\n",
      "['Bread', 'Meat', 'Pencil']:35\n",
      "['Bread', 'Meat', 'Wine']:42\n",
      "['Bread', 'Meat', 'Milk']:33\n",
      "['Bread', 'Meat', 'Bagel']:36\n",
      "['Bread', 'Pencil', 'Wine']:36\n",
      "['Bread', 'Pencil', 'Milk']:34\n",
      "['Bread', 'Pencil', 'Bagel']:28\n",
      "['Bread', 'Wine', 'Milk']:41\n",
      "['Bread', 'Wine', 'Bagel']:32\n",
      "['Bread', 'Milk', 'Bagel']:54\n",
      "['Cheese', 'Diaper', 'Eggs']:32\n",
      "['Cheese', 'Diaper', 'Meat']:36\n",
      "['Cheese', 'Diaper', 'Pencil']:28\n",
      "['Cheese', 'Diaper', 'Wine']:43\n",
      "['Cheese', 'Diaper', 'Milk']:30\n",
      "['Cheese', 'Diaper', 'Bagel']:34\n",
      "['Cheese', 'Eggs', 'Meat']:68\n",
      "['Cheese', 'Eggs', 'Pencil']:34\n",
      "['Cheese', 'Eggs', 'Wine']:52\n",
      "['Cheese', 'Eggs', 'Milk']:62\n",
      "['Cheese', 'Eggs', 'Bagel']:29\n",
      "['Cheese', 'Meat', 'Pencil']:33\n",
      "['Cheese', 'Meat', 'Wine']:53\n",
      "['Cheese', 'Meat', 'Milk']:64\n",
      "['Cheese', 'Meat', 'Bagel']:38\n",
      "['Cheese', 'Pencil', 'Wine']:40\n",
      "['Cheese', 'Pencil', 'Milk']:32\n",
      "['Cheese', 'Pencil', 'Bagel']:28\n",
      "['Cheese', 'Wine', 'Milk']:51\n",
      "['Cheese', 'Wine', 'Bagel']:34\n",
      "['Cheese', 'Milk', 'Bagel']:28\n",
      "['Diaper', 'Eggs', 'Meat']:27\n",
      "['Diaper', 'Eggs', 'Pencil']:26\n",
      "['Diaper', 'Eggs', 'Wine']:35\n",
      "['Diaper', 'Eggs', 'Milk']:23\n",
      "['Diaper', 'Eggs', 'Bagel']:22\n",
      "['Diaper', 'Meat', 'Pencil']:26\n",
      "['Diaper', 'Meat', 'Wine']:39\n",
      "['Diaper', 'Meat', 'Milk']:20\n",
      "['Diaper', 'Meat', 'Bagel']:33\n",
      "['Diaper', 'Pencil', 'Wine']:34\n",
      "['Diaper', 'Pencil', 'Milk']:23\n",
      "['Diaper', 'Pencil', 'Bagel']:26\n",
      "['Diaper', 'Wine', 'Milk']:29\n",
      "['Diaper', 'Wine', 'Bagel']:32\n",
      "['Diaper', 'Milk', 'Bagel']:25\n",
      "['Eggs', 'Meat', 'Pencil']:25\n",
      "['Eggs', 'Meat', 'Wine']:47\n",
      "['Eggs', 'Meat', 'Milk']:56\n",
      "['Eggs', 'Meat', 'Bagel']:29\n",
      "['Eggs', 'Pencil', 'Wine']:38\n",
      "['Eggs', 'Pencil', 'Milk']:27\n",
      "['Eggs', 'Pencil', 'Bagel']:23\n",
      "['Eggs', 'Wine', 'Milk']:43\n",
      "['Eggs', 'Wine', 'Bagel']:29\n",
      "['Eggs', 'Milk', 'Bagel']:20\n",
      "['Meat', 'Pencil', 'Wine']:36\n",
      "['Meat', 'Pencil', 'Milk']:25\n",
      "['Meat', 'Pencil', 'Bagel']:27\n",
      "['Meat', 'Wine', 'Milk']:40\n",
      "['Meat', 'Wine', 'Bagel']:33\n",
      "['Meat', 'Milk', 'Bagel']:24\n",
      "['Pencil', 'Wine', 'Milk']:30\n",
      "['Pencil', 'Wine', 'Bagel']:26\n",
      "['Pencil', 'Milk', 'Bagel']:22\n",
      "['Wine', 'Milk', 'Bagel']:28\n",
      "\n",
      "\n",
      "\n",
      "TABLE C4:\n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs']:18\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat']:25\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil']:18\n",
      "['Bread', 'Cheese', 'Diaper', 'Wine']:27\n",
      "['Bread', 'Cheese', 'Diaper', 'Milk']:21\n",
      "['Bread', 'Cheese', 'Diaper', 'Bagel']:21\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat']:20\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil']:21\n",
      "['Bread', 'Cheese', 'Eggs', 'Wine']:23\n",
      "['Bread', 'Cheese', 'Eggs', 'Milk']:23\n",
      "['Bread', 'Cheese', 'Eggs', 'Bagel']:14\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil']:25\n",
      "['Bread', 'Cheese', 'Meat', 'Wine']:28\n",
      "['Bread', 'Cheese', 'Meat', 'Milk']:24\n",
      "['Bread', 'Cheese', 'Meat', 'Bagel']:21\n",
      "['Bread', 'Cheese', 'Pencil', 'Wine']:23\n",
      "['Bread', 'Cheese', 'Pencil', 'Milk']:20\n",
      "['Bread', 'Cheese', 'Pencil', 'Bagel']:17\n",
      "['Bread', 'Cheese', 'Wine', 'Milk']:27\n",
      "['Bread', 'Cheese', 'Wine', 'Bagel']:18\n",
      "['Bread', 'Cheese', 'Milk', 'Bagel']:14\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat']:14\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil']:13\n",
      "['Bread', 'Diaper', 'Eggs', 'Wine']:20\n",
      "['Bread', 'Diaper', 'Eggs', 'Milk']:16\n",
      "['Bread', 'Diaper', 'Eggs', 'Bagel']:12\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil']:18\n",
      "['Bread', 'Diaper', 'Meat', 'Wine']:24\n",
      "['Bread', 'Diaper', 'Meat', 'Milk']:17\n",
      "['Bread', 'Diaper', 'Meat', 'Bagel']:22\n",
      "['Bread', 'Diaper', 'Pencil', 'Wine']:18\n",
      "['Bread', 'Diaper', 'Pencil', 'Milk']:16\n",
      "['Bread', 'Diaper', 'Pencil', 'Bagel']:15\n",
      "['Bread', 'Diaper', 'Wine', 'Milk']:21\n",
      "['Bread', 'Diaper', 'Wine', 'Bagel']:20\n",
      "['Bread', 'Diaper', 'Milk', 'Bagel']:18\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil']:15\n",
      "['Bread', 'Eggs', 'Meat', 'Wine']:20\n",
      "['Bread', 'Eggs', 'Meat', 'Milk']:19\n",
      "['Bread', 'Eggs', 'Meat', 'Bagel']:14\n",
      "['Bread', 'Eggs', 'Pencil', 'Wine']:21\n",
      "['Bread', 'Eggs', 'Pencil', 'Milk']:20\n",
      "['Bread', 'Eggs', 'Pencil', 'Bagel']:15\n",
      "['Bread', 'Eggs', 'Wine', 'Milk']:24\n",
      "['Bread', 'Eggs', 'Wine', 'Bagel']:16\n",
      "['Bread', 'Eggs', 'Milk', 'Bagel']:13\n",
      "['Bread', 'Meat', 'Pencil', 'Wine']:23\n",
      "['Bread', 'Meat', 'Pencil', 'Milk']:18\n",
      "['Bread', 'Meat', 'Pencil', 'Bagel']:15\n",
      "['Bread', 'Meat', 'Wine', 'Milk']:24\n",
      "['Bread', 'Meat', 'Wine', 'Bagel']:19\n",
      "['Bread', 'Meat', 'Milk', 'Bagel']:15\n",
      "['Bread', 'Pencil', 'Wine', 'Milk']:23\n",
      "['Bread', 'Pencil', 'Wine', 'Bagel']:12\n",
      "['Bread', 'Pencil', 'Milk', 'Bagel']:14\n",
      "['Bread', 'Wine', 'Milk', 'Bagel']:18\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat']:19\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil']:15\n",
      "['Cheese', 'Diaper', 'Eggs', 'Wine']:22\n",
      "['Cheese', 'Diaper', 'Eggs', 'Milk']:15\n",
      "['Cheese', 'Diaper', 'Eggs', 'Bagel']:16\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil']:14\n",
      "['Cheese', 'Diaper', 'Meat', 'Wine']:23\n",
      "['Cheese', 'Diaper', 'Meat', 'Milk']:13\n",
      "['Cheese', 'Diaper', 'Meat', 'Bagel']:22\n",
      "['Cheese', 'Diaper', 'Pencil', 'Wine']:20\n",
      "['Cheese', 'Diaper', 'Pencil', 'Milk']:11\n",
      "['Cheese', 'Diaper', 'Pencil', 'Bagel']:14\n",
      "['Cheese', 'Diaper', 'Wine', 'Milk']:21\n",
      "['Cheese', 'Diaper', 'Wine', 'Bagel']:21\n",
      "['Cheese', 'Diaper', 'Milk', 'Bagel']:13\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil']:17\n",
      "['Cheese', 'Eggs', 'Meat', 'Wine']:35\n",
      "['Cheese', 'Eggs', 'Meat', 'Milk']:48\n",
      "['Cheese', 'Eggs', 'Meat', 'Bagel']:20\n",
      "['Cheese', 'Eggs', 'Pencil', 'Wine']:27\n",
      "['Cheese', 'Eggs', 'Pencil', 'Milk']:16\n",
      "['Cheese', 'Eggs', 'Pencil', 'Bagel']:14\n",
      "['Cheese', 'Eggs', 'Wine', 'Milk']:33\n",
      "['Cheese', 'Eggs', 'Wine', 'Bagel']:18\n",
      "['Cheese', 'Eggs', 'Milk', 'Bagel']:10\n",
      "['Cheese', 'Meat', 'Pencil', 'Wine']:23\n",
      "['Cheese', 'Meat', 'Pencil', 'Milk']:15\n",
      "['Cheese', 'Meat', 'Pencil', 'Bagel']:14\n",
      "['Cheese', 'Meat', 'Wine', 'Milk']:32\n",
      "['Cheese', 'Meat', 'Wine', 'Bagel']:20\n",
      "['Cheese', 'Meat', 'Milk', 'Bagel']:16\n",
      "['Cheese', 'Pencil', 'Wine', 'Milk']:20\n",
      "['Cheese', 'Pencil', 'Wine', 'Bagel']:17\n",
      "['Cheese', 'Pencil', 'Milk', 'Bagel']:12\n",
      "['Cheese', 'Wine', 'Milk', 'Bagel']:18\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil']:11\n",
      "['Diaper', 'Eggs', 'Meat', 'Wine']:18\n",
      "['Diaper', 'Eggs', 'Meat', 'Milk']:10\n",
      "['Diaper', 'Eggs', 'Meat', 'Bagel']:16\n",
      "['Diaper', 'Eggs', 'Pencil', 'Wine']:20\n",
      "['Diaper', 'Eggs', 'Pencil', 'Milk']:10\n",
      "['Diaper', 'Eggs', 'Pencil', 'Bagel']:10\n",
      "['Diaper', 'Eggs', 'Wine', 'Milk']:14\n",
      "['Diaper', 'Eggs', 'Wine', 'Bagel']:15\n",
      "['Diaper', 'Eggs', 'Milk', 'Bagel']:9\n",
      "['Diaper', 'Meat', 'Pencil', 'Wine']:19\n",
      "['Diaper', 'Meat', 'Pencil', 'Milk']:8\n",
      "['Diaper', 'Meat', 'Pencil', 'Bagel']:14\n",
      "['Diaper', 'Meat', 'Wine', 'Milk']:13\n",
      "['Diaper', 'Meat', 'Wine', 'Bagel']:17\n",
      "['Diaper', 'Meat', 'Milk', 'Bagel']:11\n",
      "['Diaper', 'Pencil', 'Wine', 'Milk']:11\n",
      "['Diaper', 'Pencil', 'Wine', 'Bagel']:13\n",
      "['Diaper', 'Pencil', 'Milk', 'Bagel']:9\n",
      "['Diaper', 'Wine', 'Milk', 'Bagel']:15\n",
      "['Eggs', 'Meat', 'Pencil', 'Wine']:19\n",
      "['Eggs', 'Meat', 'Pencil', 'Milk']:13\n",
      "['Eggs', 'Meat', 'Pencil', 'Bagel']:12\n",
      "['Eggs', 'Meat', 'Wine', 'Milk']:29\n",
      "['Eggs', 'Meat', 'Wine', 'Bagel']:18\n",
      "['Eggs', 'Meat', 'Milk', 'Bagel']:13\n",
      "['Eggs', 'Pencil', 'Wine', 'Milk']:18\n",
      "['Eggs', 'Pencil', 'Wine', 'Bagel']:16\n",
      "['Eggs', 'Pencil', 'Milk', 'Bagel']:11\n",
      "['Eggs', 'Wine', 'Milk', 'Bagel']:15\n",
      "['Meat', 'Pencil', 'Wine', 'Milk']:16\n",
      "['Meat', 'Pencil', 'Wine', 'Bagel']:15\n",
      "['Meat', 'Pencil', 'Milk', 'Bagel']:10\n",
      "['Meat', 'Wine', 'Milk', 'Bagel']:14\n",
      "['Pencil', 'Wine', 'Milk', 'Bagel']:13\n",
      "\n",
      "\n",
      "\n",
      "TABLE L4: \n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs']:18\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat']:25\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil']:18\n",
      "['Bread', 'Cheese', 'Diaper', 'Wine']:27\n",
      "['Bread', 'Cheese', 'Diaper', 'Milk']:21\n",
      "['Bread', 'Cheese', 'Diaper', 'Bagel']:21\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat']:20\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil']:21\n",
      "['Bread', 'Cheese', 'Eggs', 'Wine']:23\n",
      "['Bread', 'Cheese', 'Eggs', 'Milk']:23\n",
      "['Bread', 'Cheese', 'Eggs', 'Bagel']:14\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil']:25\n",
      "['Bread', 'Cheese', 'Meat', 'Wine']:28\n",
      "['Bread', 'Cheese', 'Meat', 'Milk']:24\n",
      "['Bread', 'Cheese', 'Meat', 'Bagel']:21\n",
      "['Bread', 'Cheese', 'Pencil', 'Wine']:23\n",
      "['Bread', 'Cheese', 'Pencil', 'Milk']:20\n",
      "['Bread', 'Cheese', 'Pencil', 'Bagel']:17\n",
      "['Bread', 'Cheese', 'Wine', 'Milk']:27\n",
      "['Bread', 'Cheese', 'Wine', 'Bagel']:18\n",
      "['Bread', 'Cheese', 'Milk', 'Bagel']:14\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat']:14\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil']:13\n",
      "['Bread', 'Diaper', 'Eggs', 'Wine']:20\n",
      "['Bread', 'Diaper', 'Eggs', 'Milk']:16\n",
      "['Bread', 'Diaper', 'Eggs', 'Bagel']:12\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil']:18\n",
      "['Bread', 'Diaper', 'Meat', 'Wine']:24\n",
      "['Bread', 'Diaper', 'Meat', 'Milk']:17\n",
      "['Bread', 'Diaper', 'Meat', 'Bagel']:22\n",
      "['Bread', 'Diaper', 'Pencil', 'Wine']:18\n",
      "['Bread', 'Diaper', 'Pencil', 'Milk']:16\n",
      "['Bread', 'Diaper', 'Pencil', 'Bagel']:15\n",
      "['Bread', 'Diaper', 'Wine', 'Milk']:21\n",
      "['Bread', 'Diaper', 'Wine', 'Bagel']:20\n",
      "['Bread', 'Diaper', 'Milk', 'Bagel']:18\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil']:15\n",
      "['Bread', 'Eggs', 'Meat', 'Wine']:20\n",
      "['Bread', 'Eggs', 'Meat', 'Milk']:19\n",
      "['Bread', 'Eggs', 'Meat', 'Bagel']:14\n",
      "['Bread', 'Eggs', 'Pencil', 'Wine']:21\n",
      "['Bread', 'Eggs', 'Pencil', 'Milk']:20\n",
      "['Bread', 'Eggs', 'Pencil', 'Bagel']:15\n",
      "['Bread', 'Eggs', 'Wine', 'Milk']:24\n",
      "['Bread', 'Eggs', 'Wine', 'Bagel']:16\n",
      "['Bread', 'Eggs', 'Milk', 'Bagel']:13\n",
      "['Bread', 'Meat', 'Pencil', 'Wine']:23\n",
      "['Bread', 'Meat', 'Pencil', 'Milk']:18\n",
      "['Bread', 'Meat', 'Pencil', 'Bagel']:15\n",
      "['Bread', 'Meat', 'Wine', 'Milk']:24\n",
      "['Bread', 'Meat', 'Wine', 'Bagel']:19\n",
      "['Bread', 'Meat', 'Milk', 'Bagel']:15\n",
      "['Bread', 'Pencil', 'Wine', 'Milk']:23\n",
      "['Bread', 'Pencil', 'Wine', 'Bagel']:12\n",
      "['Bread', 'Pencil', 'Milk', 'Bagel']:14\n",
      "['Bread', 'Wine', 'Milk', 'Bagel']:18\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat']:19\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil']:15\n",
      "['Cheese', 'Diaper', 'Eggs', 'Wine']:22\n",
      "['Cheese', 'Diaper', 'Eggs', 'Milk']:15\n",
      "['Cheese', 'Diaper', 'Eggs', 'Bagel']:16\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil']:14\n",
      "['Cheese', 'Diaper', 'Meat', 'Wine']:23\n",
      "['Cheese', 'Diaper', 'Meat', 'Milk']:13\n",
      "['Cheese', 'Diaper', 'Meat', 'Bagel']:22\n",
      "['Cheese', 'Diaper', 'Pencil', 'Wine']:20\n",
      "['Cheese', 'Diaper', 'Pencil', 'Milk']:11\n",
      "['Cheese', 'Diaper', 'Pencil', 'Bagel']:14\n",
      "['Cheese', 'Diaper', 'Wine', 'Milk']:21\n",
      "['Cheese', 'Diaper', 'Wine', 'Bagel']:21\n",
      "['Cheese', 'Diaper', 'Milk', 'Bagel']:13\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil']:17\n",
      "['Cheese', 'Eggs', 'Meat', 'Wine']:35\n",
      "['Cheese', 'Eggs', 'Meat', 'Milk']:48\n",
      "['Cheese', 'Eggs', 'Meat', 'Bagel']:20\n",
      "['Cheese', 'Eggs', 'Pencil', 'Wine']:27\n",
      "['Cheese', 'Eggs', 'Pencil', 'Milk']:16\n",
      "['Cheese', 'Eggs', 'Pencil', 'Bagel']:14\n",
      "['Cheese', 'Eggs', 'Wine', 'Milk']:33\n",
      "['Cheese', 'Eggs', 'Wine', 'Bagel']:18\n",
      "['Cheese', 'Eggs', 'Milk', 'Bagel']:10\n",
      "['Cheese', 'Meat', 'Pencil', 'Wine']:23\n",
      "['Cheese', 'Meat', 'Pencil', 'Milk']:15\n",
      "['Cheese', 'Meat', 'Pencil', 'Bagel']:14\n",
      "['Cheese', 'Meat', 'Wine', 'Milk']:32\n",
      "['Cheese', 'Meat', 'Wine', 'Bagel']:20\n",
      "['Cheese', 'Meat', 'Milk', 'Bagel']:16\n",
      "['Cheese', 'Pencil', 'Wine', 'Milk']:20\n",
      "['Cheese', 'Pencil', 'Wine', 'Bagel']:17\n",
      "['Cheese', 'Pencil', 'Milk', 'Bagel']:12\n",
      "['Cheese', 'Wine', 'Milk', 'Bagel']:18\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil']:11\n",
      "['Diaper', 'Eggs', 'Meat', 'Wine']:18\n",
      "['Diaper', 'Eggs', 'Meat', 'Milk']:10\n",
      "['Diaper', 'Eggs', 'Meat', 'Bagel']:16\n",
      "['Diaper', 'Eggs', 'Pencil', 'Wine']:20\n",
      "['Diaper', 'Eggs', 'Pencil', 'Milk']:10\n",
      "['Diaper', 'Eggs', 'Pencil', 'Bagel']:10\n",
      "['Diaper', 'Eggs', 'Wine', 'Milk']:14\n",
      "['Diaper', 'Eggs', 'Wine', 'Bagel']:15\n",
      "['Diaper', 'Eggs', 'Milk', 'Bagel']:9\n",
      "['Diaper', 'Meat', 'Pencil', 'Wine']:19\n",
      "['Diaper', 'Meat', 'Pencil', 'Milk']:8\n",
      "['Diaper', 'Meat', 'Pencil', 'Bagel']:14\n",
      "['Diaper', 'Meat', 'Wine', 'Milk']:13\n",
      "['Diaper', 'Meat', 'Wine', 'Bagel']:17\n",
      "['Diaper', 'Meat', 'Milk', 'Bagel']:11\n",
      "['Diaper', 'Pencil', 'Wine', 'Milk']:11\n",
      "['Diaper', 'Pencil', 'Wine', 'Bagel']:13\n",
      "['Diaper', 'Pencil', 'Milk', 'Bagel']:9\n",
      "['Diaper', 'Wine', 'Milk', 'Bagel']:15\n",
      "['Eggs', 'Meat', 'Pencil', 'Wine']:19\n",
      "['Eggs', 'Meat', 'Pencil', 'Milk']:13\n",
      "['Eggs', 'Meat', 'Pencil', 'Bagel']:12\n",
      "['Eggs', 'Meat', 'Wine', 'Milk']:29\n",
      "['Eggs', 'Meat', 'Wine', 'Bagel']:18\n",
      "['Eggs', 'Meat', 'Milk', 'Bagel']:13\n",
      "['Eggs', 'Pencil', 'Wine', 'Milk']:18\n",
      "['Eggs', 'Pencil', 'Wine', 'Bagel']:16\n",
      "['Eggs', 'Pencil', 'Milk', 'Bagel']:11\n",
      "['Eggs', 'Wine', 'Milk', 'Bagel']:15\n",
      "['Meat', 'Pencil', 'Wine', 'Milk']:16\n",
      "['Meat', 'Pencil', 'Wine', 'Bagel']:15\n",
      "['Meat', 'Pencil', 'Milk', 'Bagel']:10\n",
      "['Meat', 'Wine', 'Milk', 'Bagel']:14\n",
      "['Pencil', 'Wine', 'Milk', 'Bagel']:13\n",
      "\n",
      "\n",
      "\n",
      "TABLE C5:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat']:10\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil']:7\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Wine']:12\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Milk']:10\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Bagel']:7\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil']:10\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Wine']:15\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Milk']:11\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Bagel']:13\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Wine']:10\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Milk']:7\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Bagel']:8\n",
      "['Bread', 'Cheese', 'Diaper', 'Wine', 'Milk']:13\n",
      "['Bread', 'Cheese', 'Diaper', 'Wine', 'Bagel']:11\n",
      "['Bread', 'Cheese', 'Diaper', 'Milk', 'Bagel']:7\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil']:11\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Wine']:13\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Milk']:12\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Bagel']:6\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Wine']:14\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Milk']:13\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Bagel']:8\n",
      "['Bread', 'Cheese', 'Eggs', 'Wine', 'Milk']:16\n",
      "['Bread', 'Cheese', 'Eggs', 'Wine', 'Bagel']:8\n",
      "['Bread', 'Cheese', 'Eggs', 'Milk', 'Bagel']:5\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Wine']:17\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Milk']:12\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Bagel']:9\n",
      "['Bread', 'Cheese', 'Meat', 'Wine', 'Milk']:17\n",
      "['Bread', 'Cheese', 'Meat', 'Wine', 'Bagel']:10\n",
      "['Bread', 'Cheese', 'Meat', 'Milk', 'Bagel']:9\n",
      "['Bread', 'Cheese', 'Pencil', 'Wine', 'Milk']:14\n",
      "['Bread', 'Cheese', 'Pencil', 'Wine', 'Bagel']:8\n",
      "['Bread', 'Cheese', 'Pencil', 'Milk', 'Bagel']:6\n",
      "['Bread', 'Cheese', 'Wine', 'Milk', 'Bagel']:10\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil']:5\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Wine']:8\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Milk']:8\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Bagel']:7\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Wine']:9\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Milk']:6\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Bagel']:5\n",
      "['Bread', 'Diaper', 'Eggs', 'Wine', 'Milk']:10\n",
      "['Bread', 'Diaper', 'Eggs', 'Wine', 'Bagel']:8\n",
      "['Bread', 'Diaper', 'Eggs', 'Milk', 'Bagel']:7\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Wine']:12\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Milk']:7\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Bagel']:8\n",
      "['Bread', 'Diaper', 'Meat', 'Wine', 'Milk']:11\n",
      "['Bread', 'Diaper', 'Meat', 'Wine', 'Bagel']:10\n",
      "['Bread', 'Diaper', 'Meat', 'Milk', 'Bagel']:8\n",
      "['Bread', 'Diaper', 'Pencil', 'Wine', 'Milk']:7\n",
      "['Bread', 'Diaper', 'Pencil', 'Wine', 'Bagel']:5\n",
      "['Bread', 'Diaper', 'Pencil', 'Milk', 'Bagel']:6\n",
      "['Bread', 'Diaper', 'Wine', 'Milk', 'Bagel']:9\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Wine']:10\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Milk']:11\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Bagel']:6\n",
      "['Bread', 'Eggs', 'Meat', 'Wine', 'Milk']:13\n",
      "['Bread', 'Eggs', 'Meat', 'Wine', 'Bagel']:8\n",
      "['Bread', 'Eggs', 'Meat', 'Milk', 'Bagel']:7\n",
      "['Bread', 'Eggs', 'Pencil', 'Wine', 'Milk']:14\n",
      "['Bread', 'Eggs', 'Pencil', 'Wine', 'Bagel']:8\n",
      "['Bread', 'Eggs', 'Pencil', 'Milk', 'Bagel']:9\n",
      "['Bread', 'Eggs', 'Wine', 'Milk', 'Bagel']:10\n",
      "['Bread', 'Meat', 'Pencil', 'Wine', 'Milk']:14\n",
      "['Bread', 'Meat', 'Pencil', 'Wine', 'Bagel']:6\n",
      "['Bread', 'Meat', 'Pencil', 'Milk', 'Bagel']:7\n",
      "['Bread', 'Meat', 'Wine', 'Milk', 'Bagel']:10\n",
      "['Bread', 'Pencil', 'Wine', 'Milk', 'Bagel']:8\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil']:7\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine']:12\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk']:6\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Bagel']:12\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine']:13\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Milk']:4\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Bagel']:6\n",
      "['Cheese', 'Diaper', 'Eggs', 'Wine', 'Milk']:10\n",
      "['Cheese', 'Diaper', 'Eggs', 'Wine', 'Bagel']:11\n",
      "['Cheese', 'Diaper', 'Eggs', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine']:12\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Milk']:3\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Bagel']:8\n",
      "['Cheese', 'Diaper', 'Meat', 'Wine', 'Milk']:9\n",
      "['Cheese', 'Diaper', 'Meat', 'Wine', 'Bagel']:11\n",
      "['Cheese', 'Diaper', 'Meat', 'Milk', 'Bagel']:6\n",
      "['Cheese', 'Diaper', 'Pencil', 'Wine', 'Milk']:7\n",
      "['Cheese', 'Diaper', 'Pencil', 'Wine', 'Bagel']:10\n",
      "['Cheese', 'Diaper', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Cheese', 'Diaper', 'Wine', 'Milk', 'Bagel']:10\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine']:14\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Milk']:8\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Bagel']:7\n",
      "['Cheese', 'Eggs', 'Meat', 'Wine', 'Milk']:23\n",
      "['Cheese', 'Eggs', 'Meat', 'Wine', 'Bagel']:11\n",
      "['Cheese', 'Eggs', 'Meat', 'Milk', 'Bagel']:6\n",
      "['Cheese', 'Eggs', 'Pencil', 'Wine', 'Milk']:12\n",
      "['Cheese', 'Eggs', 'Pencil', 'Wine', 'Bagel']:10\n",
      "['Cheese', 'Eggs', 'Pencil', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Eggs', 'Wine', 'Milk', 'Bagel']:7\n",
      "['Cheese', 'Meat', 'Pencil', 'Wine', 'Milk']:11\n",
      "['Cheese', 'Meat', 'Pencil', 'Wine', 'Bagel']:9\n",
      "['Cheese', 'Meat', 'Pencil', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Meat', 'Wine', 'Milk', 'Bagel']:9\n",
      "['Cheese', 'Pencil', 'Wine', 'Milk', 'Bagel']:8\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine']:9\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Milk']:2\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Bagel']:6\n",
      "['Diaper', 'Eggs', 'Meat', 'Wine', 'Milk']:6\n",
      "['Diaper', 'Eggs', 'Meat', 'Wine', 'Bagel']:9\n",
      "['Diaper', 'Eggs', 'Meat', 'Milk', 'Bagel']:6\n",
      "['Diaper', 'Eggs', 'Pencil', 'Wine', 'Milk']:4\n",
      "['Diaper', 'Eggs', 'Pencil', 'Wine', 'Bagel']:8\n",
      "['Diaper', 'Eggs', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Diaper', 'Eggs', 'Wine', 'Milk', 'Bagel']:7\n",
      "['Diaper', 'Meat', 'Pencil', 'Wine', 'Milk']:5\n",
      "['Diaper', 'Meat', 'Pencil', 'Wine', 'Bagel']:7\n",
      "['Diaper', 'Meat', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Diaper', 'Meat', 'Wine', 'Milk', 'Bagel']:6\n",
      "['Diaper', 'Pencil', 'Wine', 'Milk', 'Bagel']:3\n",
      "['Eggs', 'Meat', 'Pencil', 'Wine', 'Milk']:9\n",
      "['Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:8\n",
      "['Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:7\n",
      "['Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:8\n",
      "['Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:8\n",
      "['Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:6\n",
      "\n",
      "\n",
      "\n",
      "TABLE L5: \n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat']:10\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil']:7\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Wine']:12\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Milk']:10\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Bagel']:7\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil']:10\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Wine']:15\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Milk']:11\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Bagel']:13\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Wine']:10\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Milk']:7\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Bagel']:8\n",
      "['Bread', 'Cheese', 'Diaper', 'Wine', 'Milk']:13\n",
      "['Bread', 'Cheese', 'Diaper', 'Wine', 'Bagel']:11\n",
      "['Bread', 'Cheese', 'Diaper', 'Milk', 'Bagel']:7\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil']:11\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Wine']:13\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Milk']:12\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Bagel']:6\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Wine']:14\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Milk']:13\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Bagel']:8\n",
      "['Bread', 'Cheese', 'Eggs', 'Wine', 'Milk']:16\n",
      "['Bread', 'Cheese', 'Eggs', 'Wine', 'Bagel']:8\n",
      "['Bread', 'Cheese', 'Eggs', 'Milk', 'Bagel']:5\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Wine']:17\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Milk']:12\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Bagel']:9\n",
      "['Bread', 'Cheese', 'Meat', 'Wine', 'Milk']:17\n",
      "['Bread', 'Cheese', 'Meat', 'Wine', 'Bagel']:10\n",
      "['Bread', 'Cheese', 'Meat', 'Milk', 'Bagel']:9\n",
      "['Bread', 'Cheese', 'Pencil', 'Wine', 'Milk']:14\n",
      "['Bread', 'Cheese', 'Pencil', 'Wine', 'Bagel']:8\n",
      "['Bread', 'Cheese', 'Pencil', 'Milk', 'Bagel']:6\n",
      "['Bread', 'Cheese', 'Wine', 'Milk', 'Bagel']:10\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil']:5\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Wine']:8\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Milk']:8\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Bagel']:7\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Wine']:9\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Milk']:6\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Bagel']:5\n",
      "['Bread', 'Diaper', 'Eggs', 'Wine', 'Milk']:10\n",
      "['Bread', 'Diaper', 'Eggs', 'Wine', 'Bagel']:8\n",
      "['Bread', 'Diaper', 'Eggs', 'Milk', 'Bagel']:7\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Wine']:12\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Milk']:7\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Bagel']:8\n",
      "['Bread', 'Diaper', 'Meat', 'Wine', 'Milk']:11\n",
      "['Bread', 'Diaper', 'Meat', 'Wine', 'Bagel']:10\n",
      "['Bread', 'Diaper', 'Meat', 'Milk', 'Bagel']:8\n",
      "['Bread', 'Diaper', 'Pencil', 'Wine', 'Milk']:7\n",
      "['Bread', 'Diaper', 'Pencil', 'Wine', 'Bagel']:5\n",
      "['Bread', 'Diaper', 'Pencil', 'Milk', 'Bagel']:6\n",
      "['Bread', 'Diaper', 'Wine', 'Milk', 'Bagel']:9\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Wine']:10\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Milk']:11\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Bagel']:6\n",
      "['Bread', 'Eggs', 'Meat', 'Wine', 'Milk']:13\n",
      "['Bread', 'Eggs', 'Meat', 'Wine', 'Bagel']:8\n",
      "['Bread', 'Eggs', 'Meat', 'Milk', 'Bagel']:7\n",
      "['Bread', 'Eggs', 'Pencil', 'Wine', 'Milk']:14\n",
      "['Bread', 'Eggs', 'Pencil', 'Wine', 'Bagel']:8\n",
      "['Bread', 'Eggs', 'Pencil', 'Milk', 'Bagel']:9\n",
      "['Bread', 'Eggs', 'Wine', 'Milk', 'Bagel']:10\n",
      "['Bread', 'Meat', 'Pencil', 'Wine', 'Milk']:14\n",
      "['Bread', 'Meat', 'Pencil', 'Wine', 'Bagel']:6\n",
      "['Bread', 'Meat', 'Pencil', 'Milk', 'Bagel']:7\n",
      "['Bread', 'Meat', 'Wine', 'Milk', 'Bagel']:10\n",
      "['Bread', 'Pencil', 'Wine', 'Milk', 'Bagel']:8\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil']:7\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine']:12\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk']:6\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Bagel']:12\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine']:13\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Milk']:4\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Bagel']:6\n",
      "['Cheese', 'Diaper', 'Eggs', 'Wine', 'Milk']:10\n",
      "['Cheese', 'Diaper', 'Eggs', 'Wine', 'Bagel']:11\n",
      "['Cheese', 'Diaper', 'Eggs', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine']:12\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Milk']:3\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Bagel']:8\n",
      "['Cheese', 'Diaper', 'Meat', 'Wine', 'Milk']:9\n",
      "['Cheese', 'Diaper', 'Meat', 'Wine', 'Bagel']:11\n",
      "['Cheese', 'Diaper', 'Meat', 'Milk', 'Bagel']:6\n",
      "['Cheese', 'Diaper', 'Pencil', 'Wine', 'Milk']:7\n",
      "['Cheese', 'Diaper', 'Pencil', 'Wine', 'Bagel']:10\n",
      "['Cheese', 'Diaper', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Cheese', 'Diaper', 'Wine', 'Milk', 'Bagel']:10\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine']:14\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Milk']:8\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Bagel']:7\n",
      "['Cheese', 'Eggs', 'Meat', 'Wine', 'Milk']:23\n",
      "['Cheese', 'Eggs', 'Meat', 'Wine', 'Bagel']:11\n",
      "['Cheese', 'Eggs', 'Meat', 'Milk', 'Bagel']:6\n",
      "['Cheese', 'Eggs', 'Pencil', 'Wine', 'Milk']:12\n",
      "['Cheese', 'Eggs', 'Pencil', 'Wine', 'Bagel']:10\n",
      "['Cheese', 'Eggs', 'Pencil', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Eggs', 'Wine', 'Milk', 'Bagel']:7\n",
      "['Cheese', 'Meat', 'Pencil', 'Wine', 'Milk']:11\n",
      "['Cheese', 'Meat', 'Pencil', 'Wine', 'Bagel']:9\n",
      "['Cheese', 'Meat', 'Pencil', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Meat', 'Wine', 'Milk', 'Bagel']:9\n",
      "['Cheese', 'Pencil', 'Wine', 'Milk', 'Bagel']:8\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine']:9\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Milk']:2\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Bagel']:6\n",
      "['Diaper', 'Eggs', 'Meat', 'Wine', 'Milk']:6\n",
      "['Diaper', 'Eggs', 'Meat', 'Wine', 'Bagel']:9\n",
      "['Diaper', 'Eggs', 'Meat', 'Milk', 'Bagel']:6\n",
      "['Diaper', 'Eggs', 'Pencil', 'Wine', 'Milk']:4\n",
      "['Diaper', 'Eggs', 'Pencil', 'Wine', 'Bagel']:8\n",
      "['Diaper', 'Eggs', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Diaper', 'Eggs', 'Wine', 'Milk', 'Bagel']:7\n",
      "['Diaper', 'Meat', 'Pencil', 'Wine', 'Milk']:5\n",
      "['Diaper', 'Meat', 'Pencil', 'Wine', 'Bagel']:7\n",
      "['Diaper', 'Meat', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Diaper', 'Meat', 'Wine', 'Milk', 'Bagel']:6\n",
      "['Diaper', 'Pencil', 'Wine', 'Milk', 'Bagel']:3\n",
      "['Eggs', 'Meat', 'Pencil', 'Wine', 'Milk']:9\n",
      "['Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:8\n",
      "['Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:7\n",
      "['Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:8\n",
      "['Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:8\n",
      "['Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:6\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE C6:\n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine']:6\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk']:4\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Bagel']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine']:5\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Milk']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Wine', 'Milk']:6\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Wine', 'Bagel']:5\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine']:8\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Milk']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Wine', 'Milk']:7\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Wine', 'Bagel']:5\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Wine', 'Milk']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Wine', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Milk', 'Bagel']:1\n",
      "['Bread', 'Cheese', 'Diaper', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine']:8\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Milk']:7\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Wine', 'Milk']:8\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Wine', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Milk', 'Bagel']:1\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Wine', 'Milk']:9\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Wine', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Bread', 'Cheese', 'Eggs', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Wine', 'Milk']:10\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Wine', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Bread', 'Cheese', 'Meat', 'Wine', 'Milk', 'Bagel']:6\n",
      "['Bread', 'Cheese', 'Pencil', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine']:3\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Milk']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Milk']:4\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Bagel']:3\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Milk']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Bagel']:3\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Bread', 'Diaper', 'Eggs', 'Wine', 'Milk', 'Bagel']:5\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Milk']:5\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Meat', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Diaper', 'Pencil', 'Wine', 'Milk', 'Bagel']:1\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk']:7\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:2\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:5\n",
      "['Bread', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:6\n",
      "['Bread', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine']:7\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Milk']:0\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Milk']:4\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Bagel']:7\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Bagel']:2\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Milk']:2\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Bagel']:6\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Milk', 'Bagel']:0\n",
      "['Cheese', 'Diaper', 'Eggs', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Milk']:3\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Bagel']:6\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Milk', 'Bagel']:0\n",
      "['Cheese', 'Diaper', 'Meat', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Pencil', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk']:6\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:5\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:2\n",
      "['Cheese', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:3\n",
      "['Cheese', 'Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:3\n",
      "['Cheese', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:3\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk']:0\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:4\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:2\n",
      "['Diaper', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Diaper', 'Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:1\n",
      "['Diaper', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:0\n",
      "['Eggs', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:4\n",
      "\n",
      "\n",
      "\n",
      "TABLE L6: \n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine']:6\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk']:4\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Bagel']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine']:5\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Milk']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Wine', 'Milk']:6\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Wine', 'Bagel']:5\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine']:8\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Milk']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Wine', 'Milk']:7\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Wine', 'Bagel']:5\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Wine', 'Milk']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Wine', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Diaper', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine']:8\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Milk']:7\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Wine', 'Milk']:8\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Wine', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Wine', 'Milk']:9\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Wine', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Bread', 'Cheese', 'Eggs', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Wine', 'Milk']:10\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Wine', 'Bagel']:4\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Bread', 'Cheese', 'Meat', 'Wine', 'Milk', 'Bagel']:6\n",
      "['Bread', 'Cheese', 'Pencil', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine']:3\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Milk']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Milk']:4\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Bagel']:3\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Milk']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Bagel']:3\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Milk', 'Bagel']:3\n",
      "['Bread', 'Diaper', 'Eggs', 'Wine', 'Milk', 'Bagel']:5\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Milk']:5\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Meat', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk']:7\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:2\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:5\n",
      "['Bread', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Bread', 'Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:6\n",
      "['Bread', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine']:7\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Milk']:4\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Bagel']:7\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Bagel']:2\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Milk']:2\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Bagel']:6\n",
      "['Cheese', 'Diaper', 'Eggs', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Milk']:3\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Bagel']:6\n",
      "['Cheese', 'Diaper', 'Meat', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Pencil', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk']:6\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:5\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:2\n",
      "['Cheese', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:3\n",
      "['Cheese', 'Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:3\n",
      "['Cheese', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:3\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:4\n",
      "['Diaper', 'Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:2\n",
      "['Diaper', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:4\n",
      "['Eggs', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:4\n",
      "\n",
      "\n",
      "\n",
      "TABLE C7:\n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Milk']:0\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Bagel']:0\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Milk']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Bagel']:1\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Bagel']:0\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Milk']:0\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Milk', 'Bagel']:0\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Milk']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Milk', 'Bagel']:0\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Pencil', 'Wine', 'Milk', 'Bagel']:0\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk']:5\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:0\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:1\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:0\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk']:0\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:0\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:1\n",
      "['Bread', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:0\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:0\n",
      "['Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:0\n",
      "['Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:1\n",
      "\n",
      "\n",
      "\n",
      "TABLE L7: \n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Milk']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Pencil', 'Wine', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Eggs', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Milk']:3\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk']:5\n",
      "['Bread', 'Cheese', 'Eggs', 'Pencil', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Cheese', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Bread', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:2\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Pencil', 'Wine', 'Bagel']:4\n",
      "['Cheese', 'Diaper', 'Eggs', 'Meat', 'Wine', 'Milk', 'Bagel']:2\n",
      "\n",
      "\n",
      "\n",
      "TABLE C8:\n",
      "\n",
      "Item | Frequency count\n",
      "['Bread', 'Cheese', 'Diaper', 'Meat', 'Pencil', 'Wine', 'Milk', 'Bagel']:0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " C, L, supp_count_L, Discard = create_candidates(transactions, 0.0045)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "\n",
    "def powerset(s):\n",
    "    return list(chain.from_iterable(combinations(s,r) for r in range(1,len(s)+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_rule(variable_no_target,target,confidence,lift,sup_x,num_data):\n",
    "    out_rules = \"\"\n",
    "    out_rules += \"Rule:{} -> {} \\n\".format(list(variable_no_target), list(target))\n",
    "    out_rules += \"confidence:{0:2.3f} \\n\".format(confidence)\n",
    "    out_rules += \"support:{0:2.3f} \\n\".format(sup_x / num_data)\n",
    "    out_rules += \"lift:{0:2.3f} \\n\".format(lift)\n",
    "    return out_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_rule(L, data, min_cofidence = 0.2, min_support = 0.2, min_lift = 1):\n",
    "    num_data = len(data)\n",
    "    assoc_rule_str = \"\"\n",
    "    for i in range(1, len(L)):\n",
    "        for j in range(len(L[i])):\n",
    "            s = powerset(set(L[i][j]))\n",
    "            s.pop()\n",
    "            for z in s:\n",
    "                target = set(z)\n",
    "                #print(\"======\")\n",
    "                #print(target)\n",
    "                variable = set(L[i][j])   # be careful, traditional rule is already take target inside the variable\n",
    "                #print(variable)\n",
    "                #print(\"======\")\n",
    "                variable_no_target = set(variable-target) # thus we need this step to find the pure variable condiiton and take measurement\n",
    "                sup_x = count_occurence(variable, data)             # after add target\n",
    "                sup_x_s = count_occurence(variable_no_target, data) # before add target\n",
    "                sup_s = count_occurence(target, data)               # target\n",
    "                confidence = sup_x / sup_x_s                       # after / before\n",
    "                lift = confidence / (sup_s / num_data)\n",
    "                \n",
    "                if confidence >= min_cofidence and sup_x >= min_support:\n",
    "                    if lift > min_lift:\n",
    "                        assoc_rule_str += write_rule(variable_no_target,target,confidence,lift,sup_x, num_data)\n",
    "    return assoc_rule_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule:['Pencil', 'Cheese', 'Milk', 'Diaper', 'Meat'] -> ['Bread', 'Wine'] \n",
      "confidence:1.000 \n",
      "support:0.010 \n",
      "lift:4.091 \n",
      "Rule:['Eggs', 'Pencil', 'Bagel', 'Milk', 'Diaper'] -> ['Meat', 'Bread'] \n",
      "confidence:0.667 \n",
      "support:0.006 \n",
      "lift:3.231 \n",
      "Rule:['Pencil', 'Bagel', 'Milk', 'Diaper', 'Meat'] -> ['Eggs', 'Bread'] \n",
      "confidence:0.667 \n",
      "support:0.006 \n",
      "lift:3.559 \n",
      "Rule:['Eggs', 'Pencil', 'Milk', 'Diaper', 'Meat'] -> ['Bagel', 'Bread'] \n",
      "confidence:1.000 \n",
      "support:0.006 \n",
      "lift:3.580 \n",
      "Rule:['Eggs', 'Pencil', 'Cheese', 'Diaper', 'Meat'] -> ['Bagel', 'Wine'] \n",
      "confidence:0.571 \n",
      "support:0.013 \n",
      "lift:3.333 \n",
      "Rule:['Diaper', 'Pencil', 'Cheese', 'Meat'] -> ['Eggs', 'Bagel', 'Wine'] \n",
      "confidence:0.286 \n",
      "support:0.013 \n",
      "lift:3.103 \n",
      "Rule:['Diaper', 'Pencil', 'Meat', 'Eggs'] -> ['Cheese', 'Bagel', 'Wine'] \n",
      "confidence:0.364 \n",
      "support:0.013 \n",
      "lift:3.369 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (association_rule(L,transactions, min_lift = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result from python package:\n",
    "\n",
    "'Meat', 'Milk', 'Diaper', 'Cheese', 'Pencil'}), items_add=frozenset({'Wine', 'Bread'}), confidence=1.0, lift=4.090909090909091)])\n",
    "\n",
    "Excellent, we get it done correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the MOWCATL algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOWCATL stands for Minimal Occurrences With Constraints And Time Lags algorithm.\n",
    "\n",
    "This is efficient method for mining fre-quent sequential association rules from multiple sequential data sets witha time lag between the occurrence of an antecedent sequence and thecorresponding consequent sequence.\n",
    "\n",
    "publication can be seen here: (2002)\n",
    "https://www.researchgate.net/publication/2542553_Discovering_Sequential_Association_Rules_with_Constraints_and_Time_Lags_in_Multiple_Sequences/link/0912f5097e177d3ec4000000/download\n",
    "\n",
    "Original implementation from C++ from:\n",
    "https://github.com/vivin/geoevent/blob/43aa6d04717d97a7ad1a32ae600904fe03623cc8/DRBARMS/documentation.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Generate Antecedent Target Episodes of length 1 (ATE1;B);\n",
    "\n",
    "2) Generate Consequent Target Episodes of length 1 (CTE1;B);\n",
    "\n",
    "3) Input sequence S, record occurrences of ATE1;B and CTE1;B episodes;\n",
    "\n",
    "4) Prune unsupported episodes from ATE1;B and CTE1;B;\n",
    "\n",
    "5) k = 1;\n",
    "\n",
    "6) while (ATEk;B 6= ;) do\n",
    "\n",
    "    7) Generate Antecedent Target Episodes ATEk+1;B from ATEk;B\n",
    "\n",
    "    8) Record each minimal occurrence of the episodes less than wina;\n",
    "\n",
    "    9) Prune the unsupported episodes from ATEk+1;B;\n",
    "\n",
    "    10) k++;\n",
    "\n",
    "11) Repeat or execute in parallel, Steps 5 - 11 for consequent episodes, using CTEk+1;B and winc;\n",
    "\n",
    "12) Generate combination episodes CEB from ATEB \u0002 CTEB;\n",
    "\n",
    "13) Record the combination's minimal occurrences that occur within lag;\n",
    "\n",
    "14) Return the supported lagged episode rules in CEB that meet the min conf threshold;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "store_data = pd.read_csv(r\"C:\\Users\\MORPH\\DataSciCov\\store_data2.csv\")  #Importing Dataset from system\n",
    "\n",
    "store_data.head()   # to check the header\n",
    "\n",
    "store_data = pd.read_csv(r\"C:\\Users\\MORPH\\DataSciCov\\store_data2.csv\", header=None)  #keeping header as None\n",
    "\n",
    "num_records = len(store_data)\n",
    "print(num_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Bagel</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2\n",
       "0     Bread    Wine    Eggs\n",
       "1     Bread  Cheese    Meat\n",
       "2    Cheese    Meat    Eggs\n",
       "3    Cheese    Meat    Eggs\n",
       "4      Eggs   Bread    Wine\n",
       "..      ...     ...     ...\n",
       "139   Bagel   Bread  Diaper\n",
       "140  Cheese    Meat    Eggs\n",
       "141  Cheese    Meat    Eggs\n",
       "142   Bread    Wine    Eggs\n",
       "143  Cheese    Meat    Eggs\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = store_data[[0,1,2]]\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meat</td>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Pencil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Diaper</td>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1\n",
       "0      Eggs    Meat\n",
       "1      Meat  Diaper\n",
       "2      Eggs    Milk\n",
       "3      Eggs    Milk\n",
       "4      Wine  Pencil\n",
       "..      ...     ...\n",
       "139  Diaper  Cheese\n",
       "140    Eggs    Milk\n",
       "141    Eggs    Milk\n",
       "142    Eggs   Bagel\n",
       "143    Eggs    Milk\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = store_data[[2,3]]\n",
    "target_data.columns = [0,1]\n",
    "target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Antecedent Target Episodes of length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_supp = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def init_all_epsiode(data, min_supp):\n",
    "    \n",
    "    all_antecedent_list = {}\n",
    "    for i in range(len(data.columns)):\n",
    "        print(\"this is \", i, \"col\")\n",
    "        antecedent_list = init_epsiode(data[[i]], min_supp)\n",
    "        temp = [antecedent_list]\n",
    "        all_antecedent_list.update({i : temp})\n",
    "    \n",
    "    return all_antecedent_list\n",
    "\n",
    "\n",
    "def init_epsiode(data, min_supp):\n",
    "    \n",
    "    antecedent_list = []\n",
    "    \n",
    "    GC_list = data.values\n",
    "    GC_list = list(itertools.chain.from_iterable(GC_list))\n",
    "\n",
    "    _t = list(np.unique(GC_list))   \n",
    "    \n",
    "    for item in _t:\n",
    "        #print(item)\n",
    "        item = [item]\n",
    "        count = init_count(item, GC_list)\n",
    "        if count > min_supp:\n",
    "            antecedent_list.append(item)\n",
    "            print(item,count, \"is support\" )\n",
    "       \n",
    "    return antecedent_list\n",
    "\n",
    "\n",
    "def init_count(item_set, data):\n",
    "    # we need to go over the all data, find how many times the item set is appear.\n",
    "    #print(data)\n",
    "    count = 0\n",
    "    for i in range(len(item_set)):\n",
    "        for j in range(len(data)):\n",
    "\n",
    "            #print(set(item_set), set([data[j]]))\n",
    "            #print(set(item_set).issubset(set(data[j])))\n",
    "\n",
    "            if set(item_set).issubset(set([data[j]])):\n",
    "                count += 1\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is  0 col\n",
      "['Bagel'] 19 is support\n",
      "['Bread'] 27 is support\n",
      "['Cheese'] 40 is support\n",
      "this is  1 col\n",
      "['Cheese'] 22 is support\n",
      "['Meat'] 36 is support\n",
      "this is  2 col\n",
      "['Diaper'] 18 is support\n",
      "['Eggs'] 40 is support\n",
      "['Meat'] 19 is support\n"
     ]
    }
   ],
   "source": [
    "antecedent_L1 = init_all_epsiode(cleaned_data, min_supp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[['Bagel'], ['Bread'], ['Cheese']]],\n",
       " 1: [[['Cheese'], ['Meat']]],\n",
       " 2: [[['Diaper'], ['Eggs'], ['Meat']]]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antecedent_L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### same for init the consequent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is  0 col\n",
      "['Diaper'] 18 is support\n",
      "['Eggs'] 40 is support\n",
      "['Meat'] 19 is support\n",
      "this is  1 col\n",
      "['Cheese'] 18 is support\n",
      "['Milk'] 37 is support\n",
      "['Pencil'] 16 is support\n"
     ]
    }
   ],
   "source": [
    "consequent_L1 = init_all_epsiode(target_data, min_supp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[['Diaper'], ['Eggs'], ['Meat']]],\n",
       " 1: [[['Cheese'], ['Milk'], ['Pencil']]]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consequent_L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the all combination of each space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "\n",
    "def powerset(s):\n",
    "    return list(chain.from_iterable(combinations(s,r) for r in range(1,len(s)+1)))\n",
    "\n",
    "def get_all_epsiodes(data, L1_item_sets, min_supp, window):\n",
    "    \n",
    "    item_sets = {}\n",
    "    item_sets_occurences = {}\n",
    "    item_sets_count = {}\n",
    "    \n",
    "    # get data\n",
    "    # know how many space\n",
    "    # do one space each time, along with its item_set\n",
    "    length = len(data.columns)\n",
    "    for i in range(length):\n",
    "        print(\"begin data space:\", i)\n",
    "        #print(data[[i]])\n",
    "        #print(L1_item_sets[i])\n",
    "        item_set, item_occurence, item_count = check_epsiode(data[[i]], L1_item_sets[i], min_supp, window)\n",
    "        # update dict\n",
    "        item_sets.update({i: item_set})\n",
    "        item_sets_occurences.update({i : item_occurence})\n",
    "        item_sets_count.update({i : item_count})\n",
    "    \n",
    "    return item_sets, item_sets_occurences, item_sets_count\n",
    "\n",
    "\n",
    "def check_epsiode(data, L1_item_set, min_supp, window):\n",
    "    \n",
    "    item_set = []\n",
    "    item_occurence = []\n",
    "    item_count = []\n",
    "    # first generate all combination\n",
    "    # pop the combination one by one\n",
    "    # count if it meet the min_supp\n",
    "    s = powerset(L1_item_set[0])\n",
    "    s.pop()\n",
    "    \n",
    "    for z in s:\n",
    "        #print(z)\n",
    "        count, min_occurences = count_epsiode(data, z, window)\n",
    "        if count > min_supp:\n",
    "            print(\"item set candidate:\", z)\n",
    "            print(\"occur in :\", min_occurences)\n",
    "            print(\"count :\", count)\n",
    "            # add this item to list\n",
    "            # add its occurences to list\n",
    "            # add its count to list\n",
    "            item_set.append(z)\n",
    "            item_occurence.append(min_occurences)\n",
    "            item_count.append(count)\n",
    "   \n",
    "    return item_set, item_occurence, item_count\n",
    "\n",
    "def count_epsiode(data, item, window):\n",
    "    \n",
    "    count = 0\n",
    "    minimal_occurences = []\n",
    "    \n",
    "    if len(item) <= window :     \n",
    "    \n",
    "        # count epsiode\n",
    "        # also record its minimal occurences\n",
    "        # when the item not larger than window, process it\n",
    "        for i in range(len(data)- window):\n",
    "            find, begin, end = sequence_check(data, i, item, window)\n",
    "            if find:\n",
    "                occur = \"{}-{}\".format(begin, end)\n",
    "                if minimal_occurences.count(occur) == 0 :\n",
    "                    # new position found for this epsiode\n",
    "                    minimal_occurences.append(occur)\n",
    "                    count += 1\n",
    "                \n",
    "    return count, minimal_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sequence_check(data, start_index, item, window):\n",
    "    # we will try to find every item in epsiode inside the search window\n",
    "    item_mark = len(item)\n",
    "    item_flag = 0\n",
    "    begin_position = 0\n",
    "    end_position = 0\n",
    "    \n",
    "    #print(\"item to check \", item, item_mark)\n",
    "    locol_data = data.copy()\n",
    "    locol_data.columns = [0]\n",
    "    \n",
    "    for i in range(start_index, start_index + window):\n",
    "        #print(i)\n",
    "        #print(locol_data.iloc[i][0], item[item_flag][0])\n",
    "        if locol_data.iloc[i][0] == item[item_flag][0]:\n",
    "            if begin_position == 0:\n",
    "                begin_position = i\n",
    "                end_position = i\n",
    "            else:\n",
    "                end_position = i\n",
    "            item_flag += 1\n",
    "            \n",
    "            if item_flag == item_mark:\n",
    "                # this means we find all item in epsiode\n",
    "                return True,begin_position, end_position\n",
    "    \n",
    "    return False, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_antecedent = 3\n",
    "window_consequent = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin data space: 0\n",
      "item set candidate: (['Bagel'],)\n",
      "occur in : ['6-6', '8-8', '10-10', '12-12', '13-13', '40-40', '56-56', '58-58', '59-59', '60-60', '84-84', '90-90', '91-91', '102-102', '104-104', '106-106', '108-108', '109-109', '139-139']\n",
      "count : 19\n",
      "item set candidate: (['Bread'],)\n",
      "occur in : ['0-0', '1-1', '7-7', '11-11', '35-35', '37-37', '44-44', '51-51', '62-62', '65-65', '67-67', '74-74', '82-82', '86-86', '87-87', '93-93', '96-96', '97-97', '98-98', '99-99', '100-100', '103-103', '107-107', '132-132', '134-134', '136-136', '142-142']\n",
      "count : 27\n",
      "item set candidate: (['Cheese'],)\n",
      "occur in : ['2-2', '3-3', '9-9', '15-15', '19-19', '22-22', '24-24', '26-26', '27-27', '28-28', '30-30', '31-31', '41-41', '42-42', '48-48', '49-49', '52-52', '53-53', '73-73', '75-75', '77-77', '78-78', '79-79', '85-85', '88-88', '92-92', '105-105', '111-111', '115-115', '117-117', '120-120', '121-121', '123-123', '124-124', '125-125', '127-127', '128-128', '140-140']\n",
      "count : 38\n",
      "begin data space: 1\n",
      "item set candidate: (['Cheese'],)\n",
      "occur in : ['1-1', '12-12', '13-13', '32-32', '34-34', '36-36', '44-44', '45-45', '46-46', '47-47', '57-57', '71-71', '72-72', '80-80', '83-83', '90-90', '93-93', '108-108', '109-109', '129-129', '131-131', '133-133']\n",
      "count : 22\n",
      "item set candidate: (['Meat'],)\n",
      "occur in : ['2-2', '3-3', '9-9', '18-18', '19-19', '20-20', '24-24', '26-26', '27-27', '31-31', '35-35', '41-41', '42-42', '48-48', '50-50', '53-53', '62-62', '69-69', '77-77', '85-85', '88-88', '92-92', '96-96', '105-105', '114-114', '115-115', '116-116', '120-120', '121-121', '123-123', '124-124', '128-128', '132-132', '140-140']\n",
      "count : 34\n",
      "begin data space: 2\n",
      "item set candidate: (['Diaper'],)\n",
      "occur in : ['8-8', '29-29', '34-34', '36-36', '38-38', '40-40', '60-60', '87-87', '97-97', '98-98', '99-99', '100-100', '104-104', '126-126', '131-131', '133-133', '137-137', '139-139']\n",
      "count : 18\n",
      "item set candidate: (['Eggs'],)\n",
      "occur in : ['0-0', '2-2', '3-3', '5-5', '9-9', '17-17', '19-19', '21-21', '24-24', '26-26', '27-27', '31-31', '41-41', '42-42', '48-48', '51-51', '53-53', '56-56', '64-64', '71-71', '77-77', '79-79', '85-85', '88-88', '90-90', '92-92', '95-95', '101-101', '105-105', '113-113', '115-115', '120-120', '121-121', '123-123', '124-124', '128-128', '140-140']\n",
      "count : 37\n",
      "item set candidate: (['Meat'],)\n",
      "occur in : ['1-1', '10-10', '13-13', '28-28', '30-30', '39-39', '52-52', '54-54', '66-66', '67-67', '75-75', '78-78', '80-80', '89-89', '106-106', '109-109', '125-125', '127-127', '138-138']\n",
      "count : 19\n"
     ]
    }
   ],
   "source": [
    "antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count = get_all_epsiodes(cleaned_data, antecedent_L1, min_supp, window_antecedent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(['Bagel'],), (['Bread'],), (['Cheese'],)],\n",
       " 1: [(['Cheese'],), (['Meat'],)],\n",
       " 2: [(['Diaper'],), (['Eggs'],), (['Meat'],)]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antecedent_item_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [['6-6',\n",
       "   '8-8',\n",
       "   '10-10',\n",
       "   '12-12',\n",
       "   '13-13',\n",
       "   '40-40',\n",
       "   '56-56',\n",
       "   '58-58',\n",
       "   '59-59',\n",
       "   '60-60',\n",
       "   '84-84',\n",
       "   '90-90',\n",
       "   '91-91',\n",
       "   '102-102',\n",
       "   '104-104',\n",
       "   '106-106',\n",
       "   '108-108',\n",
       "   '109-109',\n",
       "   '139-139'],\n",
       "  ['0-0',\n",
       "   '1-1',\n",
       "   '7-7',\n",
       "   '11-11',\n",
       "   '35-35',\n",
       "   '37-37',\n",
       "   '44-44',\n",
       "   '51-51',\n",
       "   '62-62',\n",
       "   '65-65',\n",
       "   '67-67',\n",
       "   '74-74',\n",
       "   '82-82',\n",
       "   '86-86',\n",
       "   '87-87',\n",
       "   '93-93',\n",
       "   '96-96',\n",
       "   '97-97',\n",
       "   '98-98',\n",
       "   '99-99',\n",
       "   '100-100',\n",
       "   '103-103',\n",
       "   '107-107',\n",
       "   '132-132',\n",
       "   '134-134',\n",
       "   '136-136',\n",
       "   '142-142'],\n",
       "  ['2-2',\n",
       "   '3-3',\n",
       "   '9-9',\n",
       "   '15-15',\n",
       "   '19-19',\n",
       "   '22-22',\n",
       "   '24-24',\n",
       "   '26-26',\n",
       "   '27-27',\n",
       "   '28-28',\n",
       "   '30-30',\n",
       "   '31-31',\n",
       "   '41-41',\n",
       "   '42-42',\n",
       "   '48-48',\n",
       "   '49-49',\n",
       "   '52-52',\n",
       "   '53-53',\n",
       "   '73-73',\n",
       "   '75-75',\n",
       "   '77-77',\n",
       "   '78-78',\n",
       "   '79-79',\n",
       "   '85-85',\n",
       "   '88-88',\n",
       "   '92-92',\n",
       "   '105-105',\n",
       "   '111-111',\n",
       "   '115-115',\n",
       "   '117-117',\n",
       "   '120-120',\n",
       "   '121-121',\n",
       "   '123-123',\n",
       "   '124-124',\n",
       "   '125-125',\n",
       "   '127-127',\n",
       "   '128-128',\n",
       "   '140-140']],\n",
       " 1: [['1-1',\n",
       "   '12-12',\n",
       "   '13-13',\n",
       "   '32-32',\n",
       "   '34-34',\n",
       "   '36-36',\n",
       "   '44-44',\n",
       "   '45-45',\n",
       "   '46-46',\n",
       "   '47-47',\n",
       "   '57-57',\n",
       "   '71-71',\n",
       "   '72-72',\n",
       "   '80-80',\n",
       "   '83-83',\n",
       "   '90-90',\n",
       "   '93-93',\n",
       "   '108-108',\n",
       "   '109-109',\n",
       "   '129-129',\n",
       "   '131-131',\n",
       "   '133-133'],\n",
       "  ['2-2',\n",
       "   '3-3',\n",
       "   '9-9',\n",
       "   '18-18',\n",
       "   '19-19',\n",
       "   '20-20',\n",
       "   '24-24',\n",
       "   '26-26',\n",
       "   '27-27',\n",
       "   '31-31',\n",
       "   '35-35',\n",
       "   '41-41',\n",
       "   '42-42',\n",
       "   '48-48',\n",
       "   '50-50',\n",
       "   '53-53',\n",
       "   '62-62',\n",
       "   '69-69',\n",
       "   '77-77',\n",
       "   '85-85',\n",
       "   '88-88',\n",
       "   '92-92',\n",
       "   '96-96',\n",
       "   '105-105',\n",
       "   '114-114',\n",
       "   '115-115',\n",
       "   '116-116',\n",
       "   '120-120',\n",
       "   '121-121',\n",
       "   '123-123',\n",
       "   '124-124',\n",
       "   '128-128',\n",
       "   '132-132',\n",
       "   '140-140']],\n",
       " 2: [['8-8',\n",
       "   '29-29',\n",
       "   '34-34',\n",
       "   '36-36',\n",
       "   '38-38',\n",
       "   '40-40',\n",
       "   '60-60',\n",
       "   '87-87',\n",
       "   '97-97',\n",
       "   '98-98',\n",
       "   '99-99',\n",
       "   '100-100',\n",
       "   '104-104',\n",
       "   '126-126',\n",
       "   '131-131',\n",
       "   '133-133',\n",
       "   '137-137',\n",
       "   '139-139'],\n",
       "  ['0-0',\n",
       "   '2-2',\n",
       "   '3-3',\n",
       "   '5-5',\n",
       "   '9-9',\n",
       "   '17-17',\n",
       "   '19-19',\n",
       "   '21-21',\n",
       "   '24-24',\n",
       "   '26-26',\n",
       "   '27-27',\n",
       "   '31-31',\n",
       "   '41-41',\n",
       "   '42-42',\n",
       "   '48-48',\n",
       "   '51-51',\n",
       "   '53-53',\n",
       "   '56-56',\n",
       "   '64-64',\n",
       "   '71-71',\n",
       "   '77-77',\n",
       "   '79-79',\n",
       "   '85-85',\n",
       "   '88-88',\n",
       "   '90-90',\n",
       "   '92-92',\n",
       "   '95-95',\n",
       "   '101-101',\n",
       "   '105-105',\n",
       "   '113-113',\n",
       "   '115-115',\n",
       "   '120-120',\n",
       "   '121-121',\n",
       "   '123-123',\n",
       "   '124-124',\n",
       "   '128-128',\n",
       "   '140-140'],\n",
       "  ['1-1',\n",
       "   '10-10',\n",
       "   '13-13',\n",
       "   '28-28',\n",
       "   '30-30',\n",
       "   '39-39',\n",
       "   '52-52',\n",
       "   '54-54',\n",
       "   '66-66',\n",
       "   '67-67',\n",
       "   '75-75',\n",
       "   '78-78',\n",
       "   '80-80',\n",
       "   '89-89',\n",
       "   '106-106',\n",
       "   '109-109',\n",
       "   '125-125',\n",
       "   '127-127',\n",
       "   '138-138']]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antecedent_item_sets_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [19, 27, 38], 1: [22, 34], 2: [18, 37, 19]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antecedent_item_sets_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we do the same for consequent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin data space: 0\n",
      "item set candidate: (['Diaper'],)\n",
      "occur in : ['8-8', '29-29', '34-34', '36-36', '38-38', '40-40', '60-60', '87-87', '97-97', '98-98', '99-99', '100-100', '104-104', '126-126', '131-131', '133-133', '137-137', '139-139']\n",
      "count : 18\n",
      "item set candidate: (['Eggs'],)\n",
      "occur in : ['0-0', '2-2', '3-3', '5-5', '9-9', '17-17', '19-19', '21-21', '24-24', '26-26', '27-27', '31-31', '41-41', '42-42', '48-48', '51-51', '53-53', '56-56', '64-64', '71-71', '77-77', '79-79', '85-85', '88-88', '90-90', '92-92', '95-95', '101-101', '105-105', '113-113', '115-115', '120-120', '121-121', '123-123', '124-124', '128-128', '140-140']\n",
      "count : 37\n",
      "item set candidate: (['Meat'],)\n",
      "occur in : ['1-1', '10-10', '13-13', '28-28', '30-30', '39-39', '52-52', '54-54', '66-66', '67-67', '75-75', '78-78', '80-80', '89-89', '106-106', '109-109', '125-125', '127-127', '138-138']\n",
      "count : 19\n",
      "begin data space: 1\n",
      "item set candidate: (['Cheese'],)\n",
      "occur in : ['5-5', '21-21', '39-39', '40-40', '43-43', '51-51', '58-58', '59-59', '62-62', '64-64', '66-66', '67-67', '68-68', '87-87', '101-101', '118-118', '138-138', '139-139']\n",
      "count : 18\n",
      "item set candidate: (['Milk'],)\n",
      "occur in : ['2-2', '3-3', '7-7', '9-9', '19-19', '24-24', '26-26', '27-27', '31-31', '35-35', '41-41', '42-42', '47-47', '48-48', '53-53', '55-55', '56-56', '72-72', '77-77', '79-79', '85-85', '88-88', '90-90', '91-91', '92-92', '103-103', '105-105', '115-115', '120-120', '121-121', '123-123', '124-124', '128-128', '132-132', '140-140']\n",
      "count : 35\n",
      "item set candidate: (['Pencil'],)\n",
      "occur in : ['4-4', '6-6', '17-17', '20-20', '29-29', '32-32', '37-37', '76-76', '80-80', '84-84', '102-102', '113-113', '116-116', '126-126', '129-129', '134-134']\n",
      "count : 16\n"
     ]
    }
   ],
   "source": [
    "consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count = get_all_epsiodes(target_data, consequent_L1, min_supp, window_consequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(['Diaper'],), (['Eggs'],), (['Meat'],)],\n",
       " 1: [(['Cheese'],), (['Milk'],), (['Pencil'],)]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consequent_item_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [['8-8',\n",
       "   '29-29',\n",
       "   '34-34',\n",
       "   '36-36',\n",
       "   '38-38',\n",
       "   '40-40',\n",
       "   '60-60',\n",
       "   '87-87',\n",
       "   '97-97',\n",
       "   '98-98',\n",
       "   '99-99',\n",
       "   '100-100',\n",
       "   '104-104',\n",
       "   '126-126',\n",
       "   '131-131',\n",
       "   '133-133',\n",
       "   '137-137',\n",
       "   '139-139'],\n",
       "  ['0-0',\n",
       "   '2-2',\n",
       "   '3-3',\n",
       "   '5-5',\n",
       "   '9-9',\n",
       "   '17-17',\n",
       "   '19-19',\n",
       "   '21-21',\n",
       "   '24-24',\n",
       "   '26-26',\n",
       "   '27-27',\n",
       "   '31-31',\n",
       "   '41-41',\n",
       "   '42-42',\n",
       "   '48-48',\n",
       "   '51-51',\n",
       "   '53-53',\n",
       "   '56-56',\n",
       "   '64-64',\n",
       "   '71-71',\n",
       "   '77-77',\n",
       "   '79-79',\n",
       "   '85-85',\n",
       "   '88-88',\n",
       "   '90-90',\n",
       "   '92-92',\n",
       "   '95-95',\n",
       "   '101-101',\n",
       "   '105-105',\n",
       "   '113-113',\n",
       "   '115-115',\n",
       "   '120-120',\n",
       "   '121-121',\n",
       "   '123-123',\n",
       "   '124-124',\n",
       "   '128-128',\n",
       "   '140-140'],\n",
       "  ['1-1',\n",
       "   '10-10',\n",
       "   '13-13',\n",
       "   '28-28',\n",
       "   '30-30',\n",
       "   '39-39',\n",
       "   '52-52',\n",
       "   '54-54',\n",
       "   '66-66',\n",
       "   '67-67',\n",
       "   '75-75',\n",
       "   '78-78',\n",
       "   '80-80',\n",
       "   '89-89',\n",
       "   '106-106',\n",
       "   '109-109',\n",
       "   '125-125',\n",
       "   '127-127',\n",
       "   '138-138']],\n",
       " 1: [['5-5',\n",
       "   '21-21',\n",
       "   '39-39',\n",
       "   '40-40',\n",
       "   '43-43',\n",
       "   '51-51',\n",
       "   '58-58',\n",
       "   '59-59',\n",
       "   '62-62',\n",
       "   '64-64',\n",
       "   '66-66',\n",
       "   '67-67',\n",
       "   '68-68',\n",
       "   '87-87',\n",
       "   '101-101',\n",
       "   '118-118',\n",
       "   '138-138',\n",
       "   '139-139'],\n",
       "  ['2-2',\n",
       "   '3-3',\n",
       "   '7-7',\n",
       "   '9-9',\n",
       "   '19-19',\n",
       "   '24-24',\n",
       "   '26-26',\n",
       "   '27-27',\n",
       "   '31-31',\n",
       "   '35-35',\n",
       "   '41-41',\n",
       "   '42-42',\n",
       "   '47-47',\n",
       "   '48-48',\n",
       "   '53-53',\n",
       "   '55-55',\n",
       "   '56-56',\n",
       "   '72-72',\n",
       "   '77-77',\n",
       "   '79-79',\n",
       "   '85-85',\n",
       "   '88-88',\n",
       "   '90-90',\n",
       "   '91-91',\n",
       "   '92-92',\n",
       "   '103-103',\n",
       "   '105-105',\n",
       "   '115-115',\n",
       "   '120-120',\n",
       "   '121-121',\n",
       "   '123-123',\n",
       "   '124-124',\n",
       "   '128-128',\n",
       "   '132-132',\n",
       "   '140-140'],\n",
       "  ['4-4',\n",
       "   '6-6',\n",
       "   '17-17',\n",
       "   '20-20',\n",
       "   '29-29',\n",
       "   '32-32',\n",
       "   '37-37',\n",
       "   '76-76',\n",
       "   '80-80',\n",
       "   '84-84',\n",
       "   '102-102',\n",
       "   '113-113',\n",
       "   '116-116',\n",
       "   '126-126',\n",
       "   '129-129',\n",
       "   '134-134']]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consequent_item_sets_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [18, 37, 19], 1: [18, 35, 16]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consequent_item_sets_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_init_dataframe(antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count,\n",
    "                         consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count):\n",
    "    \n",
    "    df1 = create_init_ante_dataframe(antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count)\n",
    "    df2 = create_init_conse_dataframe(consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count)\n",
    "    df_final = pd.concat([df1, df2])\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "def create_init_ante_dataframe(antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count):\n",
    "    \n",
    "    first_col = \"episode/rule\"\n",
    "    second_col = \"consequent\"\n",
    "    third_col = \"Minimal occurrences\"\n",
    "    forth_col = \"Support\"\n",
    "    fifth_col = \"confidence\"\n",
    "    \n",
    "    first_list = []\n",
    "    second_list = []\n",
    "    third_list = []\n",
    "    forth_list = []\n",
    "    fifth_list = []\n",
    "    \n",
    "    df = pd.DataFrame(columns = [first_col,second_col,third_col,forth_col, fifth_col])\n",
    "    \n",
    "    if len(antecedent_item_sets) > 0:\n",
    "\n",
    "        for k,v in  antecedent_item_sets.items():\n",
    "            \n",
    "            #print(k, v)\n",
    "            #print(len(v))\n",
    "            \n",
    "            for i in range(len(v)):\n",
    "                first_list.append(v[i])\n",
    "                second_list.append(\"#\")\n",
    "                third_list.append(antecedent_item_sets_occurences[k][i])\n",
    "                forth_list.append(antecedent_item_sets_count[k][i])\n",
    "                fifth_list.append(\"#\")\n",
    "    \n",
    "        data = {first_col:  first_list,\n",
    "                second_col: second_list,\n",
    "                third_col: third_list,\n",
    "                forth_col: forth_list,\n",
    "                fifth_col: fifth_list\n",
    "                }\n",
    "\n",
    "        df = pd.DataFrame (data, columns = [first_col,second_col,third_col,forth_col,fifth_col])\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_init_conse_dataframe(consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count):\n",
    "    first_col = \"episode/rule\"\n",
    "    second_col = \"consequent\"\n",
    "    third_col = \"Minimal occurrences\"\n",
    "    forth_col = \"Support\"\n",
    "    fifth_col = \"confidence\"\n",
    "    \n",
    "    first_list = []\n",
    "    second_list = []\n",
    "    third_list = []\n",
    "    forth_list = []\n",
    "    fifth_list = []\n",
    "    \n",
    "    df = pd.DataFrame(columns = [first_col,second_col,third_col,forth_col,fifth_col])\n",
    "    \n",
    "    if len(consequent_item_sets) > 0:\n",
    "\n",
    "        for k,v in  consequent_item_sets.items():\n",
    "            \n",
    "            #print(k, v)\n",
    "            #print(len(v))\n",
    "            \n",
    "            for i in range(len(v)):\n",
    "                first_list.append(\"#\")\n",
    "                second_list.append(v[i])\n",
    "                third_list.append(consequent_item_sets_occurences[k][i])\n",
    "                forth_list.append(consequent_item_sets_count[k][i])\n",
    "                fifth_list.append(\"#\")\n",
    "    \n",
    "        data = {first_col:  first_list,\n",
    "                second_col: second_list,\n",
    "                third_col: third_list,\n",
    "                forth_col: forth_list,\n",
    "                fifth_col: fifth_list\n",
    "                }\n",
    "\n",
    "        df = pd.DataFrame (data, columns = [first_col,second_col,third_col,forth_col,fifth_col])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode/rule</th>\n",
       "      <th>consequent</th>\n",
       "      <th>Minimal occurrences</th>\n",
       "      <th>Support</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([Bagel],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[6-6, 8-8, 10-10, 12-12, 13-13, 40-40, 56-56, ...</td>\n",
       "      <td>19</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([Bread],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[0-0, 1-1, 7-7, 11-11, 35-35, 37-37, 44-44, 51...</td>\n",
       "      <td>27</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([Cheese],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[2-2, 3-3, 9-9, 15-15, 19-19, 22-22, 24-24, 26...</td>\n",
       "      <td>38</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([Cheese],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[1-1, 12-12, 13-13, 32-32, 34-34, 36-36, 44-44...</td>\n",
       "      <td>22</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([Meat],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[2-2, 3-3, 9-9, 18-18, 19-19, 20-20, 24-24, 26...</td>\n",
       "      <td>34</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([Diaper],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[8-8, 29-29, 34-34, 36-36, 38-38, 40-40, 60-60...</td>\n",
       "      <td>18</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([Eggs],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[0-0, 2-2, 3-3, 5-5, 9-9, 17-17, 19-19, 21-21,...</td>\n",
       "      <td>37</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([Meat],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[1-1, 10-10, 13-13, 28-28, 30-30, 39-39, 52-52...</td>\n",
       "      <td>19</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#</td>\n",
       "      <td>([Diaper],)</td>\n",
       "      <td>[8-8, 29-29, 34-34, 36-36, 38-38, 40-40, 60-60...</td>\n",
       "      <td>18</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#</td>\n",
       "      <td>([Eggs],)</td>\n",
       "      <td>[0-0, 2-2, 3-3, 5-5, 9-9, 17-17, 19-19, 21-21,...</td>\n",
       "      <td>37</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#</td>\n",
       "      <td>([Meat],)</td>\n",
       "      <td>[1-1, 10-10, 13-13, 28-28, 30-30, 39-39, 52-52...</td>\n",
       "      <td>19</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#</td>\n",
       "      <td>([Cheese],)</td>\n",
       "      <td>[5-5, 21-21, 39-39, 40-40, 43-43, 51-51, 58-58...</td>\n",
       "      <td>18</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#</td>\n",
       "      <td>([Milk],)</td>\n",
       "      <td>[2-2, 3-3, 7-7, 9-9, 19-19, 24-24, 26-26, 27-2...</td>\n",
       "      <td>35</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#</td>\n",
       "      <td>([Pencil],)</td>\n",
       "      <td>[4-4, 6-6, 17-17, 20-20, 29-29, 32-32, 37-37, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  episode/rule   consequent  \\\n",
       "0   ([Bagel],)            #   \n",
       "1   ([Bread],)            #   \n",
       "2  ([Cheese],)            #   \n",
       "3  ([Cheese],)            #   \n",
       "4    ([Meat],)            #   \n",
       "5  ([Diaper],)            #   \n",
       "6    ([Eggs],)            #   \n",
       "7    ([Meat],)            #   \n",
       "0            #  ([Diaper],)   \n",
       "1            #    ([Eggs],)   \n",
       "2            #    ([Meat],)   \n",
       "3            #  ([Cheese],)   \n",
       "4            #    ([Milk],)   \n",
       "5            #  ([Pencil],)   \n",
       "\n",
       "                                 Minimal occurrences  Support confidence  \n",
       "0  [6-6, 8-8, 10-10, 12-12, 13-13, 40-40, 56-56, ...       19          #  \n",
       "1  [0-0, 1-1, 7-7, 11-11, 35-35, 37-37, 44-44, 51...       27          #  \n",
       "2  [2-2, 3-3, 9-9, 15-15, 19-19, 22-22, 24-24, 26...       38          #  \n",
       "3  [1-1, 12-12, 13-13, 32-32, 34-34, 36-36, 44-44...       22          #  \n",
       "4  [2-2, 3-3, 9-9, 18-18, 19-19, 20-20, 24-24, 26...       34          #  \n",
       "5  [8-8, 29-29, 34-34, 36-36, 38-38, 40-40, 60-60...       18          #  \n",
       "6  [0-0, 2-2, 3-3, 5-5, 9-9, 17-17, 19-19, 21-21,...       37          #  \n",
       "7  [1-1, 10-10, 13-13, 28-28, 30-30, 39-39, 52-52...       19          #  \n",
       "0  [8-8, 29-29, 34-34, 36-36, 38-38, 40-40, 60-60...       18          #  \n",
       "1  [0-0, 2-2, 3-3, 5-5, 9-9, 17-17, 19-19, 21-21,...       37          #  \n",
       "2  [1-1, 10-10, 13-13, 28-28, 30-30, 39-39, 52-52...       19          #  \n",
       "3  [5-5, 21-21, 39-39, 40-40, 43-43, 51-51, 58-58...       18          #  \n",
       "4  [2-2, 3-3, 7-7, 9-9, 19-19, 24-24, 26-26, 27-2...       35          #  \n",
       "5  [4-4, 6-6, 17-17, 20-20, 29-29, 32-32, 37-37, ...       16          #  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_init_dataframe(antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count,\n",
    "                         consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we already get all epsiode, Next is get all the combination in two side space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "antecedent_item_sets\n",
    "antecedent_space_name_order = cleaned_data.columns.values\n",
    "consequent_item_sets\n",
    "consequent_space_name_order = target_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_space_epsiode_combination(item_sets, space_order):\n",
    "    \n",
    "    all_space_epsiode_list = []\n",
    "    \n",
    "    # first we need to add all signle epsiode into storage\n",
    "    # k = 1\n",
    "    for k,v in item_sets.items():\n",
    "        for i in range(len(v)):\n",
    "            temp = {k : v[i]}\n",
    "            all_space_epsiode_list.append(temp)\n",
    "    \n",
    "    # second we need to deal with k = 2 combination\n",
    "    \n",
    "    new_candidate = []\n",
    "    the_initial_space = list(item_sets)\n",
    "    for i in range(len(space_order) -1):\n",
    "        #print(the_initial_space[i])\n",
    "        for j in range(i+1, len(space_order)):\n",
    "        \n",
    "            print(i,j)\n",
    "            \n",
    "            first_group_candidate = list(item_sets[the_initial_space[i]])\n",
    "            print(first_group_candidate)\n",
    "            second_group_candidate = list(item_sets[the_initial_space[j]])\n",
    "            print(second_group_candidate)\n",
    "            for x in range(len(first_group_candidate)):\n",
    "                for y in range(len(second_group_candidate)):\n",
    "                    temp = merge_candidate(the_initial_space[i],first_group_candidate[x], \n",
    "                                                        the_initial_space[j], second_group_candidate[y], space_order)\n",
    "                    all_space_epsiode_list.append(temp)\n",
    "                    new_candidate.append(temp)\n",
    "                    \n",
    "    \n",
    "    # last we want to deal with k > 2 combination\n",
    "\n",
    "\n",
    "    while len(new_candidate) > 2:\n",
    "        print(\"=============\")\n",
    "        print(\"this round has candidate:\", len(new_candidate))\n",
    "        print(\"=============\")\n",
    "        Ln = []\n",
    "        # we start doing combination\n",
    "        # always resign the new_candidate\n",
    "        for i in range(0,len(new_candidate)-1):\n",
    "            for j in range(i+1,len(new_candidate)):\n",
    "                #print(list(L2_item_set[i]), list(L2_item_set[j]))\n",
    "                #print(L2_item_set[i], L2_item_set[j])\n",
    "\n",
    "                item_set = merge_candidate(list(new_candidate[i]),new_candidate[i], list(new_candidate[j]), new_candidate[j],space_order)\n",
    "\n",
    "                if len(item_set) > 0:\n",
    "                    print(item_set)\n",
    "                    # we need to check if duplicate\n",
    "                    if check_duplicate(Ln,item_set):\n",
    "                        print(\"duplicate\")\n",
    "                    else:\n",
    "                        Ln.append(item_set)\n",
    "                        all_space_epsiode_list.append(item_set)\n",
    "        new_candidate = Ln\n",
    "        \n",
    "        \n",
    "    return all_space_epsiode_list\n",
    "\n",
    "def merge_item_list(item1, item2, order):\n",
    "    length = len(item1)\n",
    "    count = 0\n",
    "    same_space = []\n",
    "    temp = item1.copy()\n",
    "    temp2 = item2.copy()\n",
    "\n",
    "    for i in order:\n",
    "        if (i in item1) & (i in item2):\n",
    "            if item1[i] == item2[i]:\n",
    "                count += 1\n",
    "                #print(i, \"is the same space\")\n",
    "                same_space.append(i)\n",
    "    \n",
    "    if (length - count) == 1:\n",
    "        # we will merge item here with the support of order\n",
    "        print(item1)\n",
    "        print(item2)\n",
    "        print(\"item allow to merge\")\n",
    "        for j in range(len(same_space)):\n",
    "            del temp2[same_space[j]]\n",
    "        \n",
    "        temp.update(temp2.items())\n",
    "        return temp\n",
    "        \n",
    "    return {}\n",
    "\n",
    "def merge_candidate(space1, item1, space2, item2, order):\n",
    "    \n",
    "    temp_dict = {}\n",
    "    \n",
    "    if isinstance(space1, list): \n",
    "        #print(\"your object is a list, proceeding for L > 2 \") \n",
    "        # this means the item we received will be multiple, we will have to\n",
    "        # apply special check for them\n",
    "        \n",
    "        #print(space1)\n",
    "        #print(len(space1))\n",
    "        #print(space2)\n",
    "        #print(len(space2))\n",
    "        \n",
    "        if len(space1) == len(space2):\n",
    "            mark = len(space1)\n",
    "            space_same_count = 0  \n",
    "            #print(\"same length\")\n",
    "        \n",
    "            # test if the two space are only different in 1 space\n",
    "            for i in range(len(space1)):\n",
    "                for j in range(len(space1)):\n",
    "                    if space1[i] == space2[j]:\n",
    "                        space_same_count += 1\n",
    "                    \n",
    "            # if the difference in space is 1, we are going to check if the same space has same item\n",
    "            # we need to trace the order of space\n",
    "            \n",
    "            if (mark-space_same_count) == 1:\n",
    "                #print(\"space allow to merge\")\n",
    "                temp_dict = merge_item_list(item1, item2, order)\n",
    "                return temp_dict\n",
    "            #else:\n",
    "                #print(\"not allow to merge\")\n",
    "        #print(\"====end====\")\n",
    "        \n",
    "    else: \n",
    "        #print(\"your object is not a list, this is the initial L2\") \n",
    "    \n",
    "        if space1 != space2:\n",
    "            temp_dict.update({space1 : item1})\n",
    "            temp_dict.update({space2 : item2})\n",
    "\n",
    "        print(\"direct merge:\", temp_dict)\n",
    "    return temp_dict \n",
    "\n",
    "\n",
    "def check_duplicate(all_rule_set, item_set):\n",
    "    result = False\n",
    "    temp = {}\n",
    "    \n",
    "    for i in range(len(all_rule_set)):\n",
    "        count = 0\n",
    "        temp = all_rule_set[i]\n",
    "        mark = len(list(temp))\n",
    "        \n",
    "        # if there is a rule exist, has the same with item_set, we consider this is dupulicate\n",
    "        \n",
    "        for k,v in temp.items():\n",
    "            if k in item_set :\n",
    "                if v == item_set[k]:\n",
    "                    count += 1\n",
    "                    if count == mark:\n",
    "                        result = True\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "[(['Bagel'],), (['Bread'],), (['Cheese'],)]\n",
      "[(['Cheese'],), (['Meat'],)]\n",
      "direct merge: {0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Bagel'],), 1: (['Meat'],)}\n",
      "direct merge: {0: (['Bread'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Bread'],), 1: (['Meat'],)}\n",
      "direct merge: {0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Cheese'],), 1: (['Meat'],)}\n",
      "0 2\n",
      "[(['Bagel'],), (['Bread'],), (['Cheese'],)]\n",
      "[(['Diaper'],), (['Eggs'],), (['Meat'],)]\n",
      "direct merge: {0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "direct merge: {0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "direct merge: {0: (['Bagel'],), 2: (['Meat'],)}\n",
      "direct merge: {0: (['Bread'],), 2: (['Diaper'],)}\n",
      "direct merge: {0: (['Bread'],), 2: (['Eggs'],)}\n",
      "direct merge: {0: (['Bread'],), 2: (['Meat'],)}\n",
      "direct merge: {0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "direct merge: {0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "direct merge: {0: (['Cheese'],), 2: (['Meat'],)}\n",
      "1 2\n",
      "[(['Cheese'],), (['Meat'],)]\n",
      "[(['Diaper'],), (['Eggs'],), (['Meat'],)]\n",
      "direct merge: {1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "direct merge: {1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "direct merge: {1: (['Cheese'],), 2: (['Meat'],)}\n",
      "direct merge: {1: (['Meat'],), 2: (['Diaper'],)}\n",
      "direct merge: {1: (['Meat'],), 2: (['Eggs'],)}\n",
      "direct merge: {1: (['Meat'],), 2: (['Meat'],)}\n",
      "=============\n",
      "this round has candidate: 21\n",
      "=============\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Diaper'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Diaper'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Eggs'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Eggs'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Meat'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Meat'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Diaper'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Diaper'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Eggs'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Eggs'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Meat'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Meat'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Diaper'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Diaper'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Eggs'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Eggs'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Meat'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Meat'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "=============\n",
      "this round has candidate: 18\n",
      "=============\n",
      "0 1\n",
      "[(['Diaper'],), (['Eggs'],), (['Meat'],)]\n",
      "[(['Cheese'],), (['Milk'],), (['Pencil'],)]\n",
      "direct merge: {0: (['Diaper'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Diaper'],), 1: (['Milk'],)}\n",
      "direct merge: {0: (['Diaper'],), 1: (['Pencil'],)}\n",
      "direct merge: {0: (['Eggs'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Eggs'],), 1: (['Milk'],)}\n",
      "direct merge: {0: (['Eggs'],), 1: (['Pencil'],)}\n",
      "direct merge: {0: (['Meat'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Meat'],), 1: (['Milk'],)}\n",
      "direct merge: {0: (['Meat'],), 1: (['Pencil'],)}\n",
      "=============\n",
      "this round has candidate: 9\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "#antecedent_item_sets\n",
    "#antecedent_space_name_order = cleaned_data.columns.values\n",
    "#consequent_item_sets\n",
    "#consequent_space_name_order = target_data.columns.values\n",
    "\n",
    "ante_Ln = get_space_epsiode_combination(antecedent_item_sets,antecedent_space_name_order)\n",
    "conse_Ln = get_space_epsiode_combination(consequent_item_sets,consequent_space_name_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{0: (['Bagel'],)},\n",
       " {0: (['Bread'],)},\n",
       " {0: (['Cheese'],)},\n",
       " {1: (['Cheese'],)},\n",
       " {1: (['Meat'],)},\n",
       " {2: (['Diaper'],)},\n",
       " {2: (['Eggs'],)},\n",
       " {2: (['Meat'],)},\n",
       " {0: (['Bagel'],), 1: (['Cheese'],)},\n",
       " {0: (['Bagel'],), 1: (['Meat'],)},\n",
       " {0: (['Bread'],), 1: (['Cheese'],)},\n",
       " {0: (['Bread'],), 1: (['Meat'],)},\n",
       " {0: (['Cheese'],), 1: (['Cheese'],)},\n",
       " {0: (['Cheese'],), 1: (['Meat'],)},\n",
       " {0: (['Bagel'],), 2: (['Diaper'],)},\n",
       " {0: (['Bagel'],), 2: (['Eggs'],)},\n",
       " {0: (['Bagel'],), 2: (['Meat'],)},\n",
       " {0: (['Bread'],), 2: (['Diaper'],)},\n",
       " {0: (['Bread'],), 2: (['Eggs'],)},\n",
       " {0: (['Bread'],), 2: (['Meat'],)},\n",
       " {0: (['Cheese'],), 2: (['Diaper'],)},\n",
       " {0: (['Cheese'],), 2: (['Eggs'],)},\n",
       " {0: (['Cheese'],), 2: (['Meat'],)},\n",
       " {1: (['Cheese'],), 2: (['Diaper'],)},\n",
       " {1: (['Cheese'],), 2: (['Eggs'],)},\n",
       " {1: (['Cheese'],), 2: (['Meat'],)},\n",
       " {1: (['Meat'],), 2: (['Diaper'],)},\n",
       " {1: (['Meat'],), 2: (['Eggs'],)},\n",
       " {1: (['Meat'],), 2: (['Meat'],)},\n",
       " {0: (['Bagel'],), 1: (['Cheese'],), 2: (['Diaper'],)},\n",
       " {0: (['Bagel'],), 1: (['Cheese'],), 2: (['Eggs'],)},\n",
       " {0: (['Bagel'],), 1: (['Cheese'],), 2: (['Meat'],)},\n",
       " {0: (['Bagel'],), 1: (['Meat'],), 2: (['Diaper'],)},\n",
       " {0: (['Bagel'],), 1: (['Meat'],), 2: (['Eggs'],)},\n",
       " {0: (['Bagel'],), 1: (['Meat'],), 2: (['Meat'],)},\n",
       " {0: (['Bread'],), 1: (['Cheese'],), 2: (['Diaper'],)},\n",
       " {0: (['Bread'],), 1: (['Cheese'],), 2: (['Eggs'],)},\n",
       " {0: (['Bread'],), 1: (['Cheese'],), 2: (['Meat'],)},\n",
       " {0: (['Bread'],), 1: (['Meat'],), 2: (['Diaper'],)},\n",
       " {0: (['Bread'],), 1: (['Meat'],), 2: (['Eggs'],)},\n",
       " {0: (['Bread'],), 1: (['Meat'],), 2: (['Meat'],)},\n",
       " {0: (['Cheese'],), 1: (['Cheese'],), 2: (['Diaper'],)},\n",
       " {0: (['Cheese'],), 1: (['Cheese'],), 2: (['Eggs'],)},\n",
       " {0: (['Cheese'],), 1: (['Cheese'],), 2: (['Meat'],)},\n",
       " {0: (['Cheese'],), 1: (['Meat'],), 2: (['Diaper'],)},\n",
       " {0: (['Cheese'],), 1: (['Meat'],), 2: (['Eggs'],)},\n",
       " {0: (['Cheese'],), 1: (['Meat'],), 2: (['Meat'],)}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ante_Ln))\n",
    "ante_Ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{0: (['Diaper'],)},\n",
       " {0: (['Eggs'],)},\n",
       " {0: (['Meat'],)},\n",
       " {1: (['Cheese'],)},\n",
       " {1: (['Milk'],)},\n",
       " {1: (['Pencil'],)},\n",
       " {0: (['Diaper'],), 1: (['Cheese'],)},\n",
       " {0: (['Diaper'],), 1: (['Milk'],)},\n",
       " {0: (['Diaper'],), 1: (['Pencil'],)},\n",
       " {0: (['Eggs'],), 1: (['Cheese'],)},\n",
       " {0: (['Eggs'],), 1: (['Milk'],)},\n",
       " {0: (['Eggs'],), 1: (['Pencil'],)},\n",
       " {0: (['Meat'],), 1: (['Cheese'],)},\n",
       " {0: (['Meat'],), 1: (['Milk'],)},\n",
       " {0: (['Meat'],), 1: (['Pencil'],)}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(conse_Ln))\n",
    "conse_Ln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final count and confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (['Bagel'],)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ante_Ln[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ante_Ln[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Bagel'],)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ante_Ln[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ante_Ln[0][0] == \"Bagel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bagel']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ante_Ln[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ante_Ln[0][0][0][0] ==  \"Bagel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have to do a 4 dimension loop to go through all the possible combination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence(antecedent_episode_list, antecedent_window, antecedent_data, \n",
    "                   consequent_episode_list, consequent_window, consequent_data, \n",
    "                   min_supp = 5, lag = 1, min_conf = 0.1):\n",
    "    \n",
    "    first_col = \"episode/rule\"\n",
    "    second_col = \"consequent\"\n",
    "    third_col = \"Minimal occurrences\"\n",
    "    forth_col = \"Support\"\n",
    "    fifth_col = \"confidence\"\n",
    "    \n",
    "    result_df = pd.DataFrame(columns = [first_col,second_col,third_col,forth_col, fifth_col])\n",
    "    for i in range(len(consequent_episode_list)):\n",
    "        for j in range(len(antecedent_episode_list)):\n",
    "            result = count_association(antecedent_episode_list[j], antecedent_window, antecedent_data, \n",
    "                                      consequent_episode_list[i], consequent_window, consequent_data, \n",
    "                                      min_supp, lag, min_conf)\n",
    "            if len(result) > 0:\n",
    "                df2 = create_final_dataframe(result)\n",
    "                \n",
    "                result_df = pd.concat([result_df, df2])\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def count_association(item1, win1, data1, item2, win2, data2, min_supp, lag, min_conf):\n",
    "    \n",
    "    ante_count = 0\n",
    "    conse_count = 0\n",
    "    \n",
    "    \n",
    "    ante_begin = 0\n",
    "    ante_end = 0\n",
    "    conse_begin = 0\n",
    "    conse_end = 0\n",
    "    \n",
    "    rule = \"\"\n",
    "    conse = \"\"\n",
    "    ante_occur = \"\"\n",
    "    conse_occur = \"\"\n",
    "    occur_list = []\n",
    "    conf = 0\n",
    "    # we want to loop based on data row index\n",
    "    for i in range(len(data1)):\n",
    "                \n",
    "        # we need to concern about the whole length may out of index, thus we need to check if index in dataframe range \n",
    "        # when processing it\n",
    "                \n",
    "        # first we need to check if all the epsiode in antecedent is exist\n",
    "        # we will collect the count of exist, see if the number match with the number of elements\n",
    "        # we will also collect the begin and end of each \n",
    "        # the begin and end of whole epsiode is the min-begin and max-end\n",
    "        # in the search of consequent, we begin with the max-end of antecedent\n",
    "        antecedent_count = 0\n",
    "        \n",
    "        ante_end_list = []    \n",
    "        for k,v in item1.items():\n",
    "            result, end_pos = check_episode_exist(k ,v, data1, i, win1)\n",
    "            if result:\n",
    "                antecedent_count += 1\n",
    "                ante_end_list.append(end_pos)\n",
    "            \n",
    "        if antecedent_count == len(item1):\n",
    "            ante_begin = i\n",
    "            ante_end = max(ante_end_list)\n",
    "            #print(\"pass\")\n",
    "            ante_count += 1\n",
    "            ante_occur = \"{}-{}\".format(ante_begin, ante_end)\n",
    "  \n",
    "            \n",
    "            # second we need to check when this item is exist, does consequent also exist\n",
    "            # we need search from the position of antecedent max-end, with a distance of lag\n",
    "            # if we deal with single dimension\n",
    "                # if we deal with single item, then we find it - done\n",
    "                # if we deal with mulitple item, we find the begining item inside distance of lag, and then find\n",
    "                # right sequence inside window - done\n",
    "            # if we deal with multiple dimension\n",
    "                # we need to do every instance like above, and check the count\n",
    "                # when the exist count is match the number of its dimension - done\n",
    "                    \n",
    "            # whatever happened here will not influence the count of antecedent, it always add 1\n",
    "\n",
    "            for j in range(ante_end, ante_end + lag + 1):\n",
    "                \n",
    "                consequent_count = 0\n",
    "                consequent_end_list = []\n",
    "                for a,b in item2.items():\n",
    "                    result, end_pos = check_episode_exist(a,b, data2, i, win2)\n",
    "                    if result:\n",
    "                        consequent_count += 1\n",
    "                        consequent_end_list.append(end_pos)\n",
    "                \n",
    "                # to avoid repeat count, we only going to find once\n",
    "                if consequent_count == len(item2):\n",
    "                    conse_count += 1\n",
    "                    conse_begin = j\n",
    "                    conse_end = max(ante_end_list)\n",
    "                    conse_occur = \"{}-{}\".format(conse_begin, conse_end)\n",
    "                    occur_list.append([ante_occur, conse_occur])\n",
    "                    break;\n",
    "        \n",
    "        \n",
    "    if (ante_count > min_supp) & (conse_count > min_supp):\n",
    "        if conse_count / ante_count > min_conf:\n",
    "            \n",
    "            for k,v in item1.items():\n",
    "                rule += \" {}\".format(v)\n",
    "                \n",
    "            for k,v in item2.items():\n",
    "                conse += \" {}\".format(v)\n",
    "            \n",
    "            rule += \"lag{}\".format(lag)\n",
    "            conf = conse_count / ante_count     \n",
    "            \n",
    "            return [rule, conse, occur_list, conse_count, conf]\n",
    "    \n",
    "    \n",
    "    return []\n",
    "\n",
    "def check_episode_exist(space, episode, data, begin_index, window):\n",
    "    \n",
    "    local_data = data[space].copy()\n",
    "    local_mark = len(episode)\n",
    "    local_count = 0\n",
    "    end_position = 0\n",
    "    result = False\n",
    "    for i in range(begin_index, begin_index + 1 + window):\n",
    "        if i in local_data.index:\n",
    "            #print(i, local_data.iloc[i] , local_mark, episode)\n",
    "            if local_data.iloc[i] == episode[local_count][0]:\n",
    "                local_count += 1\n",
    "            if local_count == local_mark:\n",
    "                end_position = i\n",
    "                result = True\n",
    "                break;\n",
    "    \n",
    "    return result, end_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_dataframe(result):\n",
    "    \n",
    "    first_col = \"episode/rule\"\n",
    "    second_col = \"consequent\"\n",
    "    third_col = \"Minimal occurrences\"\n",
    "    forth_col = \"Support\"\n",
    "    fifth_col = \"confidence\"\n",
    "    \n",
    "    first_list = []\n",
    "    second_list = []\n",
    "    third_list = []\n",
    "    forth_list = []\n",
    "    fifth_list = []\n",
    "    \n",
    "    df = pd.DataFrame(columns = [first_col,second_col,third_col,forth_col, fifth_col])\n",
    "    \n",
    "    if len(result) > 0:     \n",
    "            \n",
    "        \n",
    "        first_list.append(result[0])\n",
    "        second_list.append(result[1])\n",
    "        third_list.append(result[2])\n",
    "        forth_list.append(result[3])\n",
    "        fifth_list.append(result[4])\n",
    "    \n",
    "        data = {first_col:  first_list,\n",
    "                second_col: second_list,\n",
    "                third_col: third_list,\n",
    "                forth_col: forth_list,\n",
    "                fifth_col: fifth_list\n",
    "                }\n",
    "\n",
    "        df = pd.DataFrame (data, columns = [first_col,second_col,third_col,forth_col,fifth_col])\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = get_confidence(ante_Ln, 3, cleaned_data, conse_Ln, 3, target_data, 25, 1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode/rule</th>\n",
       "      <th>consequent</th>\n",
       "      <th>Minimal occurrences</th>\n",
       "      <th>Support</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Bread'],)lag1</td>\n",
       "      <td>(['Diaper'],)</td>\n",
       "      <td>[[5-7, 7-7], [6-7, 7-7], [7-7, 7-7], [8-11, 11...</td>\n",
       "      <td>36</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],)lag1</td>\n",
       "      <td>(['Diaper'],)</td>\n",
       "      <td>[[6-9, 9-9], [7-9, 9-9], [8-9, 9-9], [26-26, 2...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.273684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Meat'],)lag1</td>\n",
       "      <td>(['Diaper'],)</td>\n",
       "      <td>[[6-9, 9-9], [7-9, 9-9], [8-9, 9-9], [26-26, 2...</td>\n",
       "      <td>39</td>\n",
       "      <td>0.378641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Diaper'],)lag1</td>\n",
       "      <td>(['Diaper'],)</td>\n",
       "      <td>[[5-8, 8-8], [6-8, 8-8], [7-8, 8-8], [8-8, 8-8...</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Eggs'],)lag1</td>\n",
       "      <td>(['Diaper'],)</td>\n",
       "      <td>[[5-5, 5-5], [6-9, 9-9], [7-9, 9-9], [8-9, 9-9...</td>\n",
       "      <td>33</td>\n",
       "      <td>0.311321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],) (['Meat'],)lag1</td>\n",
       "      <td>(['Meat'],) (['Milk'],)</td>\n",
       "      <td>[[0-2, 2-2], [1-2, 2-2], [7-10, 10-10], [8-10,...</td>\n",
       "      <td>39</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Meat'],) (['Eggs'],)lag1</td>\n",
       "      <td>(['Meat'],) (['Milk'],)</td>\n",
       "      <td>[[0-2, 2-2], [1-2, 2-2], [7-9, 9-9], [8-9, 9-9...</td>\n",
       "      <td>36</td>\n",
       "      <td>0.404494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Meat'],) (['Meat'],)lag1</td>\n",
       "      <td>(['Meat'],) (['Milk'],)</td>\n",
       "      <td>[[0-2, 2-2], [1-2, 2-2], [7-10, 10-10], [8-10,...</td>\n",
       "      <td>36</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],) (['Meat'],) (['Eggs'],)lag1</td>\n",
       "      <td>(['Meat'],) (['Milk'],)</td>\n",
       "      <td>[[0-2, 2-2], [1-2, 2-2], [7-9, 9-9], [8-9, 9-9...</td>\n",
       "      <td>36</td>\n",
       "      <td>0.439024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],) (['Meat'],) (['Meat'],)lag1</td>\n",
       "      <td>(['Meat'],) (['Milk'],)</td>\n",
       "      <td>[[0-2, 2-2], [1-2, 2-2], [7-10, 10-10], [8-10,...</td>\n",
       "      <td>36</td>\n",
       "      <td>0.972973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  episode/rule                consequent  \\\n",
       "0                             (['Bread'],)lag1             (['Diaper'],)   \n",
       "0                            (['Cheese'],)lag1             (['Diaper'],)   \n",
       "0                              (['Meat'],)lag1             (['Diaper'],)   \n",
       "0                            (['Diaper'],)lag1             (['Diaper'],)   \n",
       "0                              (['Eggs'],)lag1             (['Diaper'],)   \n",
       "..                                         ...                       ...   \n",
       "0                (['Cheese'],) (['Meat'],)lag1   (['Meat'],) (['Milk'],)   \n",
       "0                  (['Meat'],) (['Eggs'],)lag1   (['Meat'],) (['Milk'],)   \n",
       "0                  (['Meat'],) (['Meat'],)lag1   (['Meat'],) (['Milk'],)   \n",
       "0    (['Cheese'],) (['Meat'],) (['Eggs'],)lag1   (['Meat'],) (['Milk'],)   \n",
       "0    (['Cheese'],) (['Meat'],) (['Meat'],)lag1   (['Meat'],) (['Milk'],)   \n",
       "\n",
       "                                  Minimal occurrences Support  confidence  \n",
       "0   [[5-7, 7-7], [6-7, 7-7], [7-7, 7-7], [8-11, 11...      36    0.473684  \n",
       "0   [[6-9, 9-9], [7-9, 9-9], [8-9, 9-9], [26-26, 2...      26    0.273684  \n",
       "0   [[6-9, 9-9], [7-9, 9-9], [8-9, 9-9], [26-26, 2...      39    0.378641  \n",
       "0   [[5-8, 8-8], [6-8, 8-8], [7-8, 8-8], [8-8, 8-8...      53    1.000000  \n",
       "0   [[5-5, 5-5], [6-9, 9-9], [7-9, 9-9], [8-9, 9-9...      33    0.311321  \n",
       "..                                                ...     ...         ...  \n",
       "0   [[0-2, 2-2], [1-2, 2-2], [7-10, 10-10], [8-10,...      39    0.866667  \n",
       "0   [[0-2, 2-2], [1-2, 2-2], [7-9, 9-9], [8-9, 9-9...      36    0.404494  \n",
       "0   [[0-2, 2-2], [1-2, 2-2], [7-10, 10-10], [8-10,...      36    0.923077  \n",
       "0   [[0-2, 2-2], [1-2, 2-2], [7-9, 9-9], [8-9, 9-9...      36    0.439024  \n",
       "0   [[0-2, 2-2], [1-2, 2-2], [7-10, 10-10], [8-10,...      36    0.972973  \n",
       "\n",
       "[151 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MOWCATL_algorithm(cleaned_data, target_data, min_supp = 15, window_antecedent = 3, window_consequent = 3, lag = 1, conf = 0.1):\n",
    "    \n",
    "    # init all k=1 epsiode\n",
    "    antecedent_L1 = init_all_epsiode(cleaned_data, min_supp)\n",
    "    consequent_L1 = init_all_epsiode(target_data, min_supp)\n",
    "    \n",
    "    # generate all epsiode space\n",
    "    antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count = get_all_epsiodes(cleaned_data, antecedent_L1, min_supp, window_antecedent)\n",
    "    consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count = get_all_epsiodes(target_data, consequent_L1, min_supp, window_consequent)\n",
    "    \n",
    "    # visual initial epsiode space\n",
    "    init_df = create_init_dataframe(antecedent_item_sets, antecedent_item_sets_occurences, antecedent_item_sets_count,\n",
    "                         consequent_item_sets, consequent_item_sets_occurences, consequent_item_sets_count)\n",
    "    \n",
    "    # create the combination of epsiode space\n",
    "    antecedent_space_name_order = cleaned_data.columns.values\n",
    "    consequent_space_name_order = target_data.columns.values\n",
    "\n",
    "    ante_Ln = get_space_epsiode_combination(antecedent_item_sets,antecedent_space_name_order)\n",
    "    conse_Ln = get_space_epsiode_combination(consequent_item_sets,consequent_space_name_order)\n",
    "    \n",
    "    # final association rules\n",
    "    result_df = get_confidence(ante_Ln, 3, cleaned_data, conse_Ln, 3, target_data, 5, 1, 0.1)\n",
    "    \n",
    "    return init_df, result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is  0 col\n",
      "['Bagel'] 19 is support\n",
      "['Bread'] 27 is support\n",
      "['Cheese'] 40 is support\n",
      "this is  1 col\n",
      "['Cheese'] 22 is support\n",
      "['Meat'] 36 is support\n",
      "this is  2 col\n",
      "['Diaper'] 18 is support\n",
      "['Eggs'] 40 is support\n",
      "['Meat'] 19 is support\n",
      "this is  0 col\n",
      "['Diaper'] 18 is support\n",
      "['Eggs'] 40 is support\n",
      "['Meat'] 19 is support\n",
      "this is  1 col\n",
      "['Cheese'] 18 is support\n",
      "['Milk'] 37 is support\n",
      "['Pencil'] 16 is support\n",
      "begin data space: 0\n",
      "item set candidate: (['Bagel'],)\n",
      "occur in : ['6-6', '8-8', '10-10', '12-12', '13-13', '40-40', '56-56', '58-58', '59-59', '60-60', '84-84', '90-90', '91-91', '102-102', '104-104', '106-106', '108-108', '109-109', '139-139']\n",
      "count : 19\n",
      "item set candidate: (['Bread'],)\n",
      "occur in : ['0-0', '1-1', '7-7', '11-11', '35-35', '37-37', '44-44', '51-51', '62-62', '65-65', '67-67', '74-74', '82-82', '86-86', '87-87', '93-93', '96-96', '97-97', '98-98', '99-99', '100-100', '103-103', '107-107', '132-132', '134-134', '136-136', '142-142']\n",
      "count : 27\n",
      "item set candidate: (['Cheese'],)\n",
      "occur in : ['2-2', '3-3', '9-9', '15-15', '19-19', '22-22', '24-24', '26-26', '27-27', '28-28', '30-30', '31-31', '41-41', '42-42', '48-48', '49-49', '52-52', '53-53', '73-73', '75-75', '77-77', '78-78', '79-79', '85-85', '88-88', '92-92', '105-105', '111-111', '115-115', '117-117', '120-120', '121-121', '123-123', '124-124', '125-125', '127-127', '128-128', '140-140']\n",
      "count : 38\n",
      "begin data space: 1\n",
      "item set candidate: (['Cheese'],)\n",
      "occur in : ['1-1', '12-12', '13-13', '32-32', '34-34', '36-36', '44-44', '45-45', '46-46', '47-47', '57-57', '71-71', '72-72', '80-80', '83-83', '90-90', '93-93', '108-108', '109-109', '129-129', '131-131', '133-133']\n",
      "count : 22\n",
      "item set candidate: (['Meat'],)\n",
      "occur in : ['2-2', '3-3', '9-9', '18-18', '19-19', '20-20', '24-24', '26-26', '27-27', '31-31', '35-35', '41-41', '42-42', '48-48', '50-50', '53-53', '62-62', '69-69', '77-77', '85-85', '88-88', '92-92', '96-96', '105-105', '114-114', '115-115', '116-116', '120-120', '121-121', '123-123', '124-124', '128-128', '132-132', '140-140']\n",
      "count : 34\n",
      "begin data space: 2\n",
      "item set candidate: (['Diaper'],)\n",
      "occur in : ['8-8', '29-29', '34-34', '36-36', '38-38', '40-40', '60-60', '87-87', '97-97', '98-98', '99-99', '100-100', '104-104', '126-126', '131-131', '133-133', '137-137', '139-139']\n",
      "count : 18\n",
      "item set candidate: (['Eggs'],)\n",
      "occur in : ['0-0', '2-2', '3-3', '5-5', '9-9', '17-17', '19-19', '21-21', '24-24', '26-26', '27-27', '31-31', '41-41', '42-42', '48-48', '51-51', '53-53', '56-56', '64-64', '71-71', '77-77', '79-79', '85-85', '88-88', '90-90', '92-92', '95-95', '101-101', '105-105', '113-113', '115-115', '120-120', '121-121', '123-123', '124-124', '128-128', '140-140']\n",
      "count : 37\n",
      "item set candidate: (['Meat'],)\n",
      "occur in : ['1-1', '10-10', '13-13', '28-28', '30-30', '39-39', '52-52', '54-54', '66-66', '67-67', '75-75', '78-78', '80-80', '89-89', '106-106', '109-109', '125-125', '127-127', '138-138']\n",
      "count : 19\n",
      "begin data space: 0\n",
      "item set candidate: (['Diaper'],)\n",
      "occur in : ['8-8', '29-29', '34-34', '36-36', '38-38', '40-40', '60-60', '87-87', '97-97', '98-98', '99-99', '100-100', '104-104', '126-126', '131-131', '133-133', '137-137', '139-139']\n",
      "count : 18\n",
      "item set candidate: (['Eggs'],)\n",
      "occur in : ['0-0', '2-2', '3-3', '5-5', '9-9', '17-17', '19-19', '21-21', '24-24', '26-26', '27-27', '31-31', '41-41', '42-42', '48-48', '51-51', '53-53', '56-56', '64-64', '71-71', '77-77', '79-79', '85-85', '88-88', '90-90', '92-92', '95-95', '101-101', '105-105', '113-113', '115-115', '120-120', '121-121', '123-123', '124-124', '128-128', '140-140']\n",
      "count : 37\n",
      "item set candidate: (['Meat'],)\n",
      "occur in : ['1-1', '10-10', '13-13', '28-28', '30-30', '39-39', '52-52', '54-54', '66-66', '67-67', '75-75', '78-78', '80-80', '89-89', '106-106', '109-109', '125-125', '127-127', '138-138']\n",
      "count : 19\n",
      "begin data space: 1\n",
      "item set candidate: (['Cheese'],)\n",
      "occur in : ['5-5', '21-21', '39-39', '40-40', '43-43', '51-51', '58-58', '59-59', '62-62', '64-64', '66-66', '67-67', '68-68', '87-87', '101-101', '118-118', '138-138', '139-139']\n",
      "count : 18\n",
      "item set candidate: (['Milk'],)\n",
      "occur in : ['2-2', '3-3', '7-7', '9-9', '19-19', '24-24', '26-26', '27-27', '31-31', '35-35', '41-41', '42-42', '47-47', '48-48', '53-53', '55-55', '56-56', '72-72', '77-77', '79-79', '85-85', '88-88', '90-90', '91-91', '92-92', '103-103', '105-105', '115-115', '120-120', '121-121', '123-123', '124-124', '128-128', '132-132', '140-140']\n",
      "count : 35\n",
      "item set candidate: (['Pencil'],)\n",
      "occur in : ['4-4', '6-6', '17-17', '20-20', '29-29', '32-32', '37-37', '76-76', '80-80', '84-84', '102-102', '113-113', '116-116', '126-126', '129-129', '134-134']\n",
      "count : 16\n",
      "0 1\n",
      "[(['Bagel'],), (['Bread'],), (['Cheese'],)]\n",
      "[(['Cheese'],), (['Meat'],)]\n",
      "direct merge: {0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Bagel'],), 1: (['Meat'],)}\n",
      "direct merge: {0: (['Bread'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Bread'],), 1: (['Meat'],)}\n",
      "direct merge: {0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Cheese'],), 1: (['Meat'],)}\n",
      "0 2\n",
      "[(['Bagel'],), (['Bread'],), (['Cheese'],)]\n",
      "[(['Diaper'],), (['Eggs'],), (['Meat'],)]\n",
      "direct merge: {0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "direct merge: {0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "direct merge: {0: (['Bagel'],), 2: (['Meat'],)}\n",
      "direct merge: {0: (['Bread'],), 2: (['Diaper'],)}\n",
      "direct merge: {0: (['Bread'],), 2: (['Eggs'],)}\n",
      "direct merge: {0: (['Bread'],), 2: (['Meat'],)}\n",
      "direct merge: {0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "direct merge: {0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "direct merge: {0: (['Cheese'],), 2: (['Meat'],)}\n",
      "1 2\n",
      "[(['Cheese'],), (['Meat'],)]\n",
      "[(['Diaper'],), (['Eggs'],), (['Meat'],)]\n",
      "direct merge: {1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "direct merge: {1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "direct merge: {1: (['Cheese'],), 2: (['Meat'],)}\n",
      "direct merge: {1: (['Meat'],), 2: (['Diaper'],)}\n",
      "direct merge: {1: (['Meat'],), 2: (['Eggs'],)}\n",
      "direct merge: {1: (['Meat'],), 2: (['Meat'],)}\n",
      "=============\n",
      "this round has candidate: 21\n",
      "=============\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Cheese'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Cheese'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Diaper'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Eggs'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 1: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 1: (['Meat'],), 2: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Diaper'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Diaper'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Diaper'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Eggs'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Eggs'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Eggs'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Meat'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bagel'],), 2: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bagel'],), 2: (['Meat'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Diaper'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Diaper'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Diaper'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Eggs'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Eggs'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Eggs'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Meat'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Bread'],), 2: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Bread'],), 2: (['Meat'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{1: (['Cheese'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Diaper'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Diaper'],)}\n",
      "{1: (['Meat'],), 2: (['Diaper'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Diaper'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{1: (['Cheese'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Eggs'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Eggs'],)}\n",
      "{1: (['Meat'],), 2: (['Eggs'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Eggs'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "{1: (['Cheese'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Meat'],), 1: (['Cheese'],)}\n",
      "duplicate\n",
      "{0: (['Cheese'],), 2: (['Meat'],)}\n",
      "{1: (['Meat'],), 2: (['Meat'],)}\n",
      "item allow to merge\n",
      "{0: (['Cheese'],), 2: (['Meat'],), 1: (['Meat'],)}\n",
      "duplicate\n",
      "=============\n",
      "this round has candidate: 18\n",
      "=============\n",
      "0 1\n",
      "[(['Diaper'],), (['Eggs'],), (['Meat'],)]\n",
      "[(['Cheese'],), (['Milk'],), (['Pencil'],)]\n",
      "direct merge: {0: (['Diaper'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Diaper'],), 1: (['Milk'],)}\n",
      "direct merge: {0: (['Diaper'],), 1: (['Pencil'],)}\n",
      "direct merge: {0: (['Eggs'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Eggs'],), 1: (['Milk'],)}\n",
      "direct merge: {0: (['Eggs'],), 1: (['Pencil'],)}\n",
      "direct merge: {0: (['Meat'],), 1: (['Cheese'],)}\n",
      "direct merge: {0: (['Meat'],), 1: (['Milk'],)}\n",
      "direct merge: {0: (['Meat'],), 1: (['Pencil'],)}\n",
      "=============\n",
      "this round has candidate: 9\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "init_df, result_df = MOWCATL_algorithm(cleaned_data, target_data, min_supp = 15, window_antecedent = 3, window_consequent = 3, lag = 1, conf = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode/rule</th>\n",
       "      <th>consequent</th>\n",
       "      <th>Minimal occurrences</th>\n",
       "      <th>Support</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([Bagel],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[6-6, 8-8, 10-10, 12-12, 13-13, 40-40, 56-56, ...</td>\n",
       "      <td>19</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([Bread],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[0-0, 1-1, 7-7, 11-11, 35-35, 37-37, 44-44, 51...</td>\n",
       "      <td>27</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([Cheese],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[2-2, 3-3, 9-9, 15-15, 19-19, 22-22, 24-24, 26...</td>\n",
       "      <td>38</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([Cheese],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[1-1, 12-12, 13-13, 32-32, 34-34, 36-36, 44-44...</td>\n",
       "      <td>22</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([Meat],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[2-2, 3-3, 9-9, 18-18, 19-19, 20-20, 24-24, 26...</td>\n",
       "      <td>34</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([Diaper],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[8-8, 29-29, 34-34, 36-36, 38-38, 40-40, 60-60...</td>\n",
       "      <td>18</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([Eggs],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[0-0, 2-2, 3-3, 5-5, 9-9, 17-17, 19-19, 21-21,...</td>\n",
       "      <td>37</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([Meat],)</td>\n",
       "      <td>#</td>\n",
       "      <td>[1-1, 10-10, 13-13, 28-28, 30-30, 39-39, 52-52...</td>\n",
       "      <td>19</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#</td>\n",
       "      <td>([Diaper],)</td>\n",
       "      <td>[8-8, 29-29, 34-34, 36-36, 38-38, 40-40, 60-60...</td>\n",
       "      <td>18</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#</td>\n",
       "      <td>([Eggs],)</td>\n",
       "      <td>[0-0, 2-2, 3-3, 5-5, 9-9, 17-17, 19-19, 21-21,...</td>\n",
       "      <td>37</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#</td>\n",
       "      <td>([Meat],)</td>\n",
       "      <td>[1-1, 10-10, 13-13, 28-28, 30-30, 39-39, 52-52...</td>\n",
       "      <td>19</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#</td>\n",
       "      <td>([Cheese],)</td>\n",
       "      <td>[5-5, 21-21, 39-39, 40-40, 43-43, 51-51, 58-58...</td>\n",
       "      <td>18</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#</td>\n",
       "      <td>([Milk],)</td>\n",
       "      <td>[2-2, 3-3, 7-7, 9-9, 19-19, 24-24, 26-26, 27-2...</td>\n",
       "      <td>35</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#</td>\n",
       "      <td>([Pencil],)</td>\n",
       "      <td>[4-4, 6-6, 17-17, 20-20, 29-29, 32-32, 37-37, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  episode/rule   consequent  \\\n",
       "0   ([Bagel],)            #   \n",
       "1   ([Bread],)            #   \n",
       "2  ([Cheese],)            #   \n",
       "3  ([Cheese],)            #   \n",
       "4    ([Meat],)            #   \n",
       "5  ([Diaper],)            #   \n",
       "6    ([Eggs],)            #   \n",
       "7    ([Meat],)            #   \n",
       "0            #  ([Diaper],)   \n",
       "1            #    ([Eggs],)   \n",
       "2            #    ([Meat],)   \n",
       "3            #  ([Cheese],)   \n",
       "4            #    ([Milk],)   \n",
       "5            #  ([Pencil],)   \n",
       "\n",
       "                                 Minimal occurrences  Support confidence  \n",
       "0  [6-6, 8-8, 10-10, 12-12, 13-13, 40-40, 56-56, ...       19          #  \n",
       "1  [0-0, 1-1, 7-7, 11-11, 35-35, 37-37, 44-44, 51...       27          #  \n",
       "2  [2-2, 3-3, 9-9, 15-15, 19-19, 22-22, 24-24, 26...       38          #  \n",
       "3  [1-1, 12-12, 13-13, 32-32, 34-34, 36-36, 44-44...       22          #  \n",
       "4  [2-2, 3-3, 9-9, 18-18, 19-19, 20-20, 24-24, 26...       34          #  \n",
       "5  [8-8, 29-29, 34-34, 36-36, 38-38, 40-40, 60-60...       18          #  \n",
       "6  [0-0, 2-2, 3-3, 5-5, 9-9, 17-17, 19-19, 21-21,...       37          #  \n",
       "7  [1-1, 10-10, 13-13, 28-28, 30-30, 39-39, 52-52...       19          #  \n",
       "0  [8-8, 29-29, 34-34, 36-36, 38-38, 40-40, 60-60...       18          #  \n",
       "1  [0-0, 2-2, 3-3, 5-5, 9-9, 17-17, 19-19, 21-21,...       37          #  \n",
       "2  [1-1, 10-10, 13-13, 28-28, 30-30, 39-39, 52-52...       19          #  \n",
       "3  [5-5, 21-21, 39-39, 40-40, 43-43, 51-51, 58-58...       18          #  \n",
       "4  [2-2, 3-3, 7-7, 9-9, 19-19, 24-24, 26-26, 27-2...       35          #  \n",
       "5  [4-4, 6-6, 17-17, 20-20, 29-29, 32-32, 37-37, ...       16          #  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode/rule</th>\n",
       "      <th>consequent</th>\n",
       "      <th>Minimal occurrences</th>\n",
       "      <th>Support</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Bagel'],)lag1</td>\n",
       "      <td>(['Diaper'],)</td>\n",
       "      <td>[[5-6, 6-6], [6-6, 6-6], [7-8, 8-8], [8-8, 8-8...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.510638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Bread'],)lag1</td>\n",
       "      <td>(['Diaper'],)</td>\n",
       "      <td>[[5-7, 7-7], [6-7, 7-7], [7-7, 7-7], [8-11, 11...</td>\n",
       "      <td>36</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],)lag1</td>\n",
       "      <td>(['Diaper'],)</td>\n",
       "      <td>[[6-9, 9-9], [7-9, 9-9], [8-9, 9-9], [26-26, 2...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.273684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],)lag1</td>\n",
       "      <td>(['Diaper'],)</td>\n",
       "      <td>[[29-32, 32-32], [31-32, 32-32], [32-32, 32-32...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Meat'],)lag1</td>\n",
       "      <td>(['Diaper'],)</td>\n",
       "      <td>[[6-9, 9-9], [7-9, 9-9], [8-9, 9-9], [26-26, 2...</td>\n",
       "      <td>39</td>\n",
       "      <td>0.378641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],) (['Cheese'],) (['Eggs'],)lag1</td>\n",
       "      <td>(['Meat'],) (['Pencil'],)</td>\n",
       "      <td>[[1-2, 2-2], [29-32, 32-32], [30-32, 32-32], [...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],) (['Cheese'],) (['Meat'],)lag1</td>\n",
       "      <td>(['Meat'],) (['Pencil'],)</td>\n",
       "      <td>[[1-2, 2-2], [29-32, 32-32], [30-32, 32-32], [...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],) (['Meat'],) (['Diaper'],)lag1</td>\n",
       "      <td>(['Meat'],) (['Pencil'],)</td>\n",
       "      <td>[[26-29, 29-29], [27-29, 29-29], [28-31, 31-31...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],) (['Meat'],) (['Eggs'],)lag1</td>\n",
       "      <td>(['Meat'],) (['Pencil'],)</td>\n",
       "      <td>[[1-2, 2-2], [26-26, 26-26], [27-27, 27-27], [...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.182927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(['Cheese'],) (['Meat'],) (['Meat'],)lag1</td>\n",
       "      <td>(['Meat'],) (['Pencil'],)</td>\n",
       "      <td>[[1-2, 2-2], [26-28, 28-28], [27-28, 28-28], [...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.405405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    episode/rule                  consequent  \\\n",
       "0                               (['Bagel'],)lag1               (['Diaper'],)   \n",
       "0                               (['Bread'],)lag1               (['Diaper'],)   \n",
       "0                              (['Cheese'],)lag1               (['Diaper'],)   \n",
       "0                              (['Cheese'],)lag1               (['Diaper'],)   \n",
       "0                                (['Meat'],)lag1               (['Diaper'],)   \n",
       "..                                           ...                         ...   \n",
       "0    (['Cheese'],) (['Cheese'],) (['Eggs'],)lag1   (['Meat'],) (['Pencil'],)   \n",
       "0    (['Cheese'],) (['Cheese'],) (['Meat'],)lag1   (['Meat'],) (['Pencil'],)   \n",
       "0    (['Cheese'],) (['Meat'],) (['Diaper'],)lag1   (['Meat'],) (['Pencil'],)   \n",
       "0      (['Cheese'],) (['Meat'],) (['Eggs'],)lag1   (['Meat'],) (['Pencil'],)   \n",
       "0      (['Cheese'],) (['Meat'],) (['Meat'],)lag1   (['Meat'],) (['Pencil'],)   \n",
       "\n",
       "                                  Minimal occurrences Support  confidence  \n",
       "0   [[5-6, 6-6], [6-6, 6-6], [7-8, 8-8], [8-8, 8-8...      24    0.510638  \n",
       "0   [[5-7, 7-7], [6-7, 7-7], [7-7, 7-7], [8-11, 11...      36    0.473684  \n",
       "0   [[6-9, 9-9], [7-9, 9-9], [8-9, 9-9], [26-26, 2...      26    0.273684  \n",
       "0   [[29-32, 32-32], [31-32, 32-32], [32-32, 32-32...      16    0.275862  \n",
       "0   [[6-9, 9-9], [7-9, 9-9], [8-9, 9-9], [26-26, 2...      39    0.378641  \n",
       "..                                                ...     ...         ...  \n",
       "0   [[1-2, 2-2], [29-32, 32-32], [30-32, 32-32], [...       8    0.285714  \n",
       "0   [[1-2, 2-2], [29-32, 32-32], [30-32, 32-32], [...       8    0.421053  \n",
       "0   [[26-29, 29-29], [27-29, 29-29], [28-31, 31-31...       8    0.307692  \n",
       "0   [[1-2, 2-2], [26-26, 26-26], [27-27, 27-27], [...      15    0.182927  \n",
       "0   [[1-2, 2-2], [26-28, 28-28], [27-28, 28-28], [...      15    0.405405  \n",
       "\n",
       "[515 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the DRBARMS algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Density ratio based association rules mining for multiple sequencesï¼ŒDRBARMS is a context-based method for multiple event sequences mining.\n",
    "\n",
    "the proposed method was applied to mine association rules between and PM2.5 concentration and several meteorological factors. Results indicated that the most associated meteorological factor with PM2.5 concentration was the humidity and an eligible environment for high PM2.5 concentration were high humidity, low temperature and weak winds. (2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "publication can be seen here:\n",
    "http://html.rhhz.net/WHDXXBXXKXB/html/20180519.htm#outline_anchor_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. calculate Global count,and global density\n",
    "        - This is the context we know\n",
    "2. select every event C and calculate its  local acount, local density for each of the reason events in window width\n",
    "3. calculate density ratio and relative density ratio.\n",
    "\n",
    "4. loop until the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "store_data = pd.read_csv(r\"C:\\Users\\MORPH\\DataSciCov\\store_data2.csv\")  #Importing Dataset from system\n",
    "\n",
    "store_data.head()   # to check the header\n",
    "\n",
    "store_data = pd.read_csv(r\"C:\\Users\\MORPH\\DataSciCov\\store_data2.csv\", header=None)  #keeping header as None\n",
    "\n",
    "num_records = len(store_data)\n",
    "print(num_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Pencil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>Bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Bagel</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Bagel</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2       3       4       5       6\n",
       "0     Bread    Wine    Eggs    Meat  Cheese  Pencil  Diaper\n",
       "1     Bread  Cheese    Meat  Diaper    Wine    Milk  Pencil\n",
       "2    Cheese    Meat    Eggs    Milk    Wine     NaN     NaN\n",
       "3    Cheese    Meat    Eggs    Milk    Wine     NaN     NaN\n",
       "4      Eggs   Bread    Wine  Pencil    Milk  Diaper   Bagel\n",
       "..      ...     ...     ...     ...     ...     ...     ...\n",
       "139   Bagel   Bread  Diaper  Cheese    Meat     NaN     NaN\n",
       "140  Cheese    Meat    Eggs    Milk     NaN     NaN     NaN\n",
       "141  Cheese    Meat    Eggs    Milk     NaN     NaN     NaN\n",
       "142   Bread    Wine    Eggs   Bagel  Cheese  Pencil  Diaper\n",
       "143  Cheese    Meat    Eggs    Milk     NaN     NaN     NaN\n",
       "\n",
       "[144 rows x 7 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(store_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set have at least 4 item in each column. We will have 0,1,2 as input to associate with 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Pencil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Bagel</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2       3\n",
       "0     Bread    Wine    Eggs    Meat\n",
       "1     Bread  Cheese    Meat  Diaper\n",
       "2    Cheese    Meat    Eggs    Milk\n",
       "3    Cheese    Meat    Eggs    Milk\n",
       "4      Eggs   Bread    Wine  Pencil\n",
       "..      ...     ...     ...     ...\n",
       "139   Bagel   Bread  Diaper  Cheese\n",
       "140  Cheese    Meat    Eggs    Milk\n",
       "141  Cheese    Meat    Eggs    Milk\n",
       "142   Bread    Wine    Eggs   Bagel\n",
       "143  Cheese    Meat    Eggs    Milk\n",
       "\n",
       "[144 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = store_data[[0,1,2,3]]\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>consequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Pencil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Bagel</td>\n",
       "      <td>Bread</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         S1      S2      S3 consequent\n",
       "0     Bread    Wine    Eggs       Meat\n",
       "1     Bread  Cheese    Meat     Diaper\n",
       "2    Cheese    Meat    Eggs       Milk\n",
       "3    Cheese    Meat    Eggs       Milk\n",
       "4      Eggs   Bread    Wine     Pencil\n",
       "..      ...     ...     ...        ...\n",
       "139   Bagel   Bread  Diaper     Cheese\n",
       "140  Cheese    Meat    Eggs       Milk\n",
       "141  Cheese    Meat    Eggs       Milk\n",
       "142   Bread    Wine    Eggs      Bagel\n",
       "143  Cheese    Meat    Eggs       Milk\n",
       "\n",
       "[144 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.rename({0: \"S1\", 1: \"S2\", 2: \"S3\", 3:\"consequent\"}, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### global count and global density for reason events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0     Bread\n",
       "1     Bread\n",
       "2    Cheese\n",
       "3    Cheese\n",
       "4      Eggs\n",
       "..      ...\n",
       "139   Bagel\n",
       "140  Cheese\n",
       "141  Cheese\n",
       "142   Bread\n",
       "143  Cheese\n",
       "\n",
       "[144 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC_test_1 = cleaned_data[[0]]\n",
    "GC_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bread',\n",
       " 'Bread',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Eggs',\n",
       " 'Wine',\n",
       " 'Bagel',\n",
       " 'Bread',\n",
       " 'Bagel',\n",
       " 'Cheese',\n",
       " 'Bagel',\n",
       " 'Bread',\n",
       " 'Bagel',\n",
       " 'Bagel',\n",
       " 'Meat',\n",
       " 'Cheese',\n",
       " 'Eggs',\n",
       " 'Diaper',\n",
       " 'Diaper',\n",
       " 'Cheese',\n",
       " 'Diaper',\n",
       " 'Meat',\n",
       " 'Cheese',\n",
       " 'Diaper',\n",
       " 'Cheese',\n",
       " 'Wine',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Wine',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Wine',\n",
       " 'Milk',\n",
       " 'Meat',\n",
       " 'Bread',\n",
       " 'Pencil',\n",
       " 'Bread',\n",
       " 'Pencil',\n",
       " 'Pencil',\n",
       " 'Bagel',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Meat',\n",
       " 'Bread',\n",
       " 'Meat',\n",
       " 'Milk',\n",
       " 'Pencil',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Eggs',\n",
       " 'Bread',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Diaper',\n",
       " 'Pencil',\n",
       " 'Bagel',\n",
       " 'Milk',\n",
       " 'Bagel',\n",
       " 'Bagel',\n",
       " 'Bagel',\n",
       " 'Pencil',\n",
       " 'Bread',\n",
       " 'Meat',\n",
       " 'Meat',\n",
       " 'Bread',\n",
       " 'Milk',\n",
       " 'Bread',\n",
       " 'Milk',\n",
       " 'Pencil',\n",
       " 'Wine',\n",
       " 'Meat',\n",
       " 'Meat',\n",
       " 'Cheese',\n",
       " 'Bread',\n",
       " 'Cheese',\n",
       " 'Diaper',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Wine',\n",
       " 'Eggs',\n",
       " 'Bread',\n",
       " 'Wine',\n",
       " 'Bagel',\n",
       " 'Cheese',\n",
       " 'Bread',\n",
       " 'Bread',\n",
       " 'Cheese',\n",
       " 'Eggs',\n",
       " 'Bagel',\n",
       " 'Bagel',\n",
       " 'Cheese',\n",
       " 'Bread',\n",
       " 'Milk',\n",
       " 'Wine',\n",
       " 'Bread',\n",
       " 'Bread',\n",
       " 'Bread',\n",
       " 'Bread',\n",
       " 'Bread',\n",
       " 'Wine',\n",
       " 'Bagel',\n",
       " 'Bread',\n",
       " 'Bagel',\n",
       " 'Cheese',\n",
       " 'Bagel',\n",
       " 'Bread',\n",
       " 'Bagel',\n",
       " 'Bagel',\n",
       " 'Meat',\n",
       " 'Cheese',\n",
       " 'Eggs',\n",
       " 'Diaper',\n",
       " 'Diaper',\n",
       " 'Cheese',\n",
       " 'Diaper',\n",
       " 'Cheese',\n",
       " 'Eggs',\n",
       " 'Diaper',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Wine',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Wine',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Wine',\n",
       " 'Milk',\n",
       " 'Meat',\n",
       " 'Bread',\n",
       " 'Pencil',\n",
       " 'Bread',\n",
       " 'Diaper',\n",
       " 'Bread',\n",
       " 'Pencil',\n",
       " 'Pencil',\n",
       " 'Bagel',\n",
       " 'Cheese',\n",
       " 'Cheese',\n",
       " 'Bread',\n",
       " 'Cheese']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "GC_list = GC_test_1.values.tolist()\n",
    "GC_list = list(itertools.chain.from_iterable(GC_list))\n",
    "GC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bagel',\n",
       " 'Bread',\n",
       " 'Cheese',\n",
       " 'Diaper',\n",
       " 'Eggs',\n",
       " 'Meat',\n",
       " 'Milk',\n",
       " 'Pencil',\n",
       " 'Wine']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_t = list(np.unique(GC_list))   \n",
    "_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagel\n",
      "Bread\n",
      "Cheese\n",
      "Diaper\n",
      "Eggs\n",
      "Meat\n",
      "Milk\n",
      "Pencil\n",
      "Wine\n"
     ]
    }
   ],
   "source": [
    "    # we need to go over the all data, find how many times the item set is appear.\n",
    "    c = []\n",
    "    count = 0\n",
    "    for i in range(len(_t)):\n",
    "        for j in range(len(GC_list)):\n",
    "            if set(_t[i]).issubset(set(GC_list[j])):\n",
    "                count += 1\n",
    "                \n",
    "        print(_t[i])\n",
    "        c.append(count)\n",
    "        count = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 27, 40, 11, 7, 11, 7, 10, 12]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_density = [[f/len(GC_list)] for f in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.13194444444444445],\n",
       " [0.1875],\n",
       " [0.2777777777777778],\n",
       " [0.0763888888888889],\n",
       " [0.04861111111111111],\n",
       " [0.0763888888888889],\n",
       " [0.04861111111111111],\n",
       " [0.06944444444444445],\n",
       " [0.08333333333333333]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below is the complete function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def count_occurence(item_set, data):\n",
    "    # we need to go over the all data, find how many times the item set is appear.\n",
    "    c = []\n",
    "    count = 0\n",
    "    for i in range(len(item_set)):\n",
    "        for j in range(len(data)):\n",
    "            if set(item_set[i]).issubset(set(data[j])):\n",
    "                count += 1\n",
    "                \n",
    "        #print(item_set[i])\n",
    "        c.append(count)\n",
    "        count = 0\n",
    "        \n",
    "    return c\n",
    "\n",
    "\n",
    "def  init_data_processing(data):\n",
    "    \n",
    "    list_gc = []    # collect all series gc\n",
    "    list_gd = []    # collect all series gd\n",
    "    dict_gc = {}    # global count for each unique item in this Series\n",
    "    dict_gd = {}    # global density for each unique item in this Series\n",
    "    \n",
    "    target_item = []\n",
    "    length = len(data.columns)\n",
    "    for i in range(length):\n",
    "        GC_data = data[[i]]\n",
    "        GC_list = GC_data.values.tolist()\n",
    "        GC_list = list(itertools.chain.from_iterable(GC_list))\n",
    "        _t = list(np.unique(GC_list))   \n",
    "        \n",
    "        if i == length-1:\n",
    "            #print(i)\n",
    "            target_item = _t\n",
    "        \n",
    "        c = count_occurence(_t, GC_list)\n",
    "        #print(c)\n",
    "        #({k: join_itemsets(L[k-1], my_whole_set)})\n",
    "        global_density = [[f/len(GC_list)] for f in c]\n",
    "        #print(len(GC_list))\n",
    "        \n",
    "        count_flag = 0\n",
    "        for item in _t:\n",
    "            dict_gc.update({item : c[count_flag]})\n",
    "            dict_gd.update({item : global_density[count_flag]})\n",
    "            #print( global_density[count_flag])\n",
    "            #print(\"-----\")\n",
    "            #print(dict_gc)\n",
    "            #print(dict_gd)\n",
    "            count_flag += 1\n",
    "            \n",
    "        list_gc.append(dict_gc)\n",
    "        list_gd.append(dict_gd)\n",
    "        dict_gc = {}\n",
    "        dict_gd = {}\n",
    "        \n",
    "        #print(\"end\")\n",
    "    return list_gc, list_gd, target_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_gc, list_gd, target_item = init_data_processing(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bagel': 19,\n",
       " 'Bread': 27,\n",
       " 'Cheese': 40,\n",
       " 'Diaper': 11,\n",
       " 'Eggs': 7,\n",
       " 'Meat': 11,\n",
       " 'Milk': 7,\n",
       " 'Pencil': 10,\n",
       " 'Wine': 12}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_gc))\n",
    "list_gc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bagel': [0.13194444444444445],\n",
       " 'Bread': [0.1875],\n",
       " 'Cheese': [0.2777777777777778],\n",
       " 'Diaper': [0.0763888888888889],\n",
       " 'Eggs': [0.04861111111111111],\n",
       " 'Meat': [0.0763888888888889],\n",
       " 'Milk': [0.04861111111111111],\n",
       " 'Pencil': [0.06944444444444445],\n",
       " 'Wine': [0.08333333333333333]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_gd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bagel',\n",
       " 'Bread',\n",
       " 'Cheese',\n",
       " 'Diaper',\n",
       " 'Eggs',\n",
       " 'Meat',\n",
       " 'Milk',\n",
       " 'Pencil',\n",
       " 'Wine']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### local count and local density for reason events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "56\n",
      "58\n",
      "60\n",
      "62\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "86\n",
      "88\n",
      "90\n",
      "92\n",
      "94\n",
      "96\n",
      "98\n",
      "100\n",
      "102\n",
      "104\n",
      "106\n",
      "108\n",
      "110\n",
      "112\n",
      "114\n",
      "116\n",
      "118\n",
      "120\n",
      "122\n",
      "124\n",
      "126\n",
      "128\n",
      "130\n",
      "132\n",
      "134\n",
      "136\n",
      "138\n",
      "140\n",
      "142\n"
     ]
    }
   ],
   "source": [
    "width = 2\n",
    "cleaned_data[0:2]\n",
    "for i in range(0,len(cleaned_data),2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pencil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Milk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3\n",
       "0      Meat\n",
       "1    Diaper\n",
       "2      Milk\n",
       "3      Milk\n",
       "4    Pencil\n",
       "..      ...\n",
       "139  Cheese\n",
       "140    Milk\n",
       "141    Milk\n",
       "142   Bagel\n",
       "143    Milk\n",
       "\n",
       "[144 rows x 1 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC_test_target_1 = cleaned_data[[3]]\n",
    "GC_test_target_1     # this is our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0     Bread\n",
       "1     Bread\n",
       "2    Cheese\n",
       "3    Cheese\n",
       "4      Eggs\n",
       "..      ...\n",
       "139   Bagel\n",
       "140  Cheese\n",
       "141  Cheese\n",
       "142   Bread\n",
       "143  Cheese\n",
       "\n",
       "[144 rows x 1 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1 = cleaned_data[[0]]\n",
    "S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bread'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1.loc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_reason_item(data, start_index, end_index):\n",
    "    local_list = []\n",
    "    #print(start_index, end_index)\n",
    "    for i in range(start_index, end_index):\n",
    "        #print(i)\n",
    "        #print(data)\n",
    "        print(data.iloc[i].values[0])\n",
    "        local_list.append(data.iloc[i].values[0])\n",
    "        \n",
    "    return local_list \n",
    "\n",
    "def get_reason_item(data, width, C_data, target):\n",
    "    \n",
    "    item = []\n",
    "    for i in range(0,len(data),width):\n",
    "    #print(i)\n",
    "        for j in range(i,i+width):\n",
    "            if C_data.iloc[j].values == target:\n",
    "                # if in a block the target item appear\n",
    "                # add count for every item appear \n",
    "                \n",
    "                print(\"inner loop\",j)\n",
    "                \n",
    "                temp = get_all_reason_item(data,i, i+width)\n",
    "                for x in range(len(temp)):\n",
    "                    item.append(temp[x])  \n",
    "    return item\n",
    "\n",
    "def counting_local_density(global_count, data, global_count_c, target, width):\n",
    "    \n",
    "    dict_lc = {}    # local count for each unique item in this Series\n",
    "    dict_ld = {}    # local density for each unique item in this Series\n",
    "    \n",
    "    new_t = list(global_count)\n",
    "    \n",
    "    print(\"* S1->C local count\")\n",
    "    print(new_t)\n",
    "    lc = count_occurence(new_t,data)\n",
    "    print(lc)\n",
    "    print(\"GC:\")\n",
    "    print(target, global_count_c[target])\n",
    "    print(\"local density\")\n",
    "    local_density = [[f/(global_count_c[each] * width)] for f in lc]\n",
    "    print(local_density)\n",
    "    print(\"*\")\n",
    "    \n",
    "    count_flag = 0\n",
    "    for item in new_t:\n",
    "        dict_lc.update({item : lc[count_flag]})\n",
    "        dict_ld.update({item : local_density[count_flag]})\n",
    "        count_flag += 1\n",
    "        \n",
    "    return dict_lc, dict_ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagel as C\n",
      "inner loop 11\n",
      "Bagel\n",
      "Bread\n",
      "inner loop 33\n",
      "Wine\n",
      "Milk\n",
      "inner loop 44\n",
      "Bread\n",
      "Meat\n",
      "inner loop 46\n",
      "Milk\n",
      "Pencil\n",
      "inner loop 49\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 50\n",
      "Eggs\n",
      "Bread\n",
      "inner loop 69\n",
      "Milk\n",
      "Pencil\n",
      "inner loop 71\n",
      "Wine\n",
      "Meat\n",
      "inner loop 78\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 86\n",
      "Bread\n",
      "Bread\n",
      "inner loop 107\n",
      "Bagel\n",
      "Bread\n",
      "inner loop 130\n",
      "Milk\n",
      "Meat\n",
      "inner loop 135\n",
      "Bread\n",
      "Diaper\n",
      "inner loop 142\n",
      "Bread\n",
      "Cheese\n",
      "['Bagel', 'Bread', 'Wine', 'Milk', 'Bread', 'Meat', 'Milk', 'Pencil', 'Cheese', 'Cheese', 'Eggs', 'Bread', 'Milk', 'Pencil', 'Wine', 'Meat', 'Cheese', 'Cheese', 'Bread', 'Bread', 'Bagel', 'Bread', 'Milk', 'Meat', 'Bread', 'Diaper', 'Bread', 'Cheese']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[2, 8, 5, 1, 1, 3, 4, 2, 2]\n",
      "GC:\n",
      "Bagel 14\n",
      "local density\n",
      "[[0.07142857142857142], [0.2857142857142857], [0.17857142857142858], [0.03571428571428571], [0.03571428571428571], [0.10714285714285714], [0.14285714285714285], [0.07142857142857142], [0.07142857142857142]]\n",
      "*\n",
      "===========\n",
      "Bread as C\n",
      "inner loop 10\n",
      "Bagel\n",
      "Bread\n",
      "inner loop 13\n",
      "Bagel\n",
      "Bagel\n",
      "inner loop 14\n",
      "Meat\n",
      "Cheese\n",
      "inner loop 15\n",
      "Meat\n",
      "Cheese\n",
      "inner loop 18\n",
      "Diaper\n",
      "Cheese\n",
      "inner loop 95\n",
      "Milk\n",
      "Wine\n",
      "inner loop 106\n",
      "Bagel\n",
      "Bread\n",
      "inner loop 109\n",
      "Bagel\n",
      "Bagel\n",
      "inner loop 110\n",
      "Meat\n",
      "Cheese\n",
      "inner loop 111\n",
      "Meat\n",
      "Cheese\n",
      "inner loop 114\n",
      "Diaper\n",
      "Cheese\n",
      "['Bagel', 'Bread', 'Bagel', 'Bagel', 'Meat', 'Cheese', 'Meat', 'Cheese', 'Diaper', 'Cheese', 'Milk', 'Wine', 'Bagel', 'Bread', 'Bagel', 'Bagel', 'Meat', 'Cheese', 'Meat', 'Cheese', 'Diaper', 'Cheese']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[6, 2, 6, 2, 0, 4, 1, 0, 1]\n",
      "GC:\n",
      "Bread 11\n",
      "local density\n",
      "[[0.2727272727272727], [0.09090909090909091], [0.2727272727272727], [0.09090909090909091], [0.0], [0.18181818181818182], [0.045454545454545456], [0.0], [0.045454545454545456]]\n",
      "*\n",
      "===========\n",
      "Cheese as C\n",
      "inner loop 5\n",
      "Eggs\n",
      "Wine\n",
      "inner loop 21\n",
      "Diaper\n",
      "Meat\n",
      "inner loop 39\n",
      "Pencil\n",
      "Pencil\n",
      "inner loop 40\n",
      "Bagel\n",
      "Cheese\n",
      "inner loop 43\n",
      "Cheese\n",
      "Meat\n",
      "inner loop 51\n",
      "Eggs\n",
      "Bread\n",
      "inner loop 58\n",
      "Bagel\n",
      "Bagel\n",
      "inner loop 59\n",
      "Bagel\n",
      "Bagel\n",
      "inner loop 62\n",
      "Bread\n",
      "Meat\n",
      "inner loop 64\n",
      "Meat\n",
      "Bread\n",
      "inner loop 66\n",
      "Milk\n",
      "Bread\n",
      "inner loop 67\n",
      "Milk\n",
      "Bread\n",
      "inner loop 68\n",
      "Milk\n",
      "Pencil\n",
      "inner loop 87\n",
      "Bread\n",
      "Bread\n",
      "inner loop 101\n",
      "Bread\n",
      "Wine\n",
      "inner loop 118\n",
      "Eggs\n",
      "Diaper\n",
      "inner loop 138\n",
      "Pencil\n",
      "Bagel\n",
      "inner loop 139\n",
      "Pencil\n",
      "Bagel\n",
      "['Eggs', 'Wine', 'Diaper', 'Meat', 'Pencil', 'Pencil', 'Bagel', 'Cheese', 'Cheese', 'Meat', 'Eggs', 'Bread', 'Bagel', 'Bagel', 'Bagel', 'Bagel', 'Bread', 'Meat', 'Meat', 'Bread', 'Milk', 'Bread', 'Milk', 'Bread', 'Milk', 'Pencil', 'Bread', 'Bread', 'Bread', 'Wine', 'Eggs', 'Diaper', 'Pencil', 'Bagel', 'Pencil', 'Bagel']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[7, 8, 2, 2, 3, 4, 3, 5, 2]\n",
      "GC:\n",
      "Cheese 18\n",
      "local density\n",
      "[[0.19444444444444445], [0.2222222222222222], [0.05555555555555555], [0.05555555555555555], [0.08333333333333333], [0.1111111111111111], [0.08333333333333333], [0.1388888888888889], [0.05555555555555555]]\n",
      "*\n",
      "===========\n",
      "Diaper as C\n",
      "inner loop 1\n",
      "Bread\n",
      "Bread\n",
      "inner loop 22\n",
      "Cheese\n",
      "Diaper\n",
      "inner loop 25\n",
      "Cheese\n",
      "Wine\n",
      "inner loop 30\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 63\n",
      "Bread\n",
      "Meat\n",
      "inner loop 70\n",
      "Wine\n",
      "Meat\n",
      "inner loop 74\n",
      "Bread\n",
      "Cheese\n",
      "inner loop 89\n",
      "Cheese\n",
      "Eggs\n",
      "inner loop 93\n",
      "Cheese\n",
      "Bread\n",
      "inner loop 117\n",
      "Diaper\n",
      "Cheese\n",
      "inner loop 122\n",
      "Wine\n",
      "Cheese\n",
      "inner loop 127\n",
      "Wine\n",
      "Cheese\n",
      "inner loop 136\n",
      "Bread\n",
      "Pencil\n",
      "['Bread', 'Bread', 'Cheese', 'Diaper', 'Cheese', 'Wine', 'Cheese', 'Cheese', 'Bread', 'Meat', 'Wine', 'Meat', 'Bread', 'Cheese', 'Cheese', 'Eggs', 'Cheese', 'Bread', 'Diaper', 'Cheese', 'Wine', 'Cheese', 'Wine', 'Cheese', 'Bread', 'Pencil']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[0, 6, 10, 2, 1, 2, 0, 1, 4]\n",
      "GC:\n",
      "Diaper 13\n",
      "local density\n",
      "[[0.0], [0.23076923076923078], [0.38461538461538464], [0.07692307692307693], [0.038461538461538464], [0.07692307692307693], [0.0], [0.038461538461538464], [0.15384615384615385]]\n",
      "*\n",
      "===========\n",
      "Eggs as C\n",
      "inner loop 23\n",
      "Cheese\n",
      "Diaper\n",
      "inner loop 38\n",
      "Pencil\n",
      "Pencil\n",
      "inner loop 52\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 54\n",
      "Diaper\n",
      "Pencil\n",
      "inner loop 61\n",
      "Bagel\n",
      "Pencil\n",
      "inner loop 65\n",
      "Meat\n",
      "Bread\n",
      "inner loop 73\n",
      "Meat\n",
      "Cheese\n",
      "inner loop 96\n",
      "Bread\n",
      "Bread\n",
      "inner loop 97\n",
      "Bread\n",
      "Bread\n",
      "inner loop 98\n",
      "Bread\n",
      "Bread\n",
      "inner loop 99\n",
      "Bread\n",
      "Bread\n",
      "inner loop 100\n",
      "Bread\n",
      "Wine\n",
      "inner loop 119\n",
      "Eggs\n",
      "Diaper\n",
      "inner loop 137\n",
      "Bread\n",
      "Pencil\n",
      "['Cheese', 'Diaper', 'Pencil', 'Pencil', 'Cheese', 'Cheese', 'Diaper', 'Pencil', 'Bagel', 'Pencil', 'Meat', 'Bread', 'Meat', 'Cheese', 'Bread', 'Bread', 'Bread', 'Bread', 'Bread', 'Bread', 'Bread', 'Bread', 'Bread', 'Wine', 'Eggs', 'Diaper', 'Bread', 'Pencil']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[1, 11, 4, 3, 1, 2, 0, 5, 1]\n",
      "GC:\n",
      "Eggs 14\n",
      "local density\n",
      "[[0.03571428571428571], [0.39285714285714285], [0.14285714285714285], [0.10714285714285714], [0.03571428571428571], [0.07142857142857142], [0.0], [0.17857142857142858], [0.03571428571428571]]\n",
      "*\n",
      "===========\n",
      "Meat as C\n",
      "inner loop 0\n",
      "Bread\n",
      "Bread\n",
      "inner loop 8\n",
      "Bagel\n",
      "Cheese\n",
      "inner loop 12\n",
      "Bagel\n",
      "Bagel\n",
      "inner loop 16\n",
      "Eggs\n",
      "Diaper\n",
      "inner loop 57\n",
      "Bagel\n",
      "Milk\n",
      "inner loop 83\n",
      "Bread\n",
      "Wine\n",
      "inner loop 104\n",
      "Bagel\n",
      "Cheese\n",
      "inner loop 108\n",
      "Bagel\n",
      "Bagel\n",
      "inner loop 112\n",
      "Eggs\n",
      "Diaper\n",
      "['Bread', 'Bread', 'Bagel', 'Cheese', 'Bagel', 'Bagel', 'Eggs', 'Diaper', 'Bagel', 'Milk', 'Bread', 'Wine', 'Bagel', 'Cheese', 'Bagel', 'Bagel', 'Eggs', 'Diaper']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[7, 3, 2, 2, 2, 0, 1, 0, 1]\n",
      "GC:\n",
      "Meat 9\n",
      "local density\n",
      "[[0.3888888888888889], [0.16666666666666666], [0.1111111111111111], [0.1111111111111111], [0.1111111111111111], [0.0], [0.05555555555555555], [0.0], [0.05555555555555555]]\n",
      "*\n",
      "===========\n",
      "Milk as C\n",
      "inner loop 2\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 3\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 7\n",
      "Bagel\n",
      "Bread\n",
      "inner loop 9\n",
      "Bagel\n",
      "Cheese\n",
      "inner loop 19\n",
      "Diaper\n",
      "Cheese\n",
      "inner loop 24\n",
      "Cheese\n",
      "Wine\n",
      "inner loop 26\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 27\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 31\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 35\n",
      "Meat\n",
      "Bread\n",
      "inner loop 41\n",
      "Bagel\n",
      "Cheese\n",
      "inner loop 42\n",
      "Cheese\n",
      "Meat\n",
      "inner loop 47\n",
      "Milk\n",
      "Pencil\n",
      "inner loop 48\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 53\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 55\n",
      "Diaper\n",
      "Pencil\n",
      "inner loop 56\n",
      "Bagel\n",
      "Milk\n",
      "inner loop 72\n",
      "Meat\n",
      "Cheese\n",
      "inner loop 77\n",
      "Diaper\n",
      "Cheese\n",
      "inner loop 79\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 85\n",
      "Bagel\n",
      "Cheese\n",
      "inner loop 88\n",
      "Cheese\n",
      "Eggs\n",
      "inner loop 90\n",
      "Bagel\n",
      "Bagel\n",
      "inner loop 91\n",
      "Bagel\n",
      "Bagel\n",
      "inner loop 92\n",
      "Cheese\n",
      "Bread\n",
      "inner loop 103\n",
      "Bagel\n",
      "Bread\n",
      "inner loop 105\n",
      "Bagel\n",
      "Cheese\n",
      "inner loop 115\n",
      "Diaper\n",
      "Cheese\n",
      "inner loop 120\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 121\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 123\n",
      "Wine\n",
      "Cheese\n",
      "inner loop 124\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 128\n",
      "Cheese\n",
      "Wine\n",
      "inner loop 132\n",
      "Bread\n",
      "Pencil\n",
      "inner loop 140\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 141\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 143\n",
      "Bread\n",
      "Cheese\n",
      "['Cheese', 'Cheese', 'Cheese', 'Cheese', 'Bagel', 'Bread', 'Bagel', 'Cheese', 'Diaper', 'Cheese', 'Cheese', 'Wine', 'Cheese', 'Cheese', 'Cheese', 'Cheese', 'Cheese', 'Cheese', 'Meat', 'Bread', 'Bagel', 'Cheese', 'Cheese', 'Meat', 'Milk', 'Pencil', 'Cheese', 'Cheese', 'Cheese', 'Cheese', 'Diaper', 'Pencil', 'Bagel', 'Milk', 'Meat', 'Cheese', 'Diaper', 'Cheese', 'Cheese', 'Cheese', 'Bagel', 'Cheese', 'Cheese', 'Eggs', 'Bagel', 'Bagel', 'Bagel', 'Bagel', 'Cheese', 'Bread', 'Bagel', 'Bread', 'Bagel', 'Cheese', 'Diaper', 'Cheese', 'Cheese', 'Cheese', 'Cheese', 'Cheese', 'Wine', 'Cheese', 'Cheese', 'Cheese', 'Cheese', 'Wine', 'Bread', 'Pencil', 'Cheese', 'Cheese', 'Cheese', 'Cheese', 'Bread', 'Cheese']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[11, 6, 41, 4, 1, 3, 2, 3, 3]\n",
      "GC:\n",
      "Milk 37\n",
      "local density\n",
      "[[0.14864864864864866], [0.08108108108108109], [0.5540540540540541], [0.05405405405405406], [0.013513513513513514], [0.04054054054054054], [0.02702702702702703], [0.04054054054054054], [0.04054054054054054]]\n",
      "*\n",
      "===========\n",
      "Pencil as C\n",
      "inner loop 4\n",
      "Eggs\n",
      "Wine\n",
      "inner loop 6\n",
      "Bagel\n",
      "Bread\n",
      "inner loop 17\n",
      "Eggs\n",
      "Diaper\n",
      "inner loop 20\n",
      "Diaper\n",
      "Meat\n",
      "inner loop 29\n",
      "Cheese\n",
      "Wine\n",
      "inner loop 32\n",
      "Wine\n",
      "Milk\n",
      "inner loop 37\n",
      "Pencil\n",
      "Bread\n",
      "inner loop 76\n",
      "Diaper\n",
      "Cheese\n",
      "inner loop 80\n",
      "Wine\n",
      "Eggs\n",
      "inner loop 84\n",
      "Bagel\n",
      "Cheese\n",
      "inner loop 102\n",
      "Bagel\n",
      "Bread\n",
      "inner loop 113\n",
      "Eggs\n",
      "Diaper\n",
      "inner loop 116\n",
      "Diaper\n",
      "Cheese\n",
      "inner loop 126\n",
      "Wine\n",
      "Cheese\n",
      "inner loop 129\n",
      "Cheese\n",
      "Wine\n",
      "inner loop 134\n",
      "Bread\n",
      "Diaper\n",
      "['Eggs', 'Wine', 'Bagel', 'Bread', 'Eggs', 'Diaper', 'Diaper', 'Meat', 'Cheese', 'Wine', 'Wine', 'Milk', 'Pencil', 'Bread', 'Diaper', 'Cheese', 'Wine', 'Eggs', 'Bagel', 'Cheese', 'Bagel', 'Bread', 'Eggs', 'Diaper', 'Diaper', 'Cheese', 'Wine', 'Cheese', 'Cheese', 'Wine', 'Bread', 'Diaper']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[3, 4, 6, 6, 4, 1, 1, 1, 6]\n",
      "GC:\n",
      "Pencil 16\n",
      "local density\n",
      "[[0.09375], [0.125], [0.1875], [0.1875], [0.125], [0.03125], [0.03125], [0.03125], [0.1875]]\n",
      "*\n",
      "===========\n",
      "Wine as C\n",
      "inner loop 28\n",
      "Cheese\n",
      "Wine\n",
      "inner loop 34\n",
      "Meat\n",
      "Bread\n",
      "inner loop 36\n",
      "Pencil\n",
      "Bread\n",
      "inner loop 45\n",
      "Bread\n",
      "Meat\n",
      "inner loop 60\n",
      "Bagel\n",
      "Pencil\n",
      "inner loop 75\n",
      "Bread\n",
      "Cheese\n",
      "inner loop 81\n",
      "Wine\n",
      "Eggs\n",
      "inner loop 82\n",
      "Bread\n",
      "Wine\n",
      "inner loop 94\n",
      "Milk\n",
      "Wine\n",
      "inner loop 125\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 131\n",
      "Milk\n",
      "Meat\n",
      "inner loop 133\n",
      "Bread\n",
      "Pencil\n",
      "['Cheese', 'Wine', 'Meat', 'Bread', 'Pencil', 'Bread', 'Bread', 'Meat', 'Bagel', 'Pencil', 'Bread', 'Cheese', 'Wine', 'Eggs', 'Bread', 'Wine', 'Milk', 'Wine', 'Cheese', 'Cheese', 'Milk', 'Meat', 'Bread', 'Pencil']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[1, 6, 4, 0, 1, 3, 2, 3, 4]\n",
      "GC:\n",
      "Wine 12\n",
      "local density\n",
      "[[0.041666666666666664], [0.25], [0.16666666666666666], [0.0], [0.041666666666666664], [0.125], [0.08333333333333333], [0.125], [0.16666666666666666]]\n",
      "*\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "list_local_count = []\n",
    "list_local_density = []\n",
    "count = 0\n",
    "\n",
    "local_target_item = target_item\n",
    "S1 = cleaned_data[[0]]\n",
    "C = cleaned_data[[3]]\n",
    "global_count_c = list_gc[3]\n",
    "global_density = list_gd[0]\n",
    "# currently only work on S1\n",
    "\n",
    "for each in local_target_item:\n",
    "    \n",
    "    print(each, \"as C\") \n",
    "    \n",
    "    item_in_S1 = get_reason_item(S1,width, C, each)\n",
    "    print(item_in_S1)\n",
    "    \n",
    "    global_count = list_gc[0]\n",
    "    \n",
    "    lc, ld = counting_local_density(global_count, item_in_S1, global_count_c, each, width)\n",
    "\n",
    " \n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bagel',\n",
       " 'Bread',\n",
       " 'Cheese',\n",
       " 'Diaper',\n",
       " 'Eggs',\n",
       " 'Meat',\n",
       " 'Milk',\n",
       " 'Pencil',\n",
       " 'Wine']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list_gc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = [[1],[1,2],[1],[2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [1, 2], [2, 1]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_t = list(np.unique(new_list))   \n",
    "_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### density ratio & relative density ratio & confidence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def single_target_analysis(target, width, data, target_data, global_count, global_count_target, global_density):\n",
    "    \n",
    "    \n",
    "    print(target, \"as C\") \n",
    "    \n",
    "    item_in_data = get_reason_item(data, width, target_data, target)\n",
    "    print(item_in_data)\n",
    "    \n",
    "    # lc : local count\n",
    "    # ld : local density\n",
    "    local_count, local_density = counting_local_density(global_count, item_in_data, global_count_target, target, width)\n",
    "    print(\"the ld dict:\", ld)\n",
    "    # dr : density ratio\n",
    "    dr_dict, final_candidate = get_density_ratio(global_count, local_density, global_density)\n",
    "    \n",
    "    print(\"the dr dict:\", dr_dict)\n",
    "    print(\"the candidate : \", final_candidate)    \n",
    "\n",
    "    # conf : confidence\n",
    "    conf = get_confidence(final_candidate, global_count, global_count_target, local_count, target)\n",
    "    \n",
    "    print(\"the confidence : \", conf)\n",
    "    print(\"===========\")\n",
    "    \n",
    "    return final_candidate, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_density_ratio(global_count, local_density, global_density):\n",
    "    \n",
    "    dr_dict = {}\n",
    "    item_candidate = {}\n",
    "    \n",
    "    for item in list(global_count):\n",
    "        print(\"density ratio:\")\n",
    "        print(local_density[item])\n",
    "        print(global_density[item])\n",
    "        dr = local_density[item][0] / global_density[item][0]\n",
    "        print(item, dr)\n",
    "        dr_dict.update({item: dr})    \n",
    "    \n",
    "        if (dr > 1):    # this can be varied. We want to collect the density ratio > 1 into relative density ratio analysis\n",
    "                        # also we will use them for next round explore\n",
    "                \n",
    "            item_candidate.update({item:local_density[item][0]})\n",
    "            print(\"update the item candidate\",item, local_density[item][0])\n",
    "        \n",
    "    final_candidate = get_relative_density(item_candidate)\n",
    "    \n",
    "    return dr_dict, final_candidate\n",
    "        \n",
    "\n",
    "def get_relative_density(item_candidate):        \n",
    "    \n",
    "    final_candidate = {}\n",
    "\n",
    "    for item in item_candidate:\n",
    "        #print(len(item_candidate))\n",
    "        #print(item_candidate[item])\n",
    "        sum_item = 0\n",
    "        for k,v in item_candidate.items():\n",
    "            sum_item += v\n",
    "        #print(sum_item)\n",
    "        rdr = (len(item_candidate) * item_candidate[item] )/ sum_item\n",
    "        print(\"item local_density\", item_candidate[item], sum_item)\n",
    "        print(item, \"has a relative importance:\", rdr)\n",
    "        if rdr > 1:\n",
    "            final_candidate.update({item: rdr})\n",
    "\n",
    "    return final_candidate\n",
    "\n",
    "def get_confidence(final_candidate, global_count, global_count_c, local_count, target):\n",
    "    \n",
    "    confidence = {}\n",
    "    \n",
    "    for k,v in final_candidate.items():\n",
    "        print(k,local_count[k], global_count[k], global_count_c[each])\n",
    "        conf = local_count[k] / max(global_count[k] ,global_count_c[each])\n",
    "        #print(conf)\n",
    "        confidence.update({k : conf})\n",
    "        \n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagel as C\n",
      "inner loop 11\n",
      "Eggs\n",
      "Diaper\n",
      "inner loop 33\n",
      "Cheese\n",
      "Pencil\n",
      "inner loop 44\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 46\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 49\n",
      "Meat\n",
      "Diaper\n",
      "inner loop 50\n",
      "Meat\n",
      "Milk\n",
      "inner loop 69\n",
      "Eggs\n",
      "Meat\n",
      "inner loop 71\n",
      "Eggs\n",
      "Cheese\n",
      "inner loop 78\n",
      "Wine\n",
      "Diaper\n",
      "inner loop 86\n",
      "Diaper\n",
      "Pencil\n",
      "inner loop 107\n",
      "Eggs\n",
      "Diaper\n",
      "inner loop 130\n",
      "Pencil\n",
      "Cheese\n",
      "inner loop 135\n",
      "Diaper\n",
      "Bread\n",
      "inner loop 142\n",
      "Wine\n",
      "Meat\n",
      "['Eggs', 'Diaper', 'Cheese', 'Pencil', 'Cheese', 'Cheese', 'Cheese', 'Cheese', 'Meat', 'Diaper', 'Meat', 'Milk', 'Eggs', 'Meat', 'Eggs', 'Cheese', 'Wine', 'Diaper', 'Diaper', 'Pencil', 'Eggs', 'Diaper', 'Pencil', 'Cheese', 'Diaper', 'Bread', 'Wine', 'Meat']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[0, 1, 7, 6, 4, 4, 1, 3, 2]\n",
      "GC:\n",
      "Bagel 14\n",
      "local density\n",
      "[[0.0], [0.041666666666666664], [0.2916666666666667], [0.25], [0.16666666666666666], [0.16666666666666666], [0.041666666666666664], [0.125], [0.08333333333333333]]\n",
      "*\n",
      "the ld dict: {'Bagel': [0.041666666666666664], 'Bread': [0.25], 'Cheese': [0.16666666666666666], 'Diaper': [0.0], 'Eggs': [0.041666666666666664], 'Meat': [0.125], 'Milk': [0.08333333333333333], 'Pencil': [0.125], 'Wine': [0.16666666666666666]}\n",
      "density ratio:\n",
      "[0.0]\n",
      "[0.0625]\n",
      "Bagel 0.0\n",
      "density ratio:\n",
      "[0.041666666666666664]\n",
      "[0.09027777777777778]\n",
      "Bread 0.4615384615384615\n",
      "density ratio:\n",
      "[0.2916666666666667]\n",
      "[0.1527777777777778]\n",
      "Cheese 1.909090909090909\n",
      "update the item candidate Cheese 0.2916666666666667\n",
      "density ratio:\n",
      "[0.25]\n",
      "[0.09722222222222222]\n",
      "Diaper 2.571428571428571\n",
      "update the item candidate Diaper 0.25\n",
      "density ratio:\n",
      "[0.16666666666666666]\n",
      "[0.08333333333333333]\n",
      "Eggs 2.0\n",
      "update the item candidate Eggs 0.16666666666666666\n",
      "density ratio:\n",
      "[0.16666666666666666]\n",
      "[0.25]\n",
      "Meat 0.6666666666666666\n",
      "density ratio:\n",
      "[0.041666666666666664]\n",
      "[0.08333333333333333]\n",
      "Milk 0.5\n",
      "density ratio:\n",
      "[0.125]\n",
      "[0.0763888888888889]\n",
      "Pencil 1.6363636363636362\n",
      "update the item candidate Pencil 0.125\n",
      "density ratio:\n",
      "[0.08333333333333333]\n",
      "[0.10416666666666667]\n",
      "Wine 0.7999999999999999\n",
      "item local_density 0.2916666666666667 0.8333333333333334\n",
      "Cheese has a relative importance: 1.4000000000000001\n",
      "item local_density 0.25 0.8333333333333334\n",
      "Diaper has a relative importance: 1.2\n",
      "item local_density 0.16666666666666666 0.8333333333333334\n",
      "Eggs has a relative importance: 0.7999999999999999\n",
      "item local_density 0.125 0.8333333333333334\n",
      "Pencil has a relative importance: 0.6\n",
      "the dr dict: {'Bagel': 0.0, 'Bread': 0.4615384615384615, 'Cheese': 1.909090909090909, 'Diaper': 2.571428571428571, 'Eggs': 2.0, 'Meat': 0.6666666666666666, 'Milk': 0.5, 'Pencil': 1.6363636363636362, 'Wine': 0.7999999999999999}\n",
      "the candidate :  {'Cheese': 1.4000000000000001, 'Diaper': 1.2}\n",
      "Cheese 7 22 12\n",
      "Diaper 6 14 12\n",
      "the confidence :  {'Cheese': 0.3181818181818182, 'Diaper': 0.42857142857142855}\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "local_target_item = target_item\n",
    "S1 = cleaned_data[[1]]\n",
    "C = cleaned_data[[3]]\n",
    "global_count = list_gc[1]\n",
    "global_count_c = list_gc[3]\n",
    "\n",
    "global_density = list_gd[1]\n",
    "\n",
    "# currently only work on S1\n",
    "# we just use a fix target to make our life simple in this early development stage\n",
    "target = \"Bagel\"\n",
    "\n",
    "conf, test_candidate = single_target_analysis(target, width, S1, C, global_count, global_count_c, global_density)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop all the reason series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagel\n"
     ]
    }
   ],
   "source": [
    "list_local_count = []\n",
    "list_local_density = []\n",
    "count = 0\n",
    "\n",
    "local_target_item = target_item\n",
    "S1 = cleaned_data[[0]]\n",
    "C = cleaned_data[[3]]\n",
    "global_count = list_gc[0]\n",
    "global_count_c = list_gc[3]\n",
    "\n",
    "global_density = list_gd[0]\n",
    "\n",
    "# currently only work on S1\n",
    "# we just use a fix target to make our life simple in this early development stage\n",
    "target = local_target_item[0]\n",
    "print(target)\n",
    "\n",
    "#test_candidate = singl_target_analysis(target, width, S1, C, global_count, global_count_c, global_density)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_all_series(data):\n",
    "    \n",
    "    \n",
    "    dict_candidate_from_each_series = {}\n",
    "    list_gc, list_gd, target_item = init_data_processing(data)\n",
    "    \n",
    "    # because we use the same target data, thus we initialize it at the begining.\n",
    "    target_flag = len(list_gc) - 1\n",
    "    C = data[[target_flag]]     \n",
    "    global_count_c = list_gc[target_flag]\n",
    "    \n",
    "    local_target_item = target_item\n",
    "    target = local_target_item[0]\n",
    "    print(target)\n",
    "    \n",
    "    for i in range(0, len(list_gc) - 1):\n",
    "        S = data[[i]]    # the data for all reaon series \n",
    "        global_count = list_gc[i]\n",
    "        global_density = list_gd[i]\n",
    "        \n",
    "        print(\"* Exam\")\n",
    "        print(S)\n",
    "        print(global_count)\n",
    "        print(global_density)\n",
    "        conf, test_candidate = single_target_analysis(target, width, S, C, global_count, global_count_c, global_density)\n",
    "        \n",
    "        dict_candidate_from_each_series.update({i : test_candidate})\n",
    "        \n",
    "        # we also want the confidence with its density, so we need to add more code here to make the function work\n",
    "    \n",
    "    return dict_candidate_from_each_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagel\n",
      "* Exam\n",
      "          0\n",
      "0     Bread\n",
      "1     Bread\n",
      "2    Cheese\n",
      "3    Cheese\n",
      "4      Eggs\n",
      "..      ...\n",
      "139   Bagel\n",
      "140  Cheese\n",
      "141  Cheese\n",
      "142   Bread\n",
      "143  Cheese\n",
      "\n",
      "[144 rows x 1 columns]\n",
      "{'Bagel': 19, 'Bread': 27, 'Cheese': 40, 'Diaper': 11, 'Eggs': 7, 'Meat': 11, 'Milk': 7, 'Pencil': 10, 'Wine': 12}\n",
      "{'Bagel': [0.13194444444444445], 'Bread': [0.1875], 'Cheese': [0.2777777777777778], 'Diaper': [0.0763888888888889], 'Eggs': [0.04861111111111111], 'Meat': [0.0763888888888889], 'Milk': [0.04861111111111111], 'Pencil': [0.06944444444444445], 'Wine': [0.08333333333333333]}\n",
      "Bagel as C\n",
      "inner loop 11\n",
      "Bagel\n",
      "Bread\n",
      "inner loop 33\n",
      "Wine\n",
      "Milk\n",
      "inner loop 44\n",
      "Bread\n",
      "Meat\n",
      "inner loop 46\n",
      "Milk\n",
      "Pencil\n",
      "inner loop 49\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 50\n",
      "Eggs\n",
      "Bread\n",
      "inner loop 69\n",
      "Milk\n",
      "Pencil\n",
      "inner loop 71\n",
      "Wine\n",
      "Meat\n",
      "inner loop 78\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 86\n",
      "Bread\n",
      "Bread\n",
      "inner loop 107\n",
      "Bagel\n",
      "Bread\n",
      "inner loop 130\n",
      "Milk\n",
      "Meat\n",
      "inner loop 135\n",
      "Bread\n",
      "Diaper\n",
      "inner loop 142\n",
      "Bread\n",
      "Cheese\n",
      "['Bagel', 'Bread', 'Wine', 'Milk', 'Bread', 'Meat', 'Milk', 'Pencil', 'Cheese', 'Cheese', 'Eggs', 'Bread', 'Milk', 'Pencil', 'Wine', 'Meat', 'Cheese', 'Cheese', 'Bread', 'Bread', 'Bagel', 'Bread', 'Milk', 'Meat', 'Bread', 'Diaper', 'Bread', 'Cheese']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[2, 8, 5, 1, 1, 3, 4, 2, 2]\n",
      "GC:\n",
      "Bagel 14\n",
      "local density\n",
      "[[0.08333333333333333], [0.3333333333333333], [0.20833333333333334], [0.041666666666666664], [0.041666666666666664], [0.125], [0.16666666666666666], [0.08333333333333333], [0.08333333333333333]]\n",
      "*\n",
      "the ld dict: {'Bagel': [0.041666666666666664], 'Bread': [0.25], 'Cheese': [0.16666666666666666], 'Diaper': [0.0], 'Eggs': [0.041666666666666664], 'Meat': [0.125], 'Milk': [0.08333333333333333], 'Pencil': [0.125], 'Wine': [0.16666666666666666]}\n",
      "density ratio:\n",
      "[0.08333333333333333]\n",
      "[0.13194444444444445]\n",
      "Bagel 0.631578947368421\n",
      "density ratio:\n",
      "[0.3333333333333333]\n",
      "[0.1875]\n",
      "Bread 1.7777777777777777\n",
      "update the item candidate Bread 0.3333333333333333\n",
      "density ratio:\n",
      "[0.20833333333333334]\n",
      "[0.2777777777777778]\n",
      "Cheese 0.75\n",
      "density ratio:\n",
      "[0.041666666666666664]\n",
      "[0.0763888888888889]\n",
      "Diaper 0.5454545454545454\n",
      "density ratio:\n",
      "[0.041666666666666664]\n",
      "[0.04861111111111111]\n",
      "Eggs 0.8571428571428571\n",
      "density ratio:\n",
      "[0.125]\n",
      "[0.0763888888888889]\n",
      "Meat 1.6363636363636362\n",
      "update the item candidate Meat 0.125\n",
      "density ratio:\n",
      "[0.16666666666666666]\n",
      "[0.04861111111111111]\n",
      "Milk 3.4285714285714284\n",
      "update the item candidate Milk 0.16666666666666666\n",
      "density ratio:\n",
      "[0.08333333333333333]\n",
      "[0.06944444444444445]\n",
      "Pencil 1.2\n",
      "update the item candidate Pencil 0.08333333333333333\n",
      "density ratio:\n",
      "[0.08333333333333333]\n",
      "[0.08333333333333333]\n",
      "Wine 1.0\n",
      "item local_density 0.3333333333333333 0.7083333333333334\n",
      "Bread has a relative importance: 1.8823529411764703\n",
      "item local_density 0.125 0.7083333333333334\n",
      "Meat has a relative importance: 0.7058823529411764\n",
      "item local_density 0.16666666666666666 0.7083333333333334\n",
      "Milk has a relative importance: 0.9411764705882352\n",
      "item local_density 0.08333333333333333 0.7083333333333334\n",
      "Pencil has a relative importance: 0.4705882352941176\n",
      "the dr dict: {'Bagel': 0.631578947368421, 'Bread': 1.7777777777777777, 'Cheese': 0.75, 'Diaper': 0.5454545454545454, 'Eggs': 0.8571428571428571, 'Meat': 1.6363636363636362, 'Milk': 3.4285714285714284, 'Pencil': 1.2, 'Wine': 1.0}\n",
      "the candidate :  {'Bread': 1.8823529411764703}\n",
      "Bread 8 27 12\n",
      "the confidence :  {'Bread': 0.2962962962962963}\n",
      "===========\n",
      "* Exam\n",
      "          1\n",
      "0      Wine\n",
      "1    Cheese\n",
      "2      Meat\n",
      "3      Meat\n",
      "4     Bread\n",
      "..      ...\n",
      "139   Bread\n",
      "140    Meat\n",
      "141    Meat\n",
      "142    Wine\n",
      "143    Meat\n",
      "\n",
      "[144 rows x 1 columns]\n",
      "{'Bagel': 9, 'Bread': 13, 'Cheese': 22, 'Diaper': 14, 'Eggs': 12, 'Meat': 36, 'Milk': 12, 'Pencil': 11, 'Wine': 15}\n",
      "{'Bagel': [0.0625], 'Bread': [0.09027777777777778], 'Cheese': [0.1527777777777778], 'Diaper': [0.09722222222222222], 'Eggs': [0.08333333333333333], 'Meat': [0.25], 'Milk': [0.08333333333333333], 'Pencil': [0.0763888888888889], 'Wine': [0.10416666666666667]}\n",
      "Bagel as C\n",
      "inner loop 11\n",
      "Eggs\n",
      "Diaper\n",
      "inner loop 33\n",
      "Cheese\n",
      "Pencil\n",
      "inner loop 44\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 46\n",
      "Cheese\n",
      "Cheese\n",
      "inner loop 49\n",
      "Meat\n",
      "Diaper\n",
      "inner loop 50\n",
      "Meat\n",
      "Milk\n",
      "inner loop 69\n",
      "Eggs\n",
      "Meat\n",
      "inner loop 71\n",
      "Eggs\n",
      "Cheese\n",
      "inner loop 78\n",
      "Wine\n",
      "Diaper\n",
      "inner loop 86\n",
      "Diaper\n",
      "Pencil\n",
      "inner loop 107\n",
      "Eggs\n",
      "Diaper\n",
      "inner loop 130\n",
      "Pencil\n",
      "Cheese\n",
      "inner loop 135\n",
      "Diaper\n",
      "Bread\n",
      "inner loop 142\n",
      "Wine\n",
      "Meat\n",
      "['Eggs', 'Diaper', 'Cheese', 'Pencil', 'Cheese', 'Cheese', 'Cheese', 'Cheese', 'Meat', 'Diaper', 'Meat', 'Milk', 'Eggs', 'Meat', 'Eggs', 'Cheese', 'Wine', 'Diaper', 'Diaper', 'Pencil', 'Eggs', 'Diaper', 'Pencil', 'Cheese', 'Diaper', 'Bread', 'Wine', 'Meat']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[0, 1, 7, 6, 4, 4, 1, 3, 2]\n",
      "GC:\n",
      "Bagel 14\n",
      "local density\n",
      "[[0.0], [0.041666666666666664], [0.2916666666666667], [0.25], [0.16666666666666666], [0.16666666666666666], [0.041666666666666664], [0.125], [0.08333333333333333]]\n",
      "*\n",
      "the ld dict: {'Bagel': [0.041666666666666664], 'Bread': [0.25], 'Cheese': [0.16666666666666666], 'Diaper': [0.0], 'Eggs': [0.041666666666666664], 'Meat': [0.125], 'Milk': [0.08333333333333333], 'Pencil': [0.125], 'Wine': [0.16666666666666666]}\n",
      "density ratio:\n",
      "[0.0]\n",
      "[0.0625]\n",
      "Bagel 0.0\n",
      "density ratio:\n",
      "[0.041666666666666664]\n",
      "[0.09027777777777778]\n",
      "Bread 0.4615384615384615\n",
      "density ratio:\n",
      "[0.2916666666666667]\n",
      "[0.1527777777777778]\n",
      "Cheese 1.909090909090909\n",
      "update the item candidate Cheese 0.2916666666666667\n",
      "density ratio:\n",
      "[0.25]\n",
      "[0.09722222222222222]\n",
      "Diaper 2.571428571428571\n",
      "update the item candidate Diaper 0.25\n",
      "density ratio:\n",
      "[0.16666666666666666]\n",
      "[0.08333333333333333]\n",
      "Eggs 2.0\n",
      "update the item candidate Eggs 0.16666666666666666\n",
      "density ratio:\n",
      "[0.16666666666666666]\n",
      "[0.25]\n",
      "Meat 0.6666666666666666\n",
      "density ratio:\n",
      "[0.041666666666666664]\n",
      "[0.08333333333333333]\n",
      "Milk 0.5\n",
      "density ratio:\n",
      "[0.125]\n",
      "[0.0763888888888889]\n",
      "Pencil 1.6363636363636362\n",
      "update the item candidate Pencil 0.125\n",
      "density ratio:\n",
      "[0.08333333333333333]\n",
      "[0.10416666666666667]\n",
      "Wine 0.7999999999999999\n",
      "item local_density 0.2916666666666667 0.8333333333333334\n",
      "Cheese has a relative importance: 1.4000000000000001\n",
      "item local_density 0.25 0.8333333333333334\n",
      "Diaper has a relative importance: 1.2\n",
      "item local_density 0.16666666666666666 0.8333333333333334\n",
      "Eggs has a relative importance: 0.7999999999999999\n",
      "item local_density 0.125 0.8333333333333334\n",
      "Pencil has a relative importance: 0.6\n",
      "the dr dict: {'Bagel': 0.0, 'Bread': 0.4615384615384615, 'Cheese': 1.909090909090909, 'Diaper': 2.571428571428571, 'Eggs': 2.0, 'Meat': 0.6666666666666666, 'Milk': 0.5, 'Pencil': 1.6363636363636362, 'Wine': 0.7999999999999999}\n",
      "the candidate :  {'Cheese': 1.4000000000000001, 'Diaper': 1.2}\n",
      "Cheese 7 22 12\n",
      "Diaper 6 14 12\n",
      "the confidence :  {'Cheese': 0.3181818181818182, 'Diaper': 0.42857142857142855}\n",
      "===========\n",
      "* Exam\n",
      "          2\n",
      "0      Eggs\n",
      "1      Meat\n",
      "2      Eggs\n",
      "3      Eggs\n",
      "4      Wine\n",
      "..      ...\n",
      "139  Diaper\n",
      "140    Eggs\n",
      "141    Eggs\n",
      "142    Eggs\n",
      "143    Eggs\n",
      "\n",
      "[144 rows x 1 columns]\n",
      "{'Bagel': 11, 'Bread': 11, 'Cheese': 9, 'Diaper': 18, 'Eggs': 40, 'Meat': 19, 'Milk': 14, 'Pencil': 12, 'Wine': 10}\n",
      "{'Bagel': [0.0763888888888889], 'Bread': [0.0763888888888889], 'Cheese': [0.0625], 'Diaper': [0.125], 'Eggs': [0.2777777777777778], 'Meat': [0.13194444444444445], 'Milk': [0.09722222222222222], 'Pencil': [0.08333333333333333], 'Wine': [0.06944444444444445]}\n",
      "Bagel as C\n",
      "inner loop 11\n",
      "Meat\n",
      "Pencil\n",
      "inner loop 33\n",
      "Bagel\n",
      "Cheese\n",
      "inner loop 44\n",
      "Wine\n",
      "Pencil\n",
      "inner loop 46\n",
      "Wine\n",
      "Wine\n",
      "inner loop 49\n",
      "Eggs\n",
      "Pencil\n",
      "inner loop 50\n",
      "Wine\n",
      "Eggs\n",
      "inner loop 69\n",
      "Bread\n",
      "Bread\n",
      "inner loop 71\n",
      "Bread\n",
      "Eggs\n",
      "inner loop 78\n",
      "Meat\n",
      "Eggs\n",
      "inner loop 86\n",
      "Pencil\n",
      "Diaper\n",
      "inner loop 107\n",
      "Meat\n",
      "Pencil\n",
      "inner loop 130\n",
      "Cheese\n",
      "Diaper\n",
      "inner loop 135\n",
      "Milk\n",
      "Cheese\n",
      "inner loop 142\n",
      "Eggs\n",
      "Eggs\n",
      "['Meat', 'Pencil', 'Bagel', 'Cheese', 'Wine', 'Pencil', 'Wine', 'Wine', 'Eggs', 'Pencil', 'Wine', 'Eggs', 'Bread', 'Bread', 'Bread', 'Eggs', 'Meat', 'Eggs', 'Pencil', 'Diaper', 'Meat', 'Pencil', 'Cheese', 'Diaper', 'Milk', 'Cheese', 'Eggs', 'Eggs']\n",
      "* S1->C local count\n",
      "['Bagel', 'Bread', 'Cheese', 'Diaper', 'Eggs', 'Meat', 'Milk', 'Pencil', 'Wine']\n",
      "[1, 3, 3, 2, 6, 3, 1, 5, 4]\n",
      "GC:\n",
      "Bagel 14\n",
      "local density\n",
      "[[0.041666666666666664], [0.125], [0.125], [0.08333333333333333], [0.25], [0.125], [0.041666666666666664], [0.20833333333333334], [0.16666666666666666]]\n",
      "*\n",
      "the ld dict: {'Bagel': [0.041666666666666664], 'Bread': [0.25], 'Cheese': [0.16666666666666666], 'Diaper': [0.0], 'Eggs': [0.041666666666666664], 'Meat': [0.125], 'Milk': [0.08333333333333333], 'Pencil': [0.125], 'Wine': [0.16666666666666666]}\n",
      "density ratio:\n",
      "[0.041666666666666664]\n",
      "[0.0763888888888889]\n",
      "Bagel 0.5454545454545454\n",
      "density ratio:\n",
      "[0.125]\n",
      "[0.0763888888888889]\n",
      "Bread 1.6363636363636362\n",
      "update the item candidate Bread 0.125\n",
      "density ratio:\n",
      "[0.125]\n",
      "[0.0625]\n",
      "Cheese 2.0\n",
      "update the item candidate Cheese 0.125\n",
      "density ratio:\n",
      "[0.08333333333333333]\n",
      "[0.125]\n",
      "Diaper 0.6666666666666666\n",
      "density ratio:\n",
      "[0.25]\n",
      "[0.2777777777777778]\n",
      "Eggs 0.8999999999999999\n",
      "density ratio:\n",
      "[0.125]\n",
      "[0.13194444444444445]\n",
      "Meat 0.9473684210526315\n",
      "density ratio:\n",
      "[0.041666666666666664]\n",
      "[0.09722222222222222]\n",
      "Milk 0.42857142857142855\n",
      "density ratio:\n",
      "[0.20833333333333334]\n",
      "[0.08333333333333333]\n",
      "Pencil 2.5000000000000004\n",
      "update the item candidate Pencil 0.20833333333333334\n",
      "density ratio:\n",
      "[0.16666666666666666]\n",
      "[0.06944444444444445]\n",
      "Wine 2.4\n",
      "update the item candidate Wine 0.16666666666666666\n",
      "item local_density 0.125 0.625\n",
      "Bread has a relative importance: 0.8\n",
      "item local_density 0.125 0.625\n",
      "Cheese has a relative importance: 0.8\n",
      "item local_density 0.20833333333333334 0.625\n",
      "Pencil has a relative importance: 1.3333333333333335\n",
      "item local_density 0.16666666666666666 0.625\n",
      "Wine has a relative importance: 1.0666666666666667\n",
      "the dr dict: {'Bagel': 0.5454545454545454, 'Bread': 1.6363636363636362, 'Cheese': 2.0, 'Diaper': 0.6666666666666666, 'Eggs': 0.8999999999999999, 'Meat': 0.9473684210526315, 'Milk': 0.42857142857142855, 'Pencil': 2.5000000000000004, 'Wine': 2.4}\n",
      "the candidate :  {'Pencil': 1.3333333333333335, 'Wine': 1.0666666666666667}\n",
      "Pencil 5 12 12\n",
      "Wine 4 10 12\n",
      "the confidence :  {'Pencil': 0.4166666666666667, 'Wine': 0.3333333333333333}\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "dict_new = loop_all_series(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'Bread': 0.2962962962962963},\n",
       " 1: {'Cheese': 0.3181818181818182, 'Diaper': 0.42857142857142855},\n",
       " 2: {'Pencil': 0.4166666666666667, 'Wine': 0.3333333333333333}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we need to loop and setting up the combination of candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'Bread': 0.2962962962962963}\n",
      "1\n",
      "{'Cheese': 0.3181818181818182, 'Diaper': 0.42857142857142855}\n",
      "2\n",
      "{'Pencil': 0.4166666666666667, 'Wine': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "for i in list(dict_new):\n",
    "    print(i)\n",
    "    print(dict_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bread 0.2962962962962963\n",
      "Cheese 0.3181818181818182\n",
      "Diaper 0.42857142857142855\n",
      "Pencil 0.4166666666666667\n",
      "Wine 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in list(dict_new):\n",
    "    for k,v in dict_new[i].items():\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 2\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3-1):\n",
    "    for j in range(i+1,3):\n",
    "        print(i , j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_name_order = cleaned_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'Bread': 0.2962962962962963},\n",
       " 1: {'Cheese': 0.3181818181818182, 'Diaper': 0.42857142857142855},\n",
       " 2: {'Pencil': 0.4166666666666667, 'Wine': 0.3333333333333333}}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "direct merge: {0: 'Bread', 1: 'Cheese'}\n",
      "direct merge: {0: 'Bread', 1: 'Diaper'}\n",
      "direct merge: {0: 'Bread', 2: 'Pencil'}\n",
      "direct merge: {0: 'Bread', 2: 'Wine'}\n",
      "1\n",
      "direct merge: {1: 'Cheese', 2: 'Pencil'}\n",
      "direct merge: {1: 'Cheese', 2: 'Wine'}\n",
      "direct merge: {1: 'Diaper', 2: 'Pencil'}\n",
      "direct merge: {1: 'Diaper', 2: 'Wine'}\n"
     ]
    }
   ],
   "source": [
    "the_initial_space = list(dict_new)\n",
    "L2_item_set = [] # we will get a list of dictrionary\n",
    "\n",
    "for i in range(len(the_initial_space) -1 ):\n",
    "    print(the_initial_space[i])\n",
    "    #print(\"space candidate \",list(dict_new[the_initial_space[i]]))\n",
    "    \n",
    "    for j in range(i+1, len(the_initial_space)):\n",
    "        \n",
    "        first_group_candidate = list(dict_new[the_initial_space[i]])\n",
    "        second_group_candidate = list(dict_new[the_initial_space[j]])\n",
    "        \n",
    "        for x in range(len(first_group_candidate)):\n",
    "            for y in range(len(second_group_candidate)):\n",
    "                L2_item_set.append (merge_candidate(the_initial_space[i],first_group_candidate[x], the_initial_space[j], second_group_candidate[y], space_name_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_candidate(space1, item1, space2, item2, order):\n",
    "    \n",
    "    temp_dict = {}\n",
    "    \n",
    "    if isinstance(space1, list): \n",
    "        print(\"your object is a list, proceeding for L > 2 \") \n",
    "        # this means the item we received will be multiple, we will have to\n",
    "        # apply special check for them\n",
    "        print(space1)\n",
    "        print(len(space1))\n",
    "        print(space2)\n",
    "        print(len(space2))\n",
    "        \n",
    "        if len(space1) == len(space2):\n",
    "            mark = len(space1)\n",
    "            space_same_count = 0  \n",
    "            print(\"same length\")\n",
    "        \n",
    "            # test if the two space are only different in 1 space\n",
    "            for i in range(len(space1)):\n",
    "                for j in range(len(space1)):\n",
    "                    if space1[i] == space2[j]:\n",
    "                        space_same_count += 1\n",
    "                    \n",
    "            # if the difference in space is 1, we are going to check if the same space has same item\n",
    "            # we need to trace the order of space\n",
    "            \n",
    "            if (mark-space_same_count) == 1:\n",
    "                print(\"space allow to merge\")\n",
    "                temp_dict = merge_item_list(item1, item2, order)\n",
    "                return temp_dict\n",
    "            else:\n",
    "                print(\"not allow to merge\")\n",
    "        \n",
    "            \n",
    "        print(\"====end====\")\n",
    "        \n",
    "    else: \n",
    "        print(\"your object is not a list, this is the initial L2\") \n",
    "    \n",
    "        if space1 != space2:\n",
    "            temp_dict.update({space1 : item1})\n",
    "            temp_dict.update({space2 : item2})\n",
    "\n",
    "        print(temp_dict)\n",
    "    return temp_dict \n",
    "\n",
    "\n",
    "def merge_item_list(item1, item2, order):\n",
    "    length = len(item1)\n",
    "    count = 0\n",
    "    same_space = []\n",
    "    temp = item1.copy()\n",
    "    temp2 = item2.copy()\n",
    "    print(item1)\n",
    "    print(item2)\n",
    "    for i in order:\n",
    "        if (i in item1) & (i in item2):\n",
    "            if item1[i] == item2[i]:\n",
    "                count += 1\n",
    "                print(i, \"is the same space\")\n",
    "                same_space.append(i)\n",
    "    \n",
    "    if (length - count) == 1:\n",
    "        # we will merge item here with the support of order\n",
    "        print(\"item allow to merge\")\n",
    "        for j in range(len(same_space)):\n",
    "            del temp2[same_space[j]]\n",
    "        \n",
    "        temp.update(temp2.items())\n",
    "        return temp\n",
    "        \n",
    "    return {}\n",
    "\n",
    "def check_duplicate(all_rule_set, item_set):\n",
    "    \n",
    "    result = False\n",
    "    temp = {}\n",
    "    \n",
    "    for i in range(len(all_rule_set)):\n",
    "        count = 0\n",
    "        temp = all_rule_set[i]\n",
    "        mark = len(list(temp))\n",
    "        \n",
    "        # if there is a rule exist, has the same with item_set, we consider this is dupulicate\n",
    "        \n",
    "        for k,v in temp.items():\n",
    "            if k in item_set :\n",
    "                if v == item_set[k]:\n",
    "                    count += 1\n",
    "                    if count == mark:\n",
    "                        result = True\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 'Bread', 1: 'Cheese'},\n",
       " {0: 'Bread', 1: 'Diaper'},\n",
       " {0: 'Bread', 2: 'Pencil'},\n",
       " {0: 'Bread', 2: 'Wine'},\n",
       " {1: 'Cheese', 2: 'Pencil'},\n",
       " {1: 'Cheese', 2: 'Wine'},\n",
       " {1: 'Diaper', 2: 'Pencil'},\n",
       " {1: 'Diaper', 2: 'Wine'}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_item_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(L2_item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = L2_item_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = L2_item_set[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test2[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'Pencil'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.update(test2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bread', 1: 'Diaper', 2: 'Pencil'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create L3 and Ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ln = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1]\n",
      "2\n",
      "[0, 1, 2]\n",
      "3\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1]\n",
      "2\n",
      "[0, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 1: 'Cheese'}\n",
      "{0: 'Bread', 2: 'Pencil'}\n",
      "0 is the same space\n",
      "item allow to merge\n",
      "{0: 'Bread', 1: 'Cheese', 2: 'Pencil'}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1]\n",
      "2\n",
      "[0, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 1: 'Cheese'}\n",
      "{0: 'Bread', 2: 'Wine'}\n",
      "0 is the same space\n",
      "item allow to merge\n",
      "{0: 'Bread', 1: 'Cheese', 2: 'Wine'}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1]\n",
      "2\n",
      "[2]\n",
      "1\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 1: 'Cheese'}\n",
      "{1: 'Cheese', 2: 'Wine'}\n",
      "1 is the same space\n",
      "item allow to merge\n",
      "{0: 'Bread', 1: 'Cheese', 2: 'Wine'}\n",
      "duplicate\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 1: 'Cheese'}\n",
      "{1: 'Diaper', 2: 'Pencil'}\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 1: 'Cheese'}\n",
      "{1: 'Diaper', 2: 'Wine'}\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1, 2]\n",
      "3\n",
      "[0, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1, 2]\n",
      "3\n",
      "[0, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1, 2]\n",
      "3\n",
      "[2]\n",
      "1\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1, 2]\n",
      "3\n",
      "[1, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1, 2]\n",
      "3\n",
      "[1, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1, 2]\n",
      "3\n",
      "[1, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[0, 2]\n",
      "2\n",
      "same length\n",
      "not allow to merge\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[2]\n",
      "1\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 2: 'Pencil'}\n",
      "{1: 'Cheese', 2: 'Wine'}\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 2: 'Pencil'}\n",
      "{1: 'Diaper', 2: 'Pencil'}\n",
      "2 is the same space\n",
      "item allow to merge\n",
      "{0: 'Bread', 2: 'Pencil', 1: 'Diaper'}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 2: 'Pencil'}\n",
      "{1: 'Diaper', 2: 'Wine'}\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[2]\n",
      "1\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 2: 'Wine'}\n",
      "{1: 'Cheese', 2: 'Wine'}\n",
      "2 is the same space\n",
      "item allow to merge\n",
      "{0: 'Bread', 2: 'Wine', 1: 'Cheese'}\n",
      "duplicate\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 2: 'Wine'}\n",
      "{1: 'Diaper', 2: 'Pencil'}\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 2: 'Wine'}\n",
      "{1: 'Diaper', 2: 'Wine'}\n",
      "2 is the same space\n",
      "item allow to merge\n",
      "{0: 'Bread', 2: 'Wine', 1: 'Diaper'}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[2]\n",
      "1\n",
      "[1, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[2]\n",
      "1\n",
      "[1, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[2]\n",
      "1\n",
      "[1, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[1, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "not allow to merge\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[1, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "not allow to merge\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[1, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "not allow to merge\n",
      "====end====\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(0,len(L2_item_set)-1):\n",
    "    for j in range(i+1,len(L2_item_set)):\n",
    "        #print(list(L2_item_set[i]), list(L2_item_set[j]))\n",
    "        #print(L2_item_set[i], L2_item_set[j])\n",
    "\n",
    "        item_set = merge_candidate(list(L2_item_set[i]),L2_item_set[i], list(L2_item_set[j]), L2_item_set[j],space_name_order)\n",
    "        print(item_set)\n",
    "\n",
    "        if len(item_set) > 0:\n",
    "            # we need to check if duplicate\n",
    "            if check_duplicate(Ln,item_set):\n",
    "                print(\"duplicate\")\n",
    "            else:\n",
    "                Ln.append(item_set)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 'Bread', 1: 'Cheese'},\n",
       " {0: 'Bread', 1: 'Diaper', 2: 'Pencil'},\n",
       " {0: 'Bread', 2: 'Pencil'},\n",
       " {0: 'Bread', 2: 'Wine'},\n",
       " {2: 'Pencil'},\n",
       " {1: 'Cheese', 2: 'Wine'},\n",
       " {1: 'Diaper', 2: 'Pencil'},\n",
       " {1: 'Diaper', 2: 'Wine'}]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_item_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 'Bread', 1: 'Cheese', 2: 'Pencil'},\n",
       " {0: 'Bread', 1: 'Cheese', 2: 'Wine'},\n",
       " {0: 'Bread', 2: 'Pencil', 1: 'Diaper'},\n",
       " {0: 'Bread', 2: 'Wine', 1: 'Diaper'}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_L2(candidate_dict, space_name_order):\n",
    "    the_initial_space = list(dict_new)\n",
    "    L2_item_set = [] # we will get a list of dictrionary\n",
    "    \n",
    "    for j in range(i+1, len(the_initial_space)):\n",
    "        \n",
    "        first_group_candidate = list(dict_new[the_initial_space[i]])\n",
    "        second_group_candidate = list(dict_new[the_initial_space[j]])\n",
    "        \n",
    "        for x in range(len(first_group_candidate)):\n",
    "            for y in range(len(second_group_candidate)):\n",
    "                L2_item_set.append (merge_candidate(the_initial_space[i],first_group_candidate[x], the_initial_space[j], second_group_candidate[y], space_name_order))\n",
    "    \n",
    "    return L2_item_set\n",
    "\n",
    "\n",
    "def create_Ln(candidate_list, space_name_order):\n",
    "\n",
    "    Ln = []\n",
    "    for i in range(0,len(candidate_list)-1):\n",
    "        for j in range(i+1,len(candidate_list)):\n",
    "            #print(list(L2_item_set[i]), list(L2_item_set[j]))\n",
    "            #print(L2_item_set[i], L2_item_set[j])\n",
    "\n",
    "            item_set = merge_candidate(list(candidate_list[i]),candidate_list[i], list(candidate_list[j]), candidate_list[j],space_name_order)\n",
    "            print(item_set)\n",
    "\n",
    "            if len(item_set) > 0:\n",
    "                # we need to check if duplicate\n",
    "                if check_duplicate(Ln,item_set):\n",
    "                    print(\"duplicate\")\n",
    "                else:\n",
    "                    Ln.append(item_set)\n",
    "                    \n",
    "    return Ln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create global count and density for conjunction item set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bread', 1: 'Cheese'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_item_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bagel'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = local_target_item[0]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        Meat\n",
       "1      Diaper\n",
       "2        Milk\n",
       "3        Milk\n",
       "4      Pencil\n",
       "        ...  \n",
       "139    Cheese\n",
       "140      Milk\n",
       "141      Milk\n",
       "142     Bagel\n",
       "143      Milk\n",
       "Name: 3, Length: 144, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =len(cleaned_data.columns)\n",
    "print(test)\n",
    "cleaned_data[test -1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    Bread\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[1][[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_set_count(item_set, data):\n",
    "    \n",
    "    # we need to go over the all data, find how many times the item set is appear.\n",
    "    # because we want to deal with the count of item set, we need to use different logic\n",
    "    \n",
    "    # here we received a muliple item set, and a data.\n",
    "    # we are going to count how many times it appear\n",
    "    # thus we return number\n",
    "\n",
    "        \n",
    "    count = 0\n",
    "    space = list(item_set)\n",
    "    mark = len(space)\n",
    "    flag = 0\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        for k,v in item_set.items():\n",
    "            if data[k][[i]].values[0] == v:\n",
    "                #print(data[k][[i]].values[0])\n",
    "                flag += 1\n",
    "        \n",
    "        if mark == flag:\n",
    "            #print(\"item match in\", i)\n",
    "            count += 1\n",
    "            flag = 0\n",
    "        else:\n",
    "            flag = 0\n",
    "            #count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "def get_gc_gd_for_item_set(item_set, data):\n",
    "    \n",
    "    list_space = []\n",
    "    list_gc = []\n",
    "    list_item = []\n",
    "    list_gd = []\n",
    "    # get global count\n",
    "    for i in range(len(item_set)):\n",
    "        #print(item_set[i])\n",
    "        temp = []\n",
    "        for k,v in item_set[i].items():\n",
    "            temp.append(v)\n",
    "        list_space.append(list(item_set[i]))\n",
    "        list_item.append(temp)\n",
    "        list_gc.append(get_item_set_count(item_set[i],data))\n",
    "\n",
    "    print(list_space)\n",
    "    print(list_gc)\n",
    "    print(list_item)\n",
    "    \n",
    "    # get global densitys\n",
    "    list_gd = [[f/len(data)] for f in list_gc]\n",
    "    print(list_gd)\n",
    "    \n",
    "    return list_space, list_item, list_gc, list_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_item_set_count(L2_item_set[0], cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [0, 1, 2], [0, 2], [0, 2], [2], [1, 2], [1, 2], [1, 2]]\n",
      "[3, 3, 7, 1, 12, 4, 5, 0]\n",
      "[['Bread', 'Cheese'], ['Bread', 'Diaper', 'Pencil'], ['Bread', 'Pencil'], ['Bread', 'Wine'], ['Pencil'], ['Cheese', 'Wine'], ['Diaper', 'Pencil'], ['Diaper', 'Wine']]\n",
      "[[0.020833333333333332], [0.020833333333333332], [0.04861111111111111], [0.006944444444444444], [0.08333333333333333], [0.027777777777777776], [0.034722222222222224], [0.0]]\n"
     ]
    }
   ],
   "source": [
    "list_space, list_item, list_gc, list_gd = get_gc_gd_for_item_set(L2_item_set, cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = cleaned_data[11:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>Bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagel</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2      3\n",
       "11  Bread  Diaper  Pencil  Bagel\n",
       "12  Bagel  Cheese    Milk   Meat"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>Bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagel</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2      3\n",
       "0  Bread  Diaper  Pencil  Bagel\n",
       "1  Bagel  Cheese    Milk   Meat"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.reset_index(drop=True, inplace=True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we now try to get local denisty and local count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gc_gd_lc_ld_for_item_set(item_set, data , width = 2, target = \"Bagel\"):\n",
    "    \n",
    "    list_space = []\n",
    "    list_gc = []\n",
    "    list_item = []\n",
    "    list_gd = []\n",
    "    list_lc = []\n",
    "    list_ld = []\n",
    "    list_dr = []\n",
    "    list_conf = []\n",
    "    # get global count\n",
    "    # also the local count\n",
    "    for i in range(len(item_set)):\n",
    "        #print(item_set[i])\n",
    "        temp = []\n",
    "        for k,v in item_set[i].items():\n",
    "            temp.append(v)\n",
    "        list_space.append(list(item_set[i]))\n",
    "        list_item.append(temp)\n",
    "        list_gc.append(get_item_set_count(item_set[i],data))\n",
    "    \n",
    "    # get global density\n",
    "    list_gd = [[f/len(data)] for f in list_gc]\n",
    "    #print(list_gd)\n",
    "    \n",
    "    # get local count & local density\n",
    "    if isinstance(target, list):\n",
    "        # we have to loop all targets\n",
    "        print()\n",
    "    else: \n",
    "        # we only deal with one target\n",
    "        for i in range(len(item_set)):\n",
    "            local_item_set_count, global_target = count_item_set_in_window(data, width, item_set[i], target)\n",
    "            list_lc.append(local_item_set_count)\n",
    "            list_ld.append(local_item_set_count / (width*global_target))\n",
    "            #print(list_gd[i])\n",
    "            if list_gd[i][0] == 0:\n",
    "                list_dr.append(0)\n",
    "            else:\n",
    "                list_dr.append((local_item_set_count / (width*global_target)) / list_gd[i][0])\n",
    "            list_conf.append(local_item_set_count / max(list_gc[i],global_target) )\n",
    "        \n",
    "    # we calculate the next round cancadidate and relative density ratio here\n",
    "    result = []\n",
    "    candidate_index = []\n",
    "    sum_item = 0\n",
    "    for i in range(len(list_dr)):\n",
    "        if list_dr[i] > 1:\n",
    "            temp = [list_space[i], list_item[i],[target],list_dr[i] ,list_conf[i]]\n",
    "            result.append(temp)\n",
    "            candidate_index.append(i)\n",
    "            sum_item += list_ld[i]  #  for sum of significant ld , used in rdr calculation\n",
    "            \n",
    "            print(\"space:\")\n",
    "            print(list_space[i])\n",
    "            print(\"item:\")\n",
    "            print(list_item[i])\n",
    "            print(\"density ratio:\")\n",
    "            print(list_dr[i])\n",
    "            print(\"confidence:\")\n",
    "            print(list_conf[i])\n",
    "    \n",
    "    final_candidate = []\n",
    "    print(\"creating the final candidate\")\n",
    "    print(\"the index\", candidate_index)\n",
    "    for i in range(len(candidate_index)):   \n",
    "        rdr = (len(candidate_index) * list_ld[candidate_index[i]] )/ sum_item\n",
    "        print(list_item[candidate_index[i]], \"rdr:\", rdr)\n",
    "        print(list_space[candidate_index[i]], \"rdr:\", rdr)\n",
    "        if rdr > 1:\n",
    "            temp_candidate = {}\n",
    "            for j in range(len(list_item[candidate_index[i]])):\n",
    "                temp_candidate.update({list_space[candidate_index[i]][j] : list_item[candidate_index[i]][j]})\n",
    "            \n",
    "            final_candidate.append(temp_candidate)\n",
    "    \n",
    "    print(final_candidate)\n",
    "    \n",
    "    return result, final_candidate\n",
    "\n",
    "def count_item_set(data, item_set, start_index, end_index):\n",
    "    c = 0\n",
    "    local_data = data[start_index:end_index].copy()\n",
    "    local_data.reset_index(drop=True, inplace=True)\n",
    "    #print(\"local_data\", local_data)\n",
    "    c = get_item_set_count(item_set, local_data)\n",
    "        \n",
    "    return c \n",
    "\n",
    "def count_item_set_in_window(data, width, item_set, target):\n",
    "    \n",
    "    count = 0\n",
    "    target_count = 0\n",
    "    length = int(len(data.index))\n",
    "    #print(length)\n",
    "    #print(width)\n",
    "    for i in range(0,length ,width):\n",
    "        for j in range(i,i+width):\n",
    "            if data[len(data.columns) -1][j] == target:\n",
    "                # if in a block the target item appear\n",
    "                # add count for this item appear \n",
    "                target_count += 1\n",
    "                #print(data[len(data.columns) -1][j])\n",
    "                #print(\"window:\", i)\n",
    "                count += count_item_set(data, item_set, i, i+width)\n",
    "    return count,target_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space:\n",
      "[0, 1]\n",
      "item:\n",
      "['Bread', 'Cheese']\n",
      "density ratio:\n",
      "1.7142857142857142\n",
      "confidence:\n",
      "0.07142857142857142\n",
      "space:\n",
      "[0, 1, 2]\n",
      "item:\n",
      "['Bread', 'Diaper', 'Pencil']\n",
      "density ratio:\n",
      "5.142857142857143\n",
      "confidence:\n",
      "0.21428571428571427\n",
      "space:\n",
      "[0, 2]\n",
      "item:\n",
      "['Bread', 'Pencil']\n",
      "density ratio:\n",
      "2.204081632653061\n",
      "confidence:\n",
      "0.21428571428571427\n",
      "space:\n",
      "[0, 2]\n",
      "item:\n",
      "['Bread', 'Wine']\n",
      "density ratio:\n",
      "5.142857142857143\n",
      "confidence:\n",
      "0.07142857142857142\n",
      "space:\n",
      "[2]\n",
      "item:\n",
      "['Pencil']\n",
      "density ratio:\n",
      "2.1428571428571432\n",
      "confidence:\n",
      "0.35714285714285715\n",
      "space:\n",
      "[1, 2]\n",
      "item:\n",
      "['Cheese', 'Wine']\n",
      "density ratio:\n",
      "3.857142857142857\n",
      "confidence:\n",
      "0.21428571428571427\n",
      "space:\n",
      "[1, 2]\n",
      "item:\n",
      "['Diaper', 'Pencil']\n",
      "density ratio:\n",
      "4.114285714285714\n",
      "confidence:\n",
      "0.2857142857142857\n",
      "creating the final candidate\n",
      "the index [0, 1, 2, 3, 4, 5, 6]\n",
      "['Bread', 'Cheese'] rdr: 0.35000000000000003\n",
      "[0, 1] rdr: 0.35000000000000003\n",
      "['Bread', 'Diaper', 'Pencil'] rdr: 1.05\n",
      "[0, 1, 2] rdr: 1.05\n",
      "['Bread', 'Pencil'] rdr: 1.05\n",
      "[0, 2] rdr: 1.05\n",
      "['Bread', 'Wine'] rdr: 0.35000000000000003\n",
      "[0, 2] rdr: 0.35000000000000003\n",
      "['Pencil'] rdr: 1.7500000000000002\n",
      "[2] rdr: 1.7500000000000002\n",
      "['Cheese', 'Wine'] rdr: 1.05\n",
      "[1, 2] rdr: 1.05\n",
      "['Diaper', 'Pencil'] rdr: 1.4000000000000001\n",
      "[1, 2] rdr: 1.4000000000000001\n",
      "[{0: 'Bread', 1: 'Diaper', 2: 'Pencil'}, {0: 'Bread', 2: 'Pencil'}, {2: 'Pencil'}, {1: 'Cheese', 2: 'Wine'}, {1: 'Diaper', 2: 'Pencil'}]\n"
     ]
    }
   ],
   "source": [
    "result, candidate = get_gc_gd_lc_ld_for_item_set(L2_item_set,cleaned_data,2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 'Bread', 1: 'Diaper', 2: 'Pencil'},\n",
       " {0: 'Bread', 2: 'Pencil'},\n",
       " {2: 'Pencil'},\n",
       " {1: 'Cheese', 2: 'Wine'},\n",
       " {1: 'Diaper', 2: 'Pencil'}]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1],\n",
       "  ['Bread', 'Cheese'],\n",
       "  ['Bagel'],\n",
       "  1.7142857142857142,\n",
       "  0.07142857142857142],\n",
       " [[0, 1, 2],\n",
       "  ['Bread', 'Diaper', 'Pencil'],\n",
       "  ['Bagel'],\n",
       "  5.142857142857143,\n",
       "  0.21428571428571427],\n",
       " [[0, 2],\n",
       "  ['Bread', 'Pencil'],\n",
       "  ['Bagel'],\n",
       "  2.204081632653061,\n",
       "  0.21428571428571427],\n",
       " [[0, 2],\n",
       "  ['Bread', 'Wine'],\n",
       "  ['Bagel'],\n",
       "  5.142857142857143,\n",
       "  0.07142857142857142],\n",
       " [[2], ['Pencil'], ['Bagel'], 2.1428571428571432, 0.35714285714285715],\n",
       " [[1, 2],\n",
       "  ['Cheese', 'Wine'],\n",
       "  ['Bagel'],\n",
       "  3.857142857142857,\n",
       "  0.21428571428571427],\n",
       " [[1, 2],\n",
       "  ['Diaper', 'Pencil'],\n",
       "  ['Bagel'],\n",
       "  4.114285714285714,\n",
       "  0.2857142857142857]]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1, 2]\n",
      "3\n",
      "[0, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1, 2]\n",
      "3\n",
      "[2]\n",
      "1\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1, 2]\n",
      "3\n",
      "[1, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 1, 2]\n",
      "3\n",
      "[1, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[2]\n",
      "1\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 2: 'Pencil'}\n",
      "{1: 'Cheese', 2: 'Wine'}\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[0, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "space allow to merge\n",
      "{0: 'Bread', 2: 'Pencil'}\n",
      "{1: 'Diaper', 2: 'Pencil'}\n",
      "2 is the same space\n",
      "item allow to merge\n",
      "{0: 'Bread', 2: 'Pencil', 1: 'Diaper'}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[2]\n",
      "1\n",
      "[1, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[2]\n",
      "1\n",
      "[1, 2]\n",
      "2\n",
      "====end====\n",
      "{}\n",
      "your object is a list, proceeding for L > 2 \n",
      "[1, 2]\n",
      "2\n",
      "[1, 2]\n",
      "2\n",
      "same length\n",
      "not allow to merge\n",
      "====end====\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{0: 'Bread', 2: 'Pencil', 1: 'Diaper'}]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L3candidate = create_Ln(candidate, space_name_order)\n",
    "L3candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 'Bread', 2: 'Pencil', 1: 'Diaper'}]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L3candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space:\n",
      "[0, 2, 1]\n",
      "item:\n",
      "['Bread', 'Pencil', 'Diaper']\n",
      "density ratio:\n",
      "5.142857142857143\n",
      "confidence:\n",
      "0.21428571428571427\n",
      "creating the final candidate\n",
      "the index [0]\n",
      "['Bread', 'Pencil', 'Diaper'] rdr: 1.0\n",
      "[0, 2, 1] rdr: 1.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "result, L4candidate = get_gc_gd_lc_ld_for_item_set(L3candidate,cleaned_data,2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 2, 1],\n",
       "  ['Bread', 'Pencil', 'Diaper'],\n",
       "  ['Bagel'],\n",
       "  5.142857142857143,\n",
       "  0.21428571428571427]]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L4candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
